//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30672275
// Cuda compilation tools, release 11.5, V11.5.119
// Based on NVVM 7.0.1
//

.version 7.5
.target sm_86
.address_size 64

	// .globl	heavy_hash
.global .align 1 .b8 rho[24] = {1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 2, 14, 27, 41, 56, 8, 25, 43, 62, 18, 39, 61, 20, 44};
.global .align 1 .b8 pi[24] = {10, 7, 11, 17, 18, 3, 5, 16, 8, 21, 24, 4, 15, 23, 19, 13, 12, 2, 20, 14, 22, 9, 6, 1};
.global .align 8 .b8 RC[192] = {1, 0, 0, 0, 0, 0, 0, 0, 130, 128, 0, 0, 0, 0, 0, 0, 138, 128, 0, 0, 0, 0, 0, 128, 0, 128, 0, 128, 0, 0, 0, 128, 139, 128, 0, 0, 0, 0, 0, 0, 1, 0, 0, 128, 0, 0, 0, 0, 129, 128, 0, 128, 0, 0, 0, 128, 9, 128, 0, 0, 0, 0, 0, 128, 138, 0, 0, 0, 0, 0, 0, 0, 136, 0, 0, 0, 0, 0, 0, 0, 9, 128, 0, 128, 0, 0, 0, 0, 10, 0, 0, 128, 0, 0, 0, 0, 139, 128, 0, 128, 0, 0, 0, 0, 139, 0, 0, 0, 0, 0, 0, 128, 137, 128, 0, 0, 0, 0, 0, 128, 3, 128, 0, 0, 0, 0, 0, 128, 2, 128, 0, 0, 0, 0, 0, 128, 128, 0, 0, 0, 0, 0, 0, 128, 10, 128, 0, 0, 0, 0, 0, 0, 10, 0, 0, 128, 0, 0, 0, 128, 129, 128, 0, 128, 0, 0, 0, 128, 128, 128, 0, 0, 0, 0, 0, 128, 1, 0, 0, 128, 0, 0, 0, 0, 8, 128, 0, 128, 0, 0, 0, 128};
.global .align 8 .b8 _ZZ15xoshiro256_jumpP10ulonglong4E4JUMP[32] = {186, 10, 253, 60, 211, 198, 14, 24, 44, 57, 201, 240, 102, 18, 166, 213, 170, 201, 63, 224, 24, 38, 88, 169, 28, 102, 177, 41, 69, 220, 171, 57};
.global .align 8 .b8 _ZZ20xoshiro256_long_jumpP10ulonglong4E9LONG_JUMP[32] = {191, 203, 253, 254, 62, 93, 225, 118, 179, 47, 82, 28, 68, 78, 0, 197, 65, 226, 78, 133, 105, 0, 113, 119, 53, 230, 203, 42, 176, 155, 16, 57};
.const .align 4 .b8 matrix[4096];
.const .align 8 .b8 hash_header[72];
.const .align 8 .b8 target[32];
.const .align 1 .b8 powP[200] = {61, 216, 246, 161, 13, 255, 60, 17, 60, 126, 2, 183, 85, 136, 191, 41, 210, 68, 251, 14, 114, 46, 95, 30, 160, 105, 152, 245, 163, 164, 165, 27, 101, 45, 94, 135, 202, 175, 47, 123, 70, 226, 220, 41, 214, 97, 239, 74, 16, 91, 65, 173, 30, 152, 58, 24, 156, 194, 155, 120, 12, 246, 107, 119, 64, 49, 102, 136, 51, 241, 235, 248, 240, 95, 40, 67, 60, 28, 101, 46, 10, 74, 241, 64, 5, 7, 150, 15, 82, 145, 41, 91, 135, 103, 227, 68, 21, 55, 177, 37, 164, 241, 112, 236, 137, 218, 233, 130, 143, 93, 200, 230, 35, 178, 180, 133, 31, 96, 26, 178, 70, 106, 163, 100, 144, 84, 133, 52, 26, 133, 47, 122, 28, 221, 6, 15, 66, 177, 59, 86, 29, 2, 162, 193, 228, 104, 22, 69, 228, 229, 29, 186, 141, 95, 9, 5, 65, 87, 2, 209, 74, 207, 206, 155, 132, 78, 202, 137, 219, 46, 116, 168, 39, 148, 176, 72, 114, 82, 139, 231, 156, 206, 252, 177, 188, 165, 175, 130, 207, 41, 17, 93, 131, 67, 130, 111, 120, 124, 185, 2};
.const .align 1 .b8 heavyP[200] = {9, 133, 36, 178, 82, 76, 215, 58, 22, 66, 159, 47, 14, 155, 98, 121, 238, 248, 199, 22, 72, 255, 20, 122, 152, 100, 5, 128, 76, 95, 167, 17, 218, 206, 238, 68, 223, 224, 32, 231, 105, 64, 243, 20, 46, 216, 199, 114, 186, 53, 137, 147, 42, 255, 0, 193, 98, 196, 15, 37, 64, 144, 33, 94, 72, 106, 207, 13, 166, 249, 57, 128, 12, 61, 42, 121, 159, 170, 188, 160, 38, 162, 169, 208, 93, 192, 49, 244, 63, 140, 193, 84, 195, 76, 31, 211, 61, 204, 105, 167, 1, 125, 107, 108, 228, 147, 36, 86, 211, 91, 198, 46, 68, 176, 205, 153, 58, 75, 247, 78, 176, 242, 52, 84, 131, 134, 76, 119, 22, 148, 188, 54, 176, 97, 233, 7, 7, 204, 101, 119, 177, 29, 143, 126, 57, 109, 196, 186, 128, 219, 143, 234, 88, 202, 52, 123, 211, 242, 146, 185, 87, 185, 129, 132, 4, 197, 118, 199, 46, 194, 18, 81, 103, 159, 195, 71, 10, 12, 41, 181, 157, 57, 187, 146, 21, 198, 159, 47, 49, 224, 154, 84, 53, 218, 185, 16, 125, 50, 25, 22};

.visible .entry heavy_hash(
	.param .u64 heavy_hash_param_0,
	.param .u64 heavy_hash_param_1,
	.param .u64 heavy_hash_param_2,
	.param .u8 heavy_hash_param_3,
	.param .u64 heavy_hash_param_4,
	.param .u64 heavy_hash_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<4644>;
	.reg .b64 	%rd<712>;


	ld.param.u8 	%rs1, [heavy_hash_param_3];
	ld.param.u64 	%rd129, [heavy_hash_param_0];
	ld.param.u64 	%rd130, [heavy_hash_param_1];
	ld.param.u64 	%rd131, [heavy_hash_param_2];
	ld.param.u64 	%rd132, [heavy_hash_param_4];
	ld.param.u64 	%rd133, [heavy_hash_param_5];
	cvta.to.global.u64 	%rd1, %rd132;
	cvta.to.global.u64 	%rd2, %rd133;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r8, %r6, %r5, %r7;
	cvt.s64.s32 	%rd3, %r8;
	setp.ge.u64 	%p6, %rd3, %rd131;
	@%p6 bra 	$L__BB0_19;

	cvt.u32.u64 	%r9, %rd3;
	setp.ne.s32 	%p7, %r9, 0;
	@%p7 bra 	$L__BB0_3;

	mov.u64 	%rd134, 0;
	st.global.u64 	[%rd2], %rd134;

$L__BB0_3:
	setp.eq.s16 	%p8, %rs1, 0;
	@%p8 bra 	$L__BB0_5;

	shl.b64 	%rd135, %rd3, 5;
	add.s64 	%rd136, %rd1, %rd135;
	ld.global.v2.u64 	{%rd137, %rd138}, [%rd136];
	mul.lo.s64 	%rd141, %rd138, 5;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd141, 7;
	shr.b64 	%rhs, %rd141, 57;
	add.u64 	%rd142, %lhs, %rhs;
	}
	mul.lo.s64 	%rd659, %rd142, 9;
	shl.b64 	%rd143, %rd138, 17;
	ld.global.v2.u64 	{%rd144, %rd145}, [%rd136+16];
	xor.b64  	%rd148, %rd144, %rd137;
	xor.b64  	%rd149, %rd145, %rd138;
	xor.b64  	%rd150, %rd138, %rd148;
	xor.b64  	%rd151, %rd137, %rd149;
	st.global.v2.u64 	[%rd136], {%rd151, %rd150};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r10,%dummy}, %rd149;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r11}, %rd149;
	}
	shf.r.wrap.b32 	%r12, %r11, %r10, 19;
	shf.r.wrap.b32 	%r13, %r10, %r11, 19;
	mov.b64 	%rd152, {%r13, %r12};
	xor.b64  	%rd153, %rd148, %rd143;
	st.global.v2.u64 	[%rd136+16], {%rd153, %rd152};
	bra.uni 	$L__BB0_6;

$L__BB0_5:
	brev.b32 	%r15, %r9;
	cvt.u64.u32 	%rd154, %r15;
	shl.b64 	%rd155, %rd154, 32;
	ld.global.u64 	%rd156, [%rd1];
	xor.b64  	%rd659, %rd156, %rd155;

$L__BB0_6:
	and.b64  	%rd173, %rd659, %rd129;
	or.b64  	%rd7, %rd173, %rd130;
	ld.const.u64 	%rd174, [hash_header];
	xor.b64  	%rd685, %rd174, 1242148031264380989;
	ld.const.u64 	%rd175, [hash_header+8];
	xor.b64  	%rd680, %rd175, 3008272977830772284;
	ld.const.u64 	%rd176, [hash_header+16];
	xor.b64  	%rd675, %rd176, 2188519011337848018;
	ld.const.u64 	%rd177, [hash_header+24];
	xor.b64  	%rd670, %rd177, 1992179434288343456;
	ld.const.u64 	%rd178, [hash_header+32];
	xor.b64  	%rd665, %rd178, 8876506674959887717;
	ld.const.u64 	%rd179, [hash_header+40];
	xor.b64  	%rd684, %rd179, 5399642050693751366;
	ld.const.u64 	%rd180, [hash_header+48];
	xor.b64  	%rd679, %rd180, 1745875063082670864;
	ld.const.u64 	%rd181, [hash_header+56];
	xor.b64  	%rd674, %rd181, 8605242046444978844;
	ld.const.u64 	%rd182, [hash_header+64];
	xor.b64  	%rd669, %rd182, -510048929142394560;
	xor.b64  	%rd664, %rd7, 3343109343542796272;
	mov.u32 	%r4642, 0;
	mov.u64 	%rd683, 1123092876221303306;
	mov.u64 	%rd682, 3784524041015224902;
	mov.u64 	%rd681, -8517909413761200310;
	mov.u64 	%rd678, 4963925045340115282;
	mov.u64 	%rd677, 1082795874807940378;
	mov.u64 	%rd676, 5237849264682708699;
	mov.u64 	%rd673, -1409360996057663723;
	mov.u64 	%rd672, -4494027153138273982;
	mov.u64 	%rd671, -5621391061570334094;
	mov.u64 	%rd668, -1817099578685924727;
	mov.u64 	%rd667, -5035616039755945756;
	mov.u64 	%rd666, 6706187291358897596;
	mov.u64 	%rd663, -5613068297060437469;
	mov.u64 	%rd662, -3386048033060200563;
	mov.u64 	%rd661, 196324915476054915;
	mov.u64 	%rd660, RC;

$L__BB0_7:
	xor.b64  	%rd183, %rd684, %rd685;
	xor.b64  	%rd184, %rd183, %rd683;
	xor.b64  	%rd185, %rd184, %rd682;
	xor.b64  	%rd186, %rd185, %rd681;
	xor.b64  	%rd187, %rd679, %rd680;
	xor.b64  	%rd188, %rd187, %rd678;
	xor.b64  	%rd189, %rd188, %rd677;
	xor.b64  	%rd190, %rd189, %rd676;
	xor.b64  	%rd191, %rd674, %rd675;
	xor.b64  	%rd192, %rd191, %rd673;
	xor.b64  	%rd193, %rd192, %rd672;
	xor.b64  	%rd194, %rd193, %rd671;
	xor.b64  	%rd195, %rd669, %rd670;
	xor.b64  	%rd196, %rd195, %rd668;
	xor.b64  	%rd197, %rd196, %rd667;
	xor.b64  	%rd198, %rd197, %rd666;
	xor.b64  	%rd199, %rd664, %rd665;
	xor.b64  	%rd200, %rd199, %rd663;
	xor.b64  	%rd201, %rd200, %rd662;
	xor.b64  	%rd202, %rd201, %rd661;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r17}, %rd190;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r18,%dummy}, %rd190;
	}
	shf.l.wrap.b32 	%r19, %r18, %r17, 1;
	shf.l.wrap.b32 	%r20, %r17, %r18, 1;
	mov.b64 	%rd203, {%r20, %r19};
	xor.b64  	%rd204, %rd202, %rd203;
	xor.b64  	%rd205, %rd204, %rd685;
	xor.b64  	%rd206, %rd684, %rd204;
	xor.b64  	%rd207, %rd683, %rd204;
	xor.b64  	%rd208, %rd682, %rd204;
	xor.b64  	%rd209, %rd681, %rd204;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r21}, %rd194;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r22,%dummy}, %rd194;
	}
	shf.l.wrap.b32 	%r23, %r22, %r21, 1;
	shf.l.wrap.b32 	%r24, %r21, %r22, 1;
	mov.b64 	%rd210, {%r24, %r23};
	xor.b64  	%rd211, %rd210, %rd186;
	xor.b64  	%rd212, %rd680, %rd211;
	xor.b64  	%rd213, %rd679, %rd211;
	xor.b64  	%rd214, %rd678, %rd211;
	xor.b64  	%rd215, %rd677, %rd211;
	xor.b64  	%rd216, %rd676, %rd211;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r25}, %rd198;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r26,%dummy}, %rd198;
	}
	shf.l.wrap.b32 	%r27, %r26, %r25, 1;
	shf.l.wrap.b32 	%r28, %r25, %r26, 1;
	mov.b64 	%rd217, {%r28, %r27};
	xor.b64  	%rd218, %rd217, %rd190;
	xor.b64  	%rd219, %rd675, %rd218;
	xor.b64  	%rd220, %rd674, %rd218;
	xor.b64  	%rd221, %rd673, %rd218;
	xor.b64  	%rd222, %rd672, %rd218;
	xor.b64  	%rd223, %rd671, %rd218;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r29}, %rd202;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r30,%dummy}, %rd202;
	}
	shf.l.wrap.b32 	%r31, %r30, %r29, 1;
	shf.l.wrap.b32 	%r32, %r29, %r30, 1;
	mov.b64 	%rd224, {%r32, %r31};
	xor.b64  	%rd225, %rd224, %rd194;
	xor.b64  	%rd226, %rd670, %rd225;
	xor.b64  	%rd227, %rd669, %rd225;
	xor.b64  	%rd228, %rd668, %rd225;
	xor.b64  	%rd229, %rd667, %rd225;
	xor.b64  	%rd230, %rd666, %rd225;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r33}, %rd186;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r34,%dummy}, %rd186;
	}
	shf.l.wrap.b32 	%r35, %r34, %r33, 1;
	shf.l.wrap.b32 	%r36, %r33, %r34, 1;
	mov.b64 	%rd231, {%r36, %r35};
	xor.b64  	%rd232, %rd198, %rd231;
	xor.b64  	%rd233, %rd665, %rd232;
	xor.b64  	%rd234, %rd664, %rd232;
	xor.b64  	%rd235, %rd663, %rd232;
	xor.b64  	%rd236, %rd662, %rd232;
	xor.b64  	%rd237, %rd661, %rd232;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r37}, %rd212;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r38,%dummy}, %rd212;
	}
	shf.l.wrap.b32 	%r39, %r38, %r37, 1;
	shf.l.wrap.b32 	%r40, %r37, %r38, 1;
	mov.b64 	%rd238, {%r40, %r39};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r41}, %rd207;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r42,%dummy}, %rd207;
	}
	shf.l.wrap.b32 	%r43, %r42, %r41, 3;
	shf.l.wrap.b32 	%r44, %r41, %r42, 3;
	mov.b64 	%rd239, {%r44, %r43};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r45}, %rd220;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r46,%dummy}, %rd220;
	}
	shf.l.wrap.b32 	%r47, %r46, %r45, 6;
	shf.l.wrap.b32 	%r48, %r45, %r46, 6;
	mov.b64 	%rd240, {%r48, %r47};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r49}, %rd214;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r50,%dummy}, %rd214;
	}
	shf.l.wrap.b32 	%r51, %r50, %r49, 10;
	shf.l.wrap.b32 	%r52, %r49, %r50, 10;
	mov.b64 	%rd241, {%r52, %r51};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r53}, %rd222;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r54,%dummy}, %rd222;
	}
	shf.l.wrap.b32 	%r55, %r54, %r53, 15;
	shf.l.wrap.b32 	%r56, %r53, %r54, 15;
	mov.b64 	%rd242, {%r56, %r55};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r57}, %rd229;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r58,%dummy}, %rd229;
	}
	shf.l.wrap.b32 	%r59, %r58, %r57, 21;
	shf.l.wrap.b32 	%r60, %r57, %r58, 21;
	mov.b64 	%rd243, {%r60, %r59};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r61}, %rd226;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r62,%dummy}, %rd226;
	}
	shf.l.wrap.b32 	%r63, %r62, %r61, 28;
	shf.l.wrap.b32 	%r64, %r61, %r62, 28;
	mov.b64 	%rd244, {%r64, %r63};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r65,%dummy}, %rd206;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r66}, %rd206;
	}
	shf.r.wrap.b32 	%r67, %r66, %r65, 28;
	shf.r.wrap.b32 	%r68, %r65, %r66, 28;
	mov.b64 	%rd245, {%r68, %r67};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r69,%dummy}, %rd215;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r70}, %rd215;
	}
	shf.r.wrap.b32 	%r71, %r70, %r69, 19;
	shf.r.wrap.b32 	%r72, %r69, %r70, 19;
	mov.b64 	%rd246, {%r72, %r71};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r73,%dummy}, %rd227;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r74}, %rd227;
	}
	shf.r.wrap.b32 	%r75, %r74, %r73, 9;
	shf.r.wrap.b32 	%r76, %r73, %r74, 9;
	mov.b64 	%rd247, {%r76, %r75};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r77}, %rd216;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r78,%dummy}, %rd216;
	}
	shf.l.wrap.b32 	%r79, %r78, %r77, 2;
	shf.l.wrap.b32 	%r80, %r77, %r78, 2;
	mov.b64 	%rd248, {%r80, %r79};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r81}, %rd237;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r82,%dummy}, %rd237;
	}
	shf.l.wrap.b32 	%r83, %r82, %r81, 14;
	shf.l.wrap.b32 	%r84, %r81, %r82, 14;
	mov.b64 	%rd249, {%r84, %r83};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r85}, %rd233;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r86,%dummy}, %rd233;
	}
	shf.l.wrap.b32 	%r87, %r86, %r85, 27;
	shf.l.wrap.b32 	%r88, %r85, %r86, 27;
	mov.b64 	%rd250, {%r88, %r87};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r89,%dummy}, %rd208;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r90}, %rd208;
	}
	shf.r.wrap.b32 	%r91, %r90, %r89, 23;
	shf.r.wrap.b32 	%r92, %r89, %r90, 23;
	mov.b64 	%rd251, {%r92, %r91};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r93,%dummy}, %rd230;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r94}, %rd230;
	}
	shf.r.wrap.b32 	%r95, %r94, %r93, 8;
	shf.r.wrap.b32 	%r96, %r93, %r94, 8;
	mov.b64 	%rd252, {%r96, %r95};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r97}, %rd236;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r98,%dummy}, %rd236;
	}
	shf.l.wrap.b32 	%r99, %r98, %r97, 8;
	shf.l.wrap.b32 	%r100, %r97, %r98, 8;
	mov.b64 	%rd253, {%r100, %r99};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r101}, %rd228;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r102,%dummy}, %rd228;
	}
	shf.l.wrap.b32 	%r103, %r102, %r101, 25;
	shf.l.wrap.b32 	%r104, %r101, %r102, 25;
	mov.b64 	%rd254, {%r104, %r103};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r105,%dummy}, %rd221;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r106}, %rd221;
	}
	shf.r.wrap.b32 	%r107, %r106, %r105, 21;
	shf.r.wrap.b32 	%r108, %r105, %r106, 21;
	mov.b64 	%rd255, {%r108, %r107};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r109,%dummy}, %rd219;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r110}, %rd219;
	}
	shf.r.wrap.b32 	%r111, %r110, %r109, 2;
	shf.r.wrap.b32 	%r112, %r109, %r110, 2;
	mov.b64 	%rd256, {%r112, %r111};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r113}, %rd209;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r114,%dummy}, %rd209;
	}
	shf.l.wrap.b32 	%r115, %r114, %r113, 18;
	shf.l.wrap.b32 	%r116, %r113, %r114, 18;
	mov.b64 	%rd257, {%r116, %r115};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r117,%dummy}, %rd235;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r118}, %rd235;
	}
	shf.r.wrap.b32 	%r119, %r118, %r117, 25;
	shf.r.wrap.b32 	%r120, %r117, %r118, 25;
	mov.b64 	%rd258, {%r120, %r119};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r121,%dummy}, %rd223;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r122}, %rd223;
	}
	shf.r.wrap.b32 	%r123, %r122, %r121, 3;
	shf.r.wrap.b32 	%r124, %r121, %r122, 3;
	mov.b64 	%rd259, {%r124, %r123};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r125}, %rd234;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r126,%dummy}, %rd234;
	}
	shf.l.wrap.b32 	%r127, %r126, %r125, 20;
	shf.l.wrap.b32 	%r128, %r125, %r126, 20;
	mov.b64 	%rd260, {%r128, %r127};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r129,%dummy}, %rd213;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r130}, %rd213;
	}
	shf.r.wrap.b32 	%r131, %r130, %r129, 20;
	shf.r.wrap.b32 	%r132, %r129, %r130, 20;
	mov.b64 	%rd261, {%r132, %r131};
	not.b64 	%rd262, %rd261;
	and.b64  	%rd263, %rd255, %rd262;
	xor.b64  	%rd264, %rd263, %rd205;
	not.b64 	%rd265, %rd255;
	and.b64  	%rd266, %rd243, %rd265;
	xor.b64  	%rd680, %rd266, %rd261;
	not.b64 	%rd267, %rd243;
	and.b64  	%rd268, %rd249, %rd267;
	xor.b64  	%rd675, %rd268, %rd255;
	not.b64 	%rd269, %rd249;
	and.b64  	%rd270, %rd205, %rd269;
	xor.b64  	%rd670, %rd270, %rd243;
	not.b64 	%rd271, %rd205;
	and.b64  	%rd272, %rd261, %rd271;
	xor.b64  	%rd665, %rd249, %rd272;
	not.b64 	%rd273, %rd260;
	and.b64  	%rd274, %rd239, %rd273;
	xor.b64  	%rd684, %rd274, %rd244;
	not.b64 	%rd275, %rd239;
	and.b64  	%rd276, %rd246, %rd275;
	xor.b64  	%rd679, %rd276, %rd260;
	not.b64 	%rd277, %rd246;
	and.b64  	%rd278, %rd259, %rd277;
	xor.b64  	%rd674, %rd278, %rd239;
	not.b64 	%rd279, %rd259;
	and.b64  	%rd280, %rd244, %rd279;
	xor.b64  	%rd669, %rd280, %rd246;
	not.b64 	%rd281, %rd244;
	and.b64  	%rd282, %rd260, %rd281;
	xor.b64  	%rd664, %rd259, %rd282;
	not.b64 	%rd283, %rd240;
	and.b64  	%rd284, %rd254, %rd283;
	xor.b64  	%rd683, %rd284, %rd238;
	not.b64 	%rd285, %rd254;
	and.b64  	%rd286, %rd253, %rd285;
	xor.b64  	%rd678, %rd286, %rd240;
	not.b64 	%rd287, %rd253;
	and.b64  	%rd288, %rd257, %rd287;
	xor.b64  	%rd673, %rd288, %rd254;
	not.b64 	%rd289, %rd257;
	and.b64  	%rd290, %rd238, %rd289;
	xor.b64  	%rd668, %rd290, %rd253;
	not.b64 	%rd291, %rd238;
	and.b64  	%rd292, %rd240, %rd291;
	xor.b64  	%rd663, %rd257, %rd292;
	not.b64 	%rd293, %rd245;
	and.b64  	%rd294, %rd241, %rd293;
	xor.b64  	%rd682, %rd294, %rd250;
	not.b64 	%rd295, %rd241;
	and.b64  	%rd296, %rd242, %rd295;
	xor.b64  	%rd677, %rd296, %rd245;
	not.b64 	%rd297, %rd242;
	and.b64  	%rd298, %rd252, %rd297;
	xor.b64  	%rd672, %rd298, %rd241;
	not.b64 	%rd299, %rd252;
	and.b64  	%rd300, %rd250, %rd299;
	xor.b64  	%rd667, %rd300, %rd242;
	not.b64 	%rd301, %rd250;
	and.b64  	%rd302, %rd245, %rd301;
	xor.b64  	%rd662, %rd252, %rd302;
	not.b64 	%rd303, %rd247;
	and.b64  	%rd304, %rd258, %rd303;
	xor.b64  	%rd681, %rd304, %rd256;
	not.b64 	%rd305, %rd258;
	and.b64  	%rd306, %rd251, %rd305;
	xor.b64  	%rd676, %rd306, %rd247;
	not.b64 	%rd307, %rd251;
	and.b64  	%rd308, %rd248, %rd307;
	xor.b64  	%rd671, %rd308, %rd258;
	not.b64 	%rd309, %rd248;
	and.b64  	%rd310, %rd256, %rd309;
	xor.b64  	%rd666, %rd310, %rd251;
	not.b64 	%rd311, %rd256;
	and.b64  	%rd312, %rd247, %rd311;
	xor.b64  	%rd661, %rd248, %rd312;
	ld.global.nc.u64 	%rd313, [%rd660];
	xor.b64  	%rd685, %rd264, %rd313;
	add.s64 	%rd660, %rd660, 8;
	add.s32 	%r4642, %r4642, 1;
	setp.ne.s32 	%p9, %r4642, 24;
	@%p9 bra 	$L__BB0_7;

	cvt.u16.u64 	%rs2, %rd685;
	and.b16  	%rs3, %rs2, 240;
	shr.u64 	%rd336, %rd685, 8;
	cvt.u32.u64 	%r4230, %rd336;
	shr.u64 	%rd337, %rd685, 16;
	cvt.u32.u64 	%r4231, %rd337;
	shr.u64 	%rd338, %rd685, 24;
	cvt.u32.u64 	%r4232, %rd338;
	shr.u64 	%rd339, %rd685, 32;
	cvt.u32.u64 	%r4233, %rd339;
	shr.u64 	%rd340, %rd685, 40;
	cvt.u32.u64 	%r4234, %rd340;
	shr.u64 	%rd341, %rd685, 48;
	cvt.u32.u64 	%r4235, %rd341;
	shr.u64 	%rd342, %rd685, 56;
	cvt.u32.u64 	%r4236, %rd342;
	shr.u64 	%rd343, %rd680, 8;
	cvt.u32.u64 	%r4237, %rd343;
	shr.u64 	%rd344, %rd680, 16;
	cvt.u32.u64 	%r4238, %rd344;
	shr.u64 	%rd345, %rd680, 24;
	cvt.u32.u64 	%r4239, %rd345;
	shr.u64 	%rd346, %rd680, 32;
	cvt.u32.u64 	%r4240, %rd346;
	shr.u64 	%rd347, %rd680, 40;
	cvt.u32.u64 	%r4241, %rd347;
	shr.u64 	%rd348, %rd680, 48;
	cvt.u32.u64 	%r4242, %rd348;
	shr.u64 	%rd349, %rd680, 56;
	cvt.u32.u64 	%r4243, %rd349;
	shr.u64 	%rd350, %rd675, 8;
	cvt.u32.u64 	%r4244, %rd350;
	shr.u64 	%rd351, %rd675, 16;
	cvt.u32.u64 	%r4245, %rd351;
	shr.u64 	%rd352, %rd675, 24;
	cvt.u32.u64 	%r4246, %rd352;
	shr.u64 	%rd353, %rd675, 32;
	cvt.u32.u64 	%r4247, %rd353;
	shr.u64 	%rd354, %rd675, 40;
	cvt.u32.u64 	%r4248, %rd354;
	shr.u64 	%rd355, %rd675, 48;
	cvt.u32.u64 	%r4249, %rd355;
	shr.u64 	%rd356, %rd675, 56;
	cvt.u32.u64 	%r4250, %rd356;
	shr.u16 	%rs4, %rs3, 4;
	cvt.u32.u64 	%r4251, %rd685;
	shr.u32 	%r4252, %r4251, 12;
	cvt.u32.u16 	%r4253, %rs4;
	and.b32  	%r4254, %r4251, 15;
	prmt.b32 	%r4255, %r4254, %r4253, 30212;
	shl.b32 	%r4256, %r4251, 4;
	and.b32  	%r4257, %r4256, 983040;
	or.b32  	%r4258, %r4255, %r4257;
	shl.b32 	%r4259, %r4230, 24;
	and.b32  	%r4260, %r4259, 251658240;
	or.b32  	%r4167, %r4258, %r4260;
	bfe.u32 	%r4261, %r4251, 20, 4;
	and.b32  	%r4262, %r4231, 15;
	bfi.b32 	%r4263, %r4262, %r4261, 8, 4;
	and.b32  	%r4264, %r4252, 983040;
	or.b32  	%r4265, %r4263, %r4264;
	shl.b32 	%r4266, %r4232, 24;
	and.b32  	%r4267, %r4266, 251658240;
	or.b32  	%r4171, %r4265, %r4267;
	shr.u64 	%rd357, %rd685, 36;
	cvt.u32.u64 	%r4268, %rd357;
	and.b32  	%r4269, %r4268, 15;
	and.b32  	%r4270, %r4233, 15;
	shr.u64 	%rd358, %rd685, 44;
	cvt.u32.u64 	%r4271, %rd358;
	bfi.b32 	%r4272, %r4270, %r4269, 8, 4;
	shl.b32 	%r4273, %r4271, 16;
	and.b32  	%r4274, %r4273, 983040;
	or.b32  	%r4275, %r4272, %r4274;
	shl.b32 	%r4276, %r4234, 24;
	and.b32  	%r4277, %r4276, 251658240;
	or.b32  	%r4175, %r4275, %r4277;
	shr.u64 	%rd359, %rd685, 52;
	cvt.u32.u64 	%r4278, %rd359;
	and.b32  	%r4279, %r4278, 15;
	and.b32  	%r4280, %r4235, 15;
	bfi.b32 	%r4281, %r4280, %r4279, 8, 4;
	and.b32  	%r4282, %r4271, 983040;
	or.b32  	%r4283, %r4281, %r4282;
	shl.b32 	%r4284, %r4236, 24;
	and.b32  	%r4285, %r4284, 251658240;
	or.b32  	%r4179, %r4283, %r4285;
	cvt.u16.u64 	%rs5, %rd680;
	and.b16  	%rs6, %rs5, 240;
	shr.u16 	%rs7, %rs6, 4;
	cvt.u32.u64 	%r4286, %rd680;
	shr.u32 	%r4287, %r4286, 12;
	cvt.u32.u16 	%r4288, %rs7;
	and.b32  	%r4289, %r4286, 15;
	prmt.b32 	%r4290, %r4289, %r4288, 30212;
	shl.b32 	%r4291, %r4286, 4;
	and.b32  	%r4292, %r4291, 983040;
	or.b32  	%r4293, %r4290, %r4292;
	shl.b32 	%r4294, %r4237, 24;
	and.b32  	%r4295, %r4294, 251658240;
	or.b32  	%r4183, %r4293, %r4295;
	bfe.u32 	%r4296, %r4286, 20, 4;
	and.b32  	%r4297, %r4238, 15;
	bfi.b32 	%r4298, %r4297, %r4296, 8, 4;
	and.b32  	%r4299, %r4287, 983040;
	or.b32  	%r4300, %r4298, %r4299;
	shl.b32 	%r4301, %r4239, 24;
	and.b32  	%r4302, %r4301, 251658240;
	or.b32  	%r4187, %r4300, %r4302;
	shr.u64 	%rd360, %rd680, 36;
	cvt.u32.u64 	%r4303, %rd360;
	and.b32  	%r4304, %r4303, 15;
	and.b32  	%r4305, %r4240, 15;
	shr.u64 	%rd361, %rd680, 44;
	cvt.u32.u64 	%r4306, %rd361;
	bfi.b32 	%r4307, %r4305, %r4304, 8, 4;
	shl.b32 	%r4308, %r4306, 16;
	and.b32  	%r4309, %r4308, 983040;
	or.b32  	%r4310, %r4307, %r4309;
	shl.b32 	%r4311, %r4241, 24;
	and.b32  	%r4312, %r4311, 251658240;
	or.b32  	%r4191, %r4310, %r4312;
	shr.u64 	%rd362, %rd680, 52;
	cvt.u32.u64 	%r4313, %rd362;
	and.b32  	%r4314, %r4313, 15;
	and.b32  	%r4315, %r4242, 15;
	bfi.b32 	%r4316, %r4315, %r4314, 8, 4;
	and.b32  	%r4317, %r4306, 983040;
	or.b32  	%r4318, %r4316, %r4317;
	shl.b32 	%r4319, %r4243, 24;
	and.b32  	%r4320, %r4319, 251658240;
	or.b32  	%r4195, %r4318, %r4320;
	cvt.u16.u64 	%rs8, %rd675;
	and.b16  	%rs9, %rs8, 240;
	shr.u16 	%rs10, %rs9, 4;
	cvt.u32.u64 	%r4321, %rd675;
	shr.u32 	%r4322, %r4321, 12;
	cvt.u32.u16 	%r4323, %rs10;
	and.b32  	%r4324, %r4321, 15;
	prmt.b32 	%r4325, %r4324, %r4323, 30212;
	shl.b32 	%r4326, %r4321, 4;
	and.b32  	%r4327, %r4326, 983040;
	or.b32  	%r4328, %r4325, %r4327;
	shl.b32 	%r4329, %r4244, 24;
	and.b32  	%r4330, %r4329, 251658240;
	or.b32  	%r4199, %r4328, %r4330;
	bfe.u32 	%r4331, %r4321, 20, 4;
	and.b32  	%r4332, %r4245, 15;
	bfi.b32 	%r4333, %r4332, %r4331, 8, 4;
	and.b32  	%r4334, %r4322, 983040;
	or.b32  	%r4335, %r4333, %r4334;
	shl.b32 	%r4336, %r4246, 24;
	and.b32  	%r4337, %r4336, 251658240;
	or.b32  	%r4203, %r4335, %r4337;
	shr.u64 	%rd363, %rd675, 36;
	cvt.u32.u64 	%r4338, %rd363;
	and.b32  	%r4339, %r4338, 15;
	and.b32  	%r4340, %r4247, 15;
	shr.u64 	%rd364, %rd675, 44;
	cvt.u32.u64 	%r4341, %rd364;
	bfi.b32 	%r4342, %r4340, %r4339, 8, 4;
	shl.b32 	%r4343, %r4341, 16;
	and.b32  	%r4344, %r4343, 983040;
	or.b32  	%r4345, %r4342, %r4344;
	shl.b32 	%r4346, %r4248, 24;
	and.b32  	%r4347, %r4346, 251658240;
	or.b32  	%r4207, %r4345, %r4347;
	shr.u64 	%rd365, %rd675, 52;
	cvt.u32.u64 	%r4348, %rd365;
	and.b32  	%r4349, %r4348, 15;
	and.b32  	%r4350, %r4249, 15;
	bfi.b32 	%r4351, %r4350, %r4349, 8, 4;
	and.b32  	%r4352, %r4341, 983040;
	or.b32  	%r4353, %r4351, %r4352;
	shl.b32 	%r4354, %r4250, 24;
	and.b32  	%r4355, %r4354, 251658240;
	or.b32  	%r4211, %r4353, %r4355;
	cvt.u16.u64 	%rs11, %rd670;
	and.b16  	%rs12, %rs11, 240;
	shr.u16 	%rs13, %rs12, 4;
	shr.u64 	%rd366, %rd670, 8;
	cvt.u32.u64 	%r4356, %rd366;
	cvt.u32.u64 	%r4357, %rd670;
	shr.u32 	%r4358, %r4357, 12;
	cvt.u32.u16 	%r4359, %rs13;
	and.b32  	%r4360, %r4357, 15;
	prmt.b32 	%r4361, %r4360, %r4359, 30212;
	shl.b32 	%r4362, %r4357, 4;
	and.b32  	%r4363, %r4362, 983040;
	or.b32  	%r4364, %r4361, %r4363;
	shl.b32 	%r4365, %r4356, 24;
	and.b32  	%r4366, %r4365, 251658240;
	or.b32  	%r4215, %r4364, %r4366;
	shr.u64 	%rd367, %rd670, 16;
	cvt.u32.u64 	%r4367, %rd367;
	bfe.u32 	%r4368, %r4357, 20, 4;
	and.b32  	%r4369, %r4367, 15;
	shr.u64 	%rd368, %rd670, 24;
	cvt.u32.u64 	%r4370, %rd368;
	bfi.b32 	%r4371, %r4369, %r4368, 8, 4;
	and.b32  	%r4372, %r4358, 983040;
	or.b32  	%r4373, %r4371, %r4372;
	shl.b32 	%r4374, %r4370, 24;
	and.b32  	%r4375, %r4374, 251658240;
	or.b32  	%r4219, %r4373, %r4375;
	shr.u64 	%rd369, %rd670, 32;
	cvt.u32.u64 	%r4376, %rd369;
	shr.u64 	%rd370, %rd670, 36;
	cvt.u32.u64 	%r4377, %rd370;
	and.b32  	%r4378, %r4377, 15;
	and.b32  	%r4379, %r4376, 15;
	shr.u64 	%rd371, %rd670, 40;
	cvt.u32.u64 	%r4380, %rd371;
	shr.u64 	%rd372, %rd670, 44;
	cvt.u32.u64 	%r4381, %rd372;
	bfi.b32 	%r4382, %r4379, %r4378, 8, 4;
	shl.b32 	%r4383, %r4381, 16;
	and.b32  	%r4384, %r4383, 983040;
	or.b32  	%r4385, %r4382, %r4384;
	shl.b32 	%r4386, %r4380, 24;
	and.b32  	%r4387, %r4386, 251658240;
	or.b32  	%r4223, %r4385, %r4387;
	shr.u64 	%rd373, %rd670, 48;
	cvt.u32.u64 	%r4388, %rd373;
	shr.u64 	%rd374, %rd670, 52;
	cvt.u32.u64 	%r4389, %rd374;
	and.b32  	%r4390, %r4389, 15;
	and.b32  	%r4391, %r4388, 15;
	shr.u64 	%rd375, %rd670, 56;
	cvt.u32.u64 	%r4392, %rd375;
	bfi.b32 	%r4393, %r4391, %r4390, 8, 4;
	and.b32  	%r4394, %r4381, 983040;
	or.b32  	%r4395, %r4393, %r4394;
	shl.b32 	%r4396, %r4392, 24;
	and.b32  	%r4397, %r4396, 251658240;
	or.b32  	%r4227, %r4395, %r4397;
	ld.const.u32 	%r134, [matrix];
	mov.u32 	%r4643, 0;
	// begin inline asm
	dp4a.u32.u32 %r133, %r134, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r138, [matrix+4];
	// begin inline asm
	dp4a.u32.u32 %r137, %r138, %r4171, %r133;
	// end inline asm
	ld.const.u32 	%r142, [matrix+8];
	// begin inline asm
	dp4a.u32.u32 %r141, %r142, %r4175, %r137;
	// end inline asm
	ld.const.u32 	%r146, [matrix+12];
	// begin inline asm
	dp4a.u32.u32 %r145, %r146, %r4179, %r141;
	// end inline asm
	ld.const.u32 	%r150, [matrix+16];
	// begin inline asm
	dp4a.u32.u32 %r149, %r150, %r4183, %r145;
	// end inline asm
	ld.const.u32 	%r154, [matrix+20];
	// begin inline asm
	dp4a.u32.u32 %r153, %r154, %r4187, %r149;
	// end inline asm
	ld.const.u32 	%r158, [matrix+24];
	// begin inline asm
	dp4a.u32.u32 %r157, %r158, %r4191, %r153;
	// end inline asm
	ld.const.u32 	%r162, [matrix+28];
	// begin inline asm
	dp4a.u32.u32 %r161, %r162, %r4195, %r157;
	// end inline asm
	ld.const.u32 	%r166, [matrix+32];
	// begin inline asm
	dp4a.u32.u32 %r165, %r166, %r4199, %r161;
	// end inline asm
	ld.const.u32 	%r170, [matrix+36];
	// begin inline asm
	dp4a.u32.u32 %r169, %r170, %r4203, %r165;
	// end inline asm
	ld.const.u32 	%r174, [matrix+40];
	// begin inline asm
	dp4a.u32.u32 %r173, %r174, %r4207, %r169;
	// end inline asm
	ld.const.u32 	%r178, [matrix+44];
	// begin inline asm
	dp4a.u32.u32 %r177, %r178, %r4211, %r173;
	// end inline asm
	ld.const.u32 	%r182, [matrix+48];
	// begin inline asm
	dp4a.u32.u32 %r181, %r182, %r4215, %r177;
	// end inline asm
	ld.const.u32 	%r186, [matrix+52];
	// begin inline asm
	dp4a.u32.u32 %r185, %r186, %r4219, %r181;
	// end inline asm
	ld.const.u32 	%r190, [matrix+56];
	// begin inline asm
	dp4a.u32.u32 %r189, %r190, %r4223, %r185;
	// end inline asm
	ld.const.u32 	%r194, [matrix+60];
	// begin inline asm
	dp4a.u32.u32 %r193, %r194, %r4227, %r189;
	// end inline asm
	ld.const.u32 	%r198, [matrix+64];
	// begin inline asm
	dp4a.u32.u32 %r197, %r198, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r202, [matrix+68];
	// begin inline asm
	dp4a.u32.u32 %r201, %r202, %r4171, %r197;
	// end inline asm
	ld.const.u32 	%r206, [matrix+72];
	// begin inline asm
	dp4a.u32.u32 %r205, %r206, %r4175, %r201;
	// end inline asm
	ld.const.u32 	%r210, [matrix+76];
	// begin inline asm
	dp4a.u32.u32 %r209, %r210, %r4179, %r205;
	// end inline asm
	ld.const.u32 	%r214, [matrix+80];
	// begin inline asm
	dp4a.u32.u32 %r213, %r214, %r4183, %r209;
	// end inline asm
	ld.const.u32 	%r218, [matrix+84];
	// begin inline asm
	dp4a.u32.u32 %r217, %r218, %r4187, %r213;
	// end inline asm
	ld.const.u32 	%r222, [matrix+88];
	// begin inline asm
	dp4a.u32.u32 %r221, %r222, %r4191, %r217;
	// end inline asm
	ld.const.u32 	%r226, [matrix+92];
	// begin inline asm
	dp4a.u32.u32 %r225, %r226, %r4195, %r221;
	// end inline asm
	ld.const.u32 	%r230, [matrix+96];
	// begin inline asm
	dp4a.u32.u32 %r229, %r230, %r4199, %r225;
	// end inline asm
	ld.const.u32 	%r234, [matrix+100];
	// begin inline asm
	dp4a.u32.u32 %r233, %r234, %r4203, %r229;
	// end inline asm
	ld.const.u32 	%r238, [matrix+104];
	// begin inline asm
	dp4a.u32.u32 %r237, %r238, %r4207, %r233;
	// end inline asm
	ld.const.u32 	%r242, [matrix+108];
	// begin inline asm
	dp4a.u32.u32 %r241, %r242, %r4211, %r237;
	// end inline asm
	ld.const.u32 	%r246, [matrix+112];
	// begin inline asm
	dp4a.u32.u32 %r245, %r246, %r4215, %r241;
	// end inline asm
	ld.const.u32 	%r250, [matrix+116];
	// begin inline asm
	dp4a.u32.u32 %r249, %r250, %r4219, %r245;
	// end inline asm
	ld.const.u32 	%r254, [matrix+120];
	// begin inline asm
	dp4a.u32.u32 %r253, %r254, %r4223, %r249;
	// end inline asm
	ld.const.u32 	%r258, [matrix+124];
	// begin inline asm
	dp4a.u32.u32 %r257, %r258, %r4227, %r253;
	// end inline asm
	shr.u32 	%r4398, %r193, 6;
	and.b32  	%r4399, %r4398, 240;
	shr.u32 	%r4400, %r257, 10;
	or.b32  	%r4401, %r4400, %r4399;
	cvt.u64.u32 	%rd376, %r4401;
	xor.b64  	%rd377, %rd685, %rd376;
	ld.const.u32 	%r262, [matrix+128];
	// begin inline asm
	dp4a.u32.u32 %r261, %r262, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r266, [matrix+132];
	// begin inline asm
	dp4a.u32.u32 %r265, %r266, %r4171, %r261;
	// end inline asm
	ld.const.u32 	%r270, [matrix+136];
	// begin inline asm
	dp4a.u32.u32 %r269, %r270, %r4175, %r265;
	// end inline asm
	ld.const.u32 	%r274, [matrix+140];
	// begin inline asm
	dp4a.u32.u32 %r273, %r274, %r4179, %r269;
	// end inline asm
	ld.const.u32 	%r278, [matrix+144];
	// begin inline asm
	dp4a.u32.u32 %r277, %r278, %r4183, %r273;
	// end inline asm
	ld.const.u32 	%r282, [matrix+148];
	// begin inline asm
	dp4a.u32.u32 %r281, %r282, %r4187, %r277;
	// end inline asm
	ld.const.u32 	%r286, [matrix+152];
	// begin inline asm
	dp4a.u32.u32 %r285, %r286, %r4191, %r281;
	// end inline asm
	ld.const.u32 	%r290, [matrix+156];
	// begin inline asm
	dp4a.u32.u32 %r289, %r290, %r4195, %r285;
	// end inline asm
	ld.const.u32 	%r294, [matrix+160];
	// begin inline asm
	dp4a.u32.u32 %r293, %r294, %r4199, %r289;
	// end inline asm
	ld.const.u32 	%r298, [matrix+164];
	// begin inline asm
	dp4a.u32.u32 %r297, %r298, %r4203, %r293;
	// end inline asm
	ld.const.u32 	%r302, [matrix+168];
	// begin inline asm
	dp4a.u32.u32 %r301, %r302, %r4207, %r297;
	// end inline asm
	ld.const.u32 	%r306, [matrix+172];
	// begin inline asm
	dp4a.u32.u32 %r305, %r306, %r4211, %r301;
	// end inline asm
	ld.const.u32 	%r310, [matrix+176];
	// begin inline asm
	dp4a.u32.u32 %r309, %r310, %r4215, %r305;
	// end inline asm
	ld.const.u32 	%r314, [matrix+180];
	// begin inline asm
	dp4a.u32.u32 %r313, %r314, %r4219, %r309;
	// end inline asm
	ld.const.u32 	%r318, [matrix+184];
	// begin inline asm
	dp4a.u32.u32 %r317, %r318, %r4223, %r313;
	// end inline asm
	ld.const.u32 	%r322, [matrix+188];
	// begin inline asm
	dp4a.u32.u32 %r321, %r322, %r4227, %r317;
	// end inline asm
	ld.const.u32 	%r326, [matrix+192];
	// begin inline asm
	dp4a.u32.u32 %r325, %r326, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r330, [matrix+196];
	// begin inline asm
	dp4a.u32.u32 %r329, %r330, %r4171, %r325;
	// end inline asm
	ld.const.u32 	%r334, [matrix+200];
	// begin inline asm
	dp4a.u32.u32 %r333, %r334, %r4175, %r329;
	// end inline asm
	ld.const.u32 	%r338, [matrix+204];
	// begin inline asm
	dp4a.u32.u32 %r337, %r338, %r4179, %r333;
	// end inline asm
	ld.const.u32 	%r342, [matrix+208];
	// begin inline asm
	dp4a.u32.u32 %r341, %r342, %r4183, %r337;
	// end inline asm
	ld.const.u32 	%r346, [matrix+212];
	// begin inline asm
	dp4a.u32.u32 %r345, %r346, %r4187, %r341;
	// end inline asm
	ld.const.u32 	%r350, [matrix+216];
	// begin inline asm
	dp4a.u32.u32 %r349, %r350, %r4191, %r345;
	// end inline asm
	ld.const.u32 	%r354, [matrix+220];
	// begin inline asm
	dp4a.u32.u32 %r353, %r354, %r4195, %r349;
	// end inline asm
	ld.const.u32 	%r358, [matrix+224];
	// begin inline asm
	dp4a.u32.u32 %r357, %r358, %r4199, %r353;
	// end inline asm
	ld.const.u32 	%r362, [matrix+228];
	// begin inline asm
	dp4a.u32.u32 %r361, %r362, %r4203, %r357;
	// end inline asm
	ld.const.u32 	%r366, [matrix+232];
	// begin inline asm
	dp4a.u32.u32 %r365, %r366, %r4207, %r361;
	// end inline asm
	ld.const.u32 	%r370, [matrix+236];
	// begin inline asm
	dp4a.u32.u32 %r369, %r370, %r4211, %r365;
	// end inline asm
	ld.const.u32 	%r374, [matrix+240];
	// begin inline asm
	dp4a.u32.u32 %r373, %r374, %r4215, %r369;
	// end inline asm
	ld.const.u32 	%r378, [matrix+244];
	// begin inline asm
	dp4a.u32.u32 %r377, %r378, %r4219, %r373;
	// end inline asm
	ld.const.u32 	%r382, [matrix+248];
	// begin inline asm
	dp4a.u32.u32 %r381, %r382, %r4223, %r377;
	// end inline asm
	ld.const.u32 	%r386, [matrix+252];
	// begin inline asm
	dp4a.u32.u32 %r385, %r386, %r4227, %r381;
	// end inline asm
	shr.u32 	%r4402, %r321, 6;
	and.b32  	%r4403, %r4402, 240;
	shr.u32 	%r4404, %r385, 10;
	or.b32  	%r4405, %r4404, %r4403;
	cvt.u64.u32 	%rd378, %r4405;
	xor.b64  	%rd379, %rd336, %rd378;
	ld.const.u32 	%r390, [matrix+256];
	// begin inline asm
	dp4a.u32.u32 %r389, %r390, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r394, [matrix+260];
	// begin inline asm
	dp4a.u32.u32 %r393, %r394, %r4171, %r389;
	// end inline asm
	ld.const.u32 	%r398, [matrix+264];
	// begin inline asm
	dp4a.u32.u32 %r397, %r398, %r4175, %r393;
	// end inline asm
	ld.const.u32 	%r402, [matrix+268];
	// begin inline asm
	dp4a.u32.u32 %r401, %r402, %r4179, %r397;
	// end inline asm
	ld.const.u32 	%r406, [matrix+272];
	// begin inline asm
	dp4a.u32.u32 %r405, %r406, %r4183, %r401;
	// end inline asm
	ld.const.u32 	%r410, [matrix+276];
	// begin inline asm
	dp4a.u32.u32 %r409, %r410, %r4187, %r405;
	// end inline asm
	ld.const.u32 	%r414, [matrix+280];
	// begin inline asm
	dp4a.u32.u32 %r413, %r414, %r4191, %r409;
	// end inline asm
	ld.const.u32 	%r418, [matrix+284];
	// begin inline asm
	dp4a.u32.u32 %r417, %r418, %r4195, %r413;
	// end inline asm
	ld.const.u32 	%r422, [matrix+288];
	// begin inline asm
	dp4a.u32.u32 %r421, %r422, %r4199, %r417;
	// end inline asm
	ld.const.u32 	%r426, [matrix+292];
	// begin inline asm
	dp4a.u32.u32 %r425, %r426, %r4203, %r421;
	// end inline asm
	ld.const.u32 	%r430, [matrix+296];
	// begin inline asm
	dp4a.u32.u32 %r429, %r430, %r4207, %r425;
	// end inline asm
	ld.const.u32 	%r434, [matrix+300];
	// begin inline asm
	dp4a.u32.u32 %r433, %r434, %r4211, %r429;
	// end inline asm
	ld.const.u32 	%r438, [matrix+304];
	// begin inline asm
	dp4a.u32.u32 %r437, %r438, %r4215, %r433;
	// end inline asm
	ld.const.u32 	%r442, [matrix+308];
	// begin inline asm
	dp4a.u32.u32 %r441, %r442, %r4219, %r437;
	// end inline asm
	ld.const.u32 	%r446, [matrix+312];
	// begin inline asm
	dp4a.u32.u32 %r445, %r446, %r4223, %r441;
	// end inline asm
	ld.const.u32 	%r450, [matrix+316];
	// begin inline asm
	dp4a.u32.u32 %r449, %r450, %r4227, %r445;
	// end inline asm
	ld.const.u32 	%r454, [matrix+320];
	// begin inline asm
	dp4a.u32.u32 %r453, %r454, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r458, [matrix+324];
	// begin inline asm
	dp4a.u32.u32 %r457, %r458, %r4171, %r453;
	// end inline asm
	ld.const.u32 	%r462, [matrix+328];
	// begin inline asm
	dp4a.u32.u32 %r461, %r462, %r4175, %r457;
	// end inline asm
	ld.const.u32 	%r466, [matrix+332];
	// begin inline asm
	dp4a.u32.u32 %r465, %r466, %r4179, %r461;
	// end inline asm
	ld.const.u32 	%r470, [matrix+336];
	// begin inline asm
	dp4a.u32.u32 %r469, %r470, %r4183, %r465;
	// end inline asm
	ld.const.u32 	%r474, [matrix+340];
	// begin inline asm
	dp4a.u32.u32 %r473, %r474, %r4187, %r469;
	// end inline asm
	ld.const.u32 	%r478, [matrix+344];
	// begin inline asm
	dp4a.u32.u32 %r477, %r478, %r4191, %r473;
	// end inline asm
	ld.const.u32 	%r482, [matrix+348];
	// begin inline asm
	dp4a.u32.u32 %r481, %r482, %r4195, %r477;
	// end inline asm
	ld.const.u32 	%r486, [matrix+352];
	// begin inline asm
	dp4a.u32.u32 %r485, %r486, %r4199, %r481;
	// end inline asm
	ld.const.u32 	%r490, [matrix+356];
	// begin inline asm
	dp4a.u32.u32 %r489, %r490, %r4203, %r485;
	// end inline asm
	ld.const.u32 	%r494, [matrix+360];
	// begin inline asm
	dp4a.u32.u32 %r493, %r494, %r4207, %r489;
	// end inline asm
	ld.const.u32 	%r498, [matrix+364];
	// begin inline asm
	dp4a.u32.u32 %r497, %r498, %r4211, %r493;
	// end inline asm
	ld.const.u32 	%r502, [matrix+368];
	// begin inline asm
	dp4a.u32.u32 %r501, %r502, %r4215, %r497;
	// end inline asm
	ld.const.u32 	%r506, [matrix+372];
	// begin inline asm
	dp4a.u32.u32 %r505, %r506, %r4219, %r501;
	// end inline asm
	ld.const.u32 	%r510, [matrix+376];
	// begin inline asm
	dp4a.u32.u32 %r509, %r510, %r4223, %r505;
	// end inline asm
	ld.const.u32 	%r514, [matrix+380];
	// begin inline asm
	dp4a.u32.u32 %r513, %r514, %r4227, %r509;
	// end inline asm
	shr.u32 	%r4406, %r449, 6;
	and.b32  	%r4407, %r4406, 240;
	shr.u32 	%r4408, %r513, 10;
	or.b32  	%r4409, %r4408, %r4407;
	cvt.u64.u32 	%rd380, %r4409;
	xor.b64  	%rd381, %rd337, %rd380;
	ld.const.u32 	%r518, [matrix+384];
	// begin inline asm
	dp4a.u32.u32 %r517, %r518, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r522, [matrix+388];
	// begin inline asm
	dp4a.u32.u32 %r521, %r522, %r4171, %r517;
	// end inline asm
	ld.const.u32 	%r526, [matrix+392];
	// begin inline asm
	dp4a.u32.u32 %r525, %r526, %r4175, %r521;
	// end inline asm
	ld.const.u32 	%r530, [matrix+396];
	// begin inline asm
	dp4a.u32.u32 %r529, %r530, %r4179, %r525;
	// end inline asm
	ld.const.u32 	%r534, [matrix+400];
	// begin inline asm
	dp4a.u32.u32 %r533, %r534, %r4183, %r529;
	// end inline asm
	ld.const.u32 	%r538, [matrix+404];
	// begin inline asm
	dp4a.u32.u32 %r537, %r538, %r4187, %r533;
	// end inline asm
	ld.const.u32 	%r542, [matrix+408];
	// begin inline asm
	dp4a.u32.u32 %r541, %r542, %r4191, %r537;
	// end inline asm
	ld.const.u32 	%r546, [matrix+412];
	// begin inline asm
	dp4a.u32.u32 %r545, %r546, %r4195, %r541;
	// end inline asm
	ld.const.u32 	%r550, [matrix+416];
	// begin inline asm
	dp4a.u32.u32 %r549, %r550, %r4199, %r545;
	// end inline asm
	ld.const.u32 	%r554, [matrix+420];
	// begin inline asm
	dp4a.u32.u32 %r553, %r554, %r4203, %r549;
	// end inline asm
	ld.const.u32 	%r558, [matrix+424];
	// begin inline asm
	dp4a.u32.u32 %r557, %r558, %r4207, %r553;
	// end inline asm
	ld.const.u32 	%r562, [matrix+428];
	// begin inline asm
	dp4a.u32.u32 %r561, %r562, %r4211, %r557;
	// end inline asm
	ld.const.u32 	%r566, [matrix+432];
	// begin inline asm
	dp4a.u32.u32 %r565, %r566, %r4215, %r561;
	// end inline asm
	ld.const.u32 	%r570, [matrix+436];
	// begin inline asm
	dp4a.u32.u32 %r569, %r570, %r4219, %r565;
	// end inline asm
	ld.const.u32 	%r574, [matrix+440];
	// begin inline asm
	dp4a.u32.u32 %r573, %r574, %r4223, %r569;
	// end inline asm
	ld.const.u32 	%r578, [matrix+444];
	// begin inline asm
	dp4a.u32.u32 %r577, %r578, %r4227, %r573;
	// end inline asm
	ld.const.u32 	%r582, [matrix+448];
	// begin inline asm
	dp4a.u32.u32 %r581, %r582, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r586, [matrix+452];
	// begin inline asm
	dp4a.u32.u32 %r585, %r586, %r4171, %r581;
	// end inline asm
	ld.const.u32 	%r590, [matrix+456];
	// begin inline asm
	dp4a.u32.u32 %r589, %r590, %r4175, %r585;
	// end inline asm
	ld.const.u32 	%r594, [matrix+460];
	// begin inline asm
	dp4a.u32.u32 %r593, %r594, %r4179, %r589;
	// end inline asm
	ld.const.u32 	%r598, [matrix+464];
	// begin inline asm
	dp4a.u32.u32 %r597, %r598, %r4183, %r593;
	// end inline asm
	ld.const.u32 	%r602, [matrix+468];
	// begin inline asm
	dp4a.u32.u32 %r601, %r602, %r4187, %r597;
	// end inline asm
	ld.const.u32 	%r606, [matrix+472];
	// begin inline asm
	dp4a.u32.u32 %r605, %r606, %r4191, %r601;
	// end inline asm
	ld.const.u32 	%r610, [matrix+476];
	// begin inline asm
	dp4a.u32.u32 %r609, %r610, %r4195, %r605;
	// end inline asm
	ld.const.u32 	%r614, [matrix+480];
	// begin inline asm
	dp4a.u32.u32 %r613, %r614, %r4199, %r609;
	// end inline asm
	ld.const.u32 	%r618, [matrix+484];
	// begin inline asm
	dp4a.u32.u32 %r617, %r618, %r4203, %r613;
	// end inline asm
	ld.const.u32 	%r622, [matrix+488];
	// begin inline asm
	dp4a.u32.u32 %r621, %r622, %r4207, %r617;
	// end inline asm
	ld.const.u32 	%r626, [matrix+492];
	// begin inline asm
	dp4a.u32.u32 %r625, %r626, %r4211, %r621;
	// end inline asm
	ld.const.u32 	%r630, [matrix+496];
	// begin inline asm
	dp4a.u32.u32 %r629, %r630, %r4215, %r625;
	// end inline asm
	ld.const.u32 	%r634, [matrix+500];
	// begin inline asm
	dp4a.u32.u32 %r633, %r634, %r4219, %r629;
	// end inline asm
	ld.const.u32 	%r638, [matrix+504];
	// begin inline asm
	dp4a.u32.u32 %r637, %r638, %r4223, %r633;
	// end inline asm
	ld.const.u32 	%r642, [matrix+508];
	// begin inline asm
	dp4a.u32.u32 %r641, %r642, %r4227, %r637;
	// end inline asm
	shr.u32 	%r4410, %r577, 6;
	and.b32  	%r4411, %r4410, 240;
	shr.u32 	%r4412, %r641, 10;
	or.b32  	%r4413, %r4412, %r4411;
	cvt.u64.u32 	%rd382, %r4413;
	xor.b64  	%rd383, %rd338, %rd382;
	ld.const.u32 	%r646, [matrix+512];
	// begin inline asm
	dp4a.u32.u32 %r645, %r646, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r650, [matrix+516];
	// begin inline asm
	dp4a.u32.u32 %r649, %r650, %r4171, %r645;
	// end inline asm
	ld.const.u32 	%r654, [matrix+520];
	// begin inline asm
	dp4a.u32.u32 %r653, %r654, %r4175, %r649;
	// end inline asm
	ld.const.u32 	%r658, [matrix+524];
	// begin inline asm
	dp4a.u32.u32 %r657, %r658, %r4179, %r653;
	// end inline asm
	ld.const.u32 	%r662, [matrix+528];
	// begin inline asm
	dp4a.u32.u32 %r661, %r662, %r4183, %r657;
	// end inline asm
	ld.const.u32 	%r666, [matrix+532];
	// begin inline asm
	dp4a.u32.u32 %r665, %r666, %r4187, %r661;
	// end inline asm
	ld.const.u32 	%r670, [matrix+536];
	// begin inline asm
	dp4a.u32.u32 %r669, %r670, %r4191, %r665;
	// end inline asm
	ld.const.u32 	%r674, [matrix+540];
	// begin inline asm
	dp4a.u32.u32 %r673, %r674, %r4195, %r669;
	// end inline asm
	ld.const.u32 	%r678, [matrix+544];
	// begin inline asm
	dp4a.u32.u32 %r677, %r678, %r4199, %r673;
	// end inline asm
	ld.const.u32 	%r682, [matrix+548];
	// begin inline asm
	dp4a.u32.u32 %r681, %r682, %r4203, %r677;
	// end inline asm
	ld.const.u32 	%r686, [matrix+552];
	// begin inline asm
	dp4a.u32.u32 %r685, %r686, %r4207, %r681;
	// end inline asm
	ld.const.u32 	%r690, [matrix+556];
	// begin inline asm
	dp4a.u32.u32 %r689, %r690, %r4211, %r685;
	// end inline asm
	ld.const.u32 	%r694, [matrix+560];
	// begin inline asm
	dp4a.u32.u32 %r693, %r694, %r4215, %r689;
	// end inline asm
	ld.const.u32 	%r698, [matrix+564];
	// begin inline asm
	dp4a.u32.u32 %r697, %r698, %r4219, %r693;
	// end inline asm
	ld.const.u32 	%r702, [matrix+568];
	// begin inline asm
	dp4a.u32.u32 %r701, %r702, %r4223, %r697;
	// end inline asm
	ld.const.u32 	%r706, [matrix+572];
	// begin inline asm
	dp4a.u32.u32 %r705, %r706, %r4227, %r701;
	// end inline asm
	ld.const.u32 	%r710, [matrix+576];
	// begin inline asm
	dp4a.u32.u32 %r709, %r710, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r714, [matrix+580];
	// begin inline asm
	dp4a.u32.u32 %r713, %r714, %r4171, %r709;
	// end inline asm
	ld.const.u32 	%r718, [matrix+584];
	// begin inline asm
	dp4a.u32.u32 %r717, %r718, %r4175, %r713;
	// end inline asm
	ld.const.u32 	%r722, [matrix+588];
	// begin inline asm
	dp4a.u32.u32 %r721, %r722, %r4179, %r717;
	// end inline asm
	ld.const.u32 	%r726, [matrix+592];
	// begin inline asm
	dp4a.u32.u32 %r725, %r726, %r4183, %r721;
	// end inline asm
	ld.const.u32 	%r730, [matrix+596];
	// begin inline asm
	dp4a.u32.u32 %r729, %r730, %r4187, %r725;
	// end inline asm
	ld.const.u32 	%r734, [matrix+600];
	// begin inline asm
	dp4a.u32.u32 %r733, %r734, %r4191, %r729;
	// end inline asm
	ld.const.u32 	%r738, [matrix+604];
	// begin inline asm
	dp4a.u32.u32 %r737, %r738, %r4195, %r733;
	// end inline asm
	ld.const.u32 	%r742, [matrix+608];
	// begin inline asm
	dp4a.u32.u32 %r741, %r742, %r4199, %r737;
	// end inline asm
	ld.const.u32 	%r746, [matrix+612];
	// begin inline asm
	dp4a.u32.u32 %r745, %r746, %r4203, %r741;
	// end inline asm
	ld.const.u32 	%r750, [matrix+616];
	// begin inline asm
	dp4a.u32.u32 %r749, %r750, %r4207, %r745;
	// end inline asm
	ld.const.u32 	%r754, [matrix+620];
	// begin inline asm
	dp4a.u32.u32 %r753, %r754, %r4211, %r749;
	// end inline asm
	ld.const.u32 	%r758, [matrix+624];
	// begin inline asm
	dp4a.u32.u32 %r757, %r758, %r4215, %r753;
	// end inline asm
	ld.const.u32 	%r762, [matrix+628];
	// begin inline asm
	dp4a.u32.u32 %r761, %r762, %r4219, %r757;
	// end inline asm
	ld.const.u32 	%r766, [matrix+632];
	// begin inline asm
	dp4a.u32.u32 %r765, %r766, %r4223, %r761;
	// end inline asm
	ld.const.u32 	%r770, [matrix+636];
	// begin inline asm
	dp4a.u32.u32 %r769, %r770, %r4227, %r765;
	// end inline asm
	shr.u32 	%r4414, %r705, 6;
	and.b32  	%r4415, %r4414, 240;
	shr.u32 	%r4416, %r769, 10;
	or.b32  	%r4417, %r4416, %r4415;
	cvt.u64.u32 	%rd384, %r4417;
	xor.b64  	%rd385, %rd339, %rd384;
	ld.const.u32 	%r774, [matrix+640];
	// begin inline asm
	dp4a.u32.u32 %r773, %r774, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r778, [matrix+644];
	// begin inline asm
	dp4a.u32.u32 %r777, %r778, %r4171, %r773;
	// end inline asm
	ld.const.u32 	%r782, [matrix+648];
	// begin inline asm
	dp4a.u32.u32 %r781, %r782, %r4175, %r777;
	// end inline asm
	ld.const.u32 	%r786, [matrix+652];
	// begin inline asm
	dp4a.u32.u32 %r785, %r786, %r4179, %r781;
	// end inline asm
	ld.const.u32 	%r790, [matrix+656];
	// begin inline asm
	dp4a.u32.u32 %r789, %r790, %r4183, %r785;
	// end inline asm
	ld.const.u32 	%r794, [matrix+660];
	// begin inline asm
	dp4a.u32.u32 %r793, %r794, %r4187, %r789;
	// end inline asm
	ld.const.u32 	%r798, [matrix+664];
	// begin inline asm
	dp4a.u32.u32 %r797, %r798, %r4191, %r793;
	// end inline asm
	ld.const.u32 	%r802, [matrix+668];
	// begin inline asm
	dp4a.u32.u32 %r801, %r802, %r4195, %r797;
	// end inline asm
	ld.const.u32 	%r806, [matrix+672];
	// begin inline asm
	dp4a.u32.u32 %r805, %r806, %r4199, %r801;
	// end inline asm
	ld.const.u32 	%r810, [matrix+676];
	// begin inline asm
	dp4a.u32.u32 %r809, %r810, %r4203, %r805;
	// end inline asm
	ld.const.u32 	%r814, [matrix+680];
	// begin inline asm
	dp4a.u32.u32 %r813, %r814, %r4207, %r809;
	// end inline asm
	ld.const.u32 	%r818, [matrix+684];
	// begin inline asm
	dp4a.u32.u32 %r817, %r818, %r4211, %r813;
	// end inline asm
	ld.const.u32 	%r822, [matrix+688];
	// begin inline asm
	dp4a.u32.u32 %r821, %r822, %r4215, %r817;
	// end inline asm
	ld.const.u32 	%r826, [matrix+692];
	// begin inline asm
	dp4a.u32.u32 %r825, %r826, %r4219, %r821;
	// end inline asm
	ld.const.u32 	%r830, [matrix+696];
	// begin inline asm
	dp4a.u32.u32 %r829, %r830, %r4223, %r825;
	// end inline asm
	ld.const.u32 	%r834, [matrix+700];
	// begin inline asm
	dp4a.u32.u32 %r833, %r834, %r4227, %r829;
	// end inline asm
	ld.const.u32 	%r838, [matrix+704];
	// begin inline asm
	dp4a.u32.u32 %r837, %r838, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r842, [matrix+708];
	// begin inline asm
	dp4a.u32.u32 %r841, %r842, %r4171, %r837;
	// end inline asm
	ld.const.u32 	%r846, [matrix+712];
	// begin inline asm
	dp4a.u32.u32 %r845, %r846, %r4175, %r841;
	// end inline asm
	ld.const.u32 	%r850, [matrix+716];
	// begin inline asm
	dp4a.u32.u32 %r849, %r850, %r4179, %r845;
	// end inline asm
	ld.const.u32 	%r854, [matrix+720];
	// begin inline asm
	dp4a.u32.u32 %r853, %r854, %r4183, %r849;
	// end inline asm
	ld.const.u32 	%r858, [matrix+724];
	// begin inline asm
	dp4a.u32.u32 %r857, %r858, %r4187, %r853;
	// end inline asm
	ld.const.u32 	%r862, [matrix+728];
	// begin inline asm
	dp4a.u32.u32 %r861, %r862, %r4191, %r857;
	// end inline asm
	ld.const.u32 	%r866, [matrix+732];
	// begin inline asm
	dp4a.u32.u32 %r865, %r866, %r4195, %r861;
	// end inline asm
	ld.const.u32 	%r870, [matrix+736];
	// begin inline asm
	dp4a.u32.u32 %r869, %r870, %r4199, %r865;
	// end inline asm
	ld.const.u32 	%r874, [matrix+740];
	// begin inline asm
	dp4a.u32.u32 %r873, %r874, %r4203, %r869;
	// end inline asm
	ld.const.u32 	%r878, [matrix+744];
	// begin inline asm
	dp4a.u32.u32 %r877, %r878, %r4207, %r873;
	// end inline asm
	ld.const.u32 	%r882, [matrix+748];
	// begin inline asm
	dp4a.u32.u32 %r881, %r882, %r4211, %r877;
	// end inline asm
	ld.const.u32 	%r886, [matrix+752];
	// begin inline asm
	dp4a.u32.u32 %r885, %r886, %r4215, %r881;
	// end inline asm
	ld.const.u32 	%r890, [matrix+756];
	// begin inline asm
	dp4a.u32.u32 %r889, %r890, %r4219, %r885;
	// end inline asm
	ld.const.u32 	%r894, [matrix+760];
	// begin inline asm
	dp4a.u32.u32 %r893, %r894, %r4223, %r889;
	// end inline asm
	ld.const.u32 	%r898, [matrix+764];
	// begin inline asm
	dp4a.u32.u32 %r897, %r898, %r4227, %r893;
	// end inline asm
	shr.u32 	%r4418, %r833, 6;
	and.b32  	%r4419, %r4418, 240;
	shr.u32 	%r4420, %r897, 10;
	or.b32  	%r4421, %r4420, %r4419;
	cvt.u64.u32 	%rd386, %r4421;
	xor.b64  	%rd387, %rd340, %rd386;
	ld.const.u32 	%r902, [matrix+768];
	// begin inline asm
	dp4a.u32.u32 %r901, %r902, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r906, [matrix+772];
	// begin inline asm
	dp4a.u32.u32 %r905, %r906, %r4171, %r901;
	// end inline asm
	ld.const.u32 	%r910, [matrix+776];
	// begin inline asm
	dp4a.u32.u32 %r909, %r910, %r4175, %r905;
	// end inline asm
	ld.const.u32 	%r914, [matrix+780];
	// begin inline asm
	dp4a.u32.u32 %r913, %r914, %r4179, %r909;
	// end inline asm
	ld.const.u32 	%r918, [matrix+784];
	// begin inline asm
	dp4a.u32.u32 %r917, %r918, %r4183, %r913;
	// end inline asm
	ld.const.u32 	%r922, [matrix+788];
	// begin inline asm
	dp4a.u32.u32 %r921, %r922, %r4187, %r917;
	// end inline asm
	ld.const.u32 	%r926, [matrix+792];
	// begin inline asm
	dp4a.u32.u32 %r925, %r926, %r4191, %r921;
	// end inline asm
	ld.const.u32 	%r930, [matrix+796];
	// begin inline asm
	dp4a.u32.u32 %r929, %r930, %r4195, %r925;
	// end inline asm
	ld.const.u32 	%r934, [matrix+800];
	// begin inline asm
	dp4a.u32.u32 %r933, %r934, %r4199, %r929;
	// end inline asm
	ld.const.u32 	%r938, [matrix+804];
	// begin inline asm
	dp4a.u32.u32 %r937, %r938, %r4203, %r933;
	// end inline asm
	ld.const.u32 	%r942, [matrix+808];
	// begin inline asm
	dp4a.u32.u32 %r941, %r942, %r4207, %r937;
	// end inline asm
	ld.const.u32 	%r946, [matrix+812];
	// begin inline asm
	dp4a.u32.u32 %r945, %r946, %r4211, %r941;
	// end inline asm
	ld.const.u32 	%r950, [matrix+816];
	// begin inline asm
	dp4a.u32.u32 %r949, %r950, %r4215, %r945;
	// end inline asm
	ld.const.u32 	%r954, [matrix+820];
	// begin inline asm
	dp4a.u32.u32 %r953, %r954, %r4219, %r949;
	// end inline asm
	ld.const.u32 	%r958, [matrix+824];
	// begin inline asm
	dp4a.u32.u32 %r957, %r958, %r4223, %r953;
	// end inline asm
	ld.const.u32 	%r962, [matrix+828];
	// begin inline asm
	dp4a.u32.u32 %r961, %r962, %r4227, %r957;
	// end inline asm
	ld.const.u32 	%r966, [matrix+832];
	// begin inline asm
	dp4a.u32.u32 %r965, %r966, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r970, [matrix+836];
	// begin inline asm
	dp4a.u32.u32 %r969, %r970, %r4171, %r965;
	// end inline asm
	ld.const.u32 	%r974, [matrix+840];
	// begin inline asm
	dp4a.u32.u32 %r973, %r974, %r4175, %r969;
	// end inline asm
	ld.const.u32 	%r978, [matrix+844];
	// begin inline asm
	dp4a.u32.u32 %r977, %r978, %r4179, %r973;
	// end inline asm
	ld.const.u32 	%r982, [matrix+848];
	// begin inline asm
	dp4a.u32.u32 %r981, %r982, %r4183, %r977;
	// end inline asm
	ld.const.u32 	%r986, [matrix+852];
	// begin inline asm
	dp4a.u32.u32 %r985, %r986, %r4187, %r981;
	// end inline asm
	ld.const.u32 	%r990, [matrix+856];
	// begin inline asm
	dp4a.u32.u32 %r989, %r990, %r4191, %r985;
	// end inline asm
	ld.const.u32 	%r994, [matrix+860];
	// begin inline asm
	dp4a.u32.u32 %r993, %r994, %r4195, %r989;
	// end inline asm
	ld.const.u32 	%r998, [matrix+864];
	// begin inline asm
	dp4a.u32.u32 %r997, %r998, %r4199, %r993;
	// end inline asm
	ld.const.u32 	%r1002, [matrix+868];
	// begin inline asm
	dp4a.u32.u32 %r1001, %r1002, %r4203, %r997;
	// end inline asm
	ld.const.u32 	%r1006, [matrix+872];
	// begin inline asm
	dp4a.u32.u32 %r1005, %r1006, %r4207, %r1001;
	// end inline asm
	ld.const.u32 	%r1010, [matrix+876];
	// begin inline asm
	dp4a.u32.u32 %r1009, %r1010, %r4211, %r1005;
	// end inline asm
	ld.const.u32 	%r1014, [matrix+880];
	// begin inline asm
	dp4a.u32.u32 %r1013, %r1014, %r4215, %r1009;
	// end inline asm
	ld.const.u32 	%r1018, [matrix+884];
	// begin inline asm
	dp4a.u32.u32 %r1017, %r1018, %r4219, %r1013;
	// end inline asm
	ld.const.u32 	%r1022, [matrix+888];
	// begin inline asm
	dp4a.u32.u32 %r1021, %r1022, %r4223, %r1017;
	// end inline asm
	ld.const.u32 	%r1026, [matrix+892];
	// begin inline asm
	dp4a.u32.u32 %r1025, %r1026, %r4227, %r1021;
	// end inline asm
	shr.u32 	%r4422, %r961, 6;
	and.b32  	%r4423, %r4422, 240;
	shr.u32 	%r4424, %r1025, 10;
	or.b32  	%r4425, %r4424, %r4423;
	cvt.u64.u32 	%rd388, %r4425;
	xor.b64  	%rd389, %rd341, %rd388;
	ld.const.u32 	%r1030, [matrix+896];
	// begin inline asm
	dp4a.u32.u32 %r1029, %r1030, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1034, [matrix+900];
	// begin inline asm
	dp4a.u32.u32 %r1033, %r1034, %r4171, %r1029;
	// end inline asm
	ld.const.u32 	%r1038, [matrix+904];
	// begin inline asm
	dp4a.u32.u32 %r1037, %r1038, %r4175, %r1033;
	// end inline asm
	ld.const.u32 	%r1042, [matrix+908];
	// begin inline asm
	dp4a.u32.u32 %r1041, %r1042, %r4179, %r1037;
	// end inline asm
	ld.const.u32 	%r1046, [matrix+912];
	// begin inline asm
	dp4a.u32.u32 %r1045, %r1046, %r4183, %r1041;
	// end inline asm
	ld.const.u32 	%r1050, [matrix+916];
	// begin inline asm
	dp4a.u32.u32 %r1049, %r1050, %r4187, %r1045;
	// end inline asm
	ld.const.u32 	%r1054, [matrix+920];
	// begin inline asm
	dp4a.u32.u32 %r1053, %r1054, %r4191, %r1049;
	// end inline asm
	ld.const.u32 	%r1058, [matrix+924];
	// begin inline asm
	dp4a.u32.u32 %r1057, %r1058, %r4195, %r1053;
	// end inline asm
	ld.const.u32 	%r1062, [matrix+928];
	// begin inline asm
	dp4a.u32.u32 %r1061, %r1062, %r4199, %r1057;
	// end inline asm
	ld.const.u32 	%r1066, [matrix+932];
	// begin inline asm
	dp4a.u32.u32 %r1065, %r1066, %r4203, %r1061;
	// end inline asm
	ld.const.u32 	%r1070, [matrix+936];
	// begin inline asm
	dp4a.u32.u32 %r1069, %r1070, %r4207, %r1065;
	// end inline asm
	ld.const.u32 	%r1074, [matrix+940];
	// begin inline asm
	dp4a.u32.u32 %r1073, %r1074, %r4211, %r1069;
	// end inline asm
	ld.const.u32 	%r1078, [matrix+944];
	// begin inline asm
	dp4a.u32.u32 %r1077, %r1078, %r4215, %r1073;
	// end inline asm
	ld.const.u32 	%r1082, [matrix+948];
	// begin inline asm
	dp4a.u32.u32 %r1081, %r1082, %r4219, %r1077;
	// end inline asm
	ld.const.u32 	%r1086, [matrix+952];
	// begin inline asm
	dp4a.u32.u32 %r1085, %r1086, %r4223, %r1081;
	// end inline asm
	ld.const.u32 	%r1090, [matrix+956];
	// begin inline asm
	dp4a.u32.u32 %r1089, %r1090, %r4227, %r1085;
	// end inline asm
	ld.const.u32 	%r1094, [matrix+960];
	// begin inline asm
	dp4a.u32.u32 %r1093, %r1094, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1098, [matrix+964];
	// begin inline asm
	dp4a.u32.u32 %r1097, %r1098, %r4171, %r1093;
	// end inline asm
	ld.const.u32 	%r1102, [matrix+968];
	// begin inline asm
	dp4a.u32.u32 %r1101, %r1102, %r4175, %r1097;
	// end inline asm
	ld.const.u32 	%r1106, [matrix+972];
	// begin inline asm
	dp4a.u32.u32 %r1105, %r1106, %r4179, %r1101;
	// end inline asm
	ld.const.u32 	%r1110, [matrix+976];
	// begin inline asm
	dp4a.u32.u32 %r1109, %r1110, %r4183, %r1105;
	// end inline asm
	ld.const.u32 	%r1114, [matrix+980];
	// begin inline asm
	dp4a.u32.u32 %r1113, %r1114, %r4187, %r1109;
	// end inline asm
	ld.const.u32 	%r1118, [matrix+984];
	// begin inline asm
	dp4a.u32.u32 %r1117, %r1118, %r4191, %r1113;
	// end inline asm
	ld.const.u32 	%r1122, [matrix+988];
	// begin inline asm
	dp4a.u32.u32 %r1121, %r1122, %r4195, %r1117;
	// end inline asm
	ld.const.u32 	%r1126, [matrix+992];
	// begin inline asm
	dp4a.u32.u32 %r1125, %r1126, %r4199, %r1121;
	// end inline asm
	ld.const.u32 	%r1130, [matrix+996];
	// begin inline asm
	dp4a.u32.u32 %r1129, %r1130, %r4203, %r1125;
	// end inline asm
	ld.const.u32 	%r1134, [matrix+1000];
	// begin inline asm
	dp4a.u32.u32 %r1133, %r1134, %r4207, %r1129;
	// end inline asm
	ld.const.u32 	%r1138, [matrix+1004];
	// begin inline asm
	dp4a.u32.u32 %r1137, %r1138, %r4211, %r1133;
	// end inline asm
	ld.const.u32 	%r1142, [matrix+1008];
	// begin inline asm
	dp4a.u32.u32 %r1141, %r1142, %r4215, %r1137;
	// end inline asm
	ld.const.u32 	%r1146, [matrix+1012];
	// begin inline asm
	dp4a.u32.u32 %r1145, %r1146, %r4219, %r1141;
	// end inline asm
	ld.const.u32 	%r1150, [matrix+1016];
	// begin inline asm
	dp4a.u32.u32 %r1149, %r1150, %r4223, %r1145;
	// end inline asm
	ld.const.u32 	%r1154, [matrix+1020];
	// begin inline asm
	dp4a.u32.u32 %r1153, %r1154, %r4227, %r1149;
	// end inline asm
	shr.u32 	%r4426, %r1089, 6;
	and.b32  	%r4427, %r4426, 240;
	shr.u32 	%r4428, %r1153, 10;
	or.b32  	%r4429, %r4428, %r4427;
	cvt.u64.u32 	%rd390, %r4429;
	ld.const.u32 	%r1158, [matrix+1024];
	// begin inline asm
	dp4a.u32.u32 %r1157, %r1158, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1162, [matrix+1028];
	// begin inline asm
	dp4a.u32.u32 %r1161, %r1162, %r4171, %r1157;
	// end inline asm
	ld.const.u32 	%r1166, [matrix+1032];
	// begin inline asm
	dp4a.u32.u32 %r1165, %r1166, %r4175, %r1161;
	// end inline asm
	ld.const.u32 	%r1170, [matrix+1036];
	// begin inline asm
	dp4a.u32.u32 %r1169, %r1170, %r4179, %r1165;
	// end inline asm
	ld.const.u32 	%r1174, [matrix+1040];
	// begin inline asm
	dp4a.u32.u32 %r1173, %r1174, %r4183, %r1169;
	// end inline asm
	ld.const.u32 	%r1178, [matrix+1044];
	// begin inline asm
	dp4a.u32.u32 %r1177, %r1178, %r4187, %r1173;
	// end inline asm
	ld.const.u32 	%r1182, [matrix+1048];
	// begin inline asm
	dp4a.u32.u32 %r1181, %r1182, %r4191, %r1177;
	// end inline asm
	ld.const.u32 	%r1186, [matrix+1052];
	// begin inline asm
	dp4a.u32.u32 %r1185, %r1186, %r4195, %r1181;
	// end inline asm
	ld.const.u32 	%r1190, [matrix+1056];
	// begin inline asm
	dp4a.u32.u32 %r1189, %r1190, %r4199, %r1185;
	// end inline asm
	ld.const.u32 	%r1194, [matrix+1060];
	// begin inline asm
	dp4a.u32.u32 %r1193, %r1194, %r4203, %r1189;
	// end inline asm
	ld.const.u32 	%r1198, [matrix+1064];
	// begin inline asm
	dp4a.u32.u32 %r1197, %r1198, %r4207, %r1193;
	// end inline asm
	ld.const.u32 	%r1202, [matrix+1068];
	// begin inline asm
	dp4a.u32.u32 %r1201, %r1202, %r4211, %r1197;
	// end inline asm
	ld.const.u32 	%r1206, [matrix+1072];
	// begin inline asm
	dp4a.u32.u32 %r1205, %r1206, %r4215, %r1201;
	// end inline asm
	ld.const.u32 	%r1210, [matrix+1076];
	// begin inline asm
	dp4a.u32.u32 %r1209, %r1210, %r4219, %r1205;
	// end inline asm
	ld.const.u32 	%r1214, [matrix+1080];
	// begin inline asm
	dp4a.u32.u32 %r1213, %r1214, %r4223, %r1209;
	// end inline asm
	ld.const.u32 	%r1218, [matrix+1084];
	// begin inline asm
	dp4a.u32.u32 %r1217, %r1218, %r4227, %r1213;
	// end inline asm
	ld.const.u32 	%r1222, [matrix+1088];
	// begin inline asm
	dp4a.u32.u32 %r1221, %r1222, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1226, [matrix+1092];
	// begin inline asm
	dp4a.u32.u32 %r1225, %r1226, %r4171, %r1221;
	// end inline asm
	ld.const.u32 	%r1230, [matrix+1096];
	// begin inline asm
	dp4a.u32.u32 %r1229, %r1230, %r4175, %r1225;
	// end inline asm
	ld.const.u32 	%r1234, [matrix+1100];
	// begin inline asm
	dp4a.u32.u32 %r1233, %r1234, %r4179, %r1229;
	// end inline asm
	ld.const.u32 	%r1238, [matrix+1104];
	// begin inline asm
	dp4a.u32.u32 %r1237, %r1238, %r4183, %r1233;
	// end inline asm
	ld.const.u32 	%r1242, [matrix+1108];
	// begin inline asm
	dp4a.u32.u32 %r1241, %r1242, %r4187, %r1237;
	// end inline asm
	ld.const.u32 	%r1246, [matrix+1112];
	// begin inline asm
	dp4a.u32.u32 %r1245, %r1246, %r4191, %r1241;
	// end inline asm
	ld.const.u32 	%r1250, [matrix+1116];
	// begin inline asm
	dp4a.u32.u32 %r1249, %r1250, %r4195, %r1245;
	// end inline asm
	ld.const.u32 	%r1254, [matrix+1120];
	// begin inline asm
	dp4a.u32.u32 %r1253, %r1254, %r4199, %r1249;
	// end inline asm
	ld.const.u32 	%r1258, [matrix+1124];
	// begin inline asm
	dp4a.u32.u32 %r1257, %r1258, %r4203, %r1253;
	// end inline asm
	ld.const.u32 	%r1262, [matrix+1128];
	// begin inline asm
	dp4a.u32.u32 %r1261, %r1262, %r4207, %r1257;
	// end inline asm
	ld.const.u32 	%r1266, [matrix+1132];
	// begin inline asm
	dp4a.u32.u32 %r1265, %r1266, %r4211, %r1261;
	// end inline asm
	ld.const.u32 	%r1270, [matrix+1136];
	// begin inline asm
	dp4a.u32.u32 %r1269, %r1270, %r4215, %r1265;
	// end inline asm
	ld.const.u32 	%r1274, [matrix+1140];
	// begin inline asm
	dp4a.u32.u32 %r1273, %r1274, %r4219, %r1269;
	// end inline asm
	ld.const.u32 	%r1278, [matrix+1144];
	// begin inline asm
	dp4a.u32.u32 %r1277, %r1278, %r4223, %r1273;
	// end inline asm
	ld.const.u32 	%r1282, [matrix+1148];
	// begin inline asm
	dp4a.u32.u32 %r1281, %r1282, %r4227, %r1277;
	// end inline asm
	shr.u32 	%r4430, %r1217, 6;
	and.b32  	%r4431, %r4430, 240;
	shr.u32 	%r4432, %r1281, 10;
	or.b32  	%r4433, %r4432, %r4431;
	cvt.u64.u32 	%rd391, %r4433;
	xor.b64  	%rd392, %rd680, %rd391;
	ld.const.u32 	%r1286, [matrix+1152];
	// begin inline asm
	dp4a.u32.u32 %r1285, %r1286, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1290, [matrix+1156];
	// begin inline asm
	dp4a.u32.u32 %r1289, %r1290, %r4171, %r1285;
	// end inline asm
	ld.const.u32 	%r1294, [matrix+1160];
	// begin inline asm
	dp4a.u32.u32 %r1293, %r1294, %r4175, %r1289;
	// end inline asm
	ld.const.u32 	%r1298, [matrix+1164];
	// begin inline asm
	dp4a.u32.u32 %r1297, %r1298, %r4179, %r1293;
	// end inline asm
	ld.const.u32 	%r1302, [matrix+1168];
	// begin inline asm
	dp4a.u32.u32 %r1301, %r1302, %r4183, %r1297;
	// end inline asm
	ld.const.u32 	%r1306, [matrix+1172];
	// begin inline asm
	dp4a.u32.u32 %r1305, %r1306, %r4187, %r1301;
	// end inline asm
	ld.const.u32 	%r1310, [matrix+1176];
	// begin inline asm
	dp4a.u32.u32 %r1309, %r1310, %r4191, %r1305;
	// end inline asm
	ld.const.u32 	%r1314, [matrix+1180];
	// begin inline asm
	dp4a.u32.u32 %r1313, %r1314, %r4195, %r1309;
	// end inline asm
	ld.const.u32 	%r1318, [matrix+1184];
	// begin inline asm
	dp4a.u32.u32 %r1317, %r1318, %r4199, %r1313;
	// end inline asm
	ld.const.u32 	%r1322, [matrix+1188];
	// begin inline asm
	dp4a.u32.u32 %r1321, %r1322, %r4203, %r1317;
	// end inline asm
	ld.const.u32 	%r1326, [matrix+1192];
	// begin inline asm
	dp4a.u32.u32 %r1325, %r1326, %r4207, %r1321;
	// end inline asm
	ld.const.u32 	%r1330, [matrix+1196];
	// begin inline asm
	dp4a.u32.u32 %r1329, %r1330, %r4211, %r1325;
	// end inline asm
	ld.const.u32 	%r1334, [matrix+1200];
	// begin inline asm
	dp4a.u32.u32 %r1333, %r1334, %r4215, %r1329;
	// end inline asm
	ld.const.u32 	%r1338, [matrix+1204];
	// begin inline asm
	dp4a.u32.u32 %r1337, %r1338, %r4219, %r1333;
	// end inline asm
	ld.const.u32 	%r1342, [matrix+1208];
	// begin inline asm
	dp4a.u32.u32 %r1341, %r1342, %r4223, %r1337;
	// end inline asm
	ld.const.u32 	%r1346, [matrix+1212];
	// begin inline asm
	dp4a.u32.u32 %r1345, %r1346, %r4227, %r1341;
	// end inline asm
	ld.const.u32 	%r1350, [matrix+1216];
	// begin inline asm
	dp4a.u32.u32 %r1349, %r1350, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1354, [matrix+1220];
	// begin inline asm
	dp4a.u32.u32 %r1353, %r1354, %r4171, %r1349;
	// end inline asm
	ld.const.u32 	%r1358, [matrix+1224];
	// begin inline asm
	dp4a.u32.u32 %r1357, %r1358, %r4175, %r1353;
	// end inline asm
	ld.const.u32 	%r1362, [matrix+1228];
	// begin inline asm
	dp4a.u32.u32 %r1361, %r1362, %r4179, %r1357;
	// end inline asm
	ld.const.u32 	%r1366, [matrix+1232];
	// begin inline asm
	dp4a.u32.u32 %r1365, %r1366, %r4183, %r1361;
	// end inline asm
	ld.const.u32 	%r1370, [matrix+1236];
	// begin inline asm
	dp4a.u32.u32 %r1369, %r1370, %r4187, %r1365;
	// end inline asm
	ld.const.u32 	%r1374, [matrix+1240];
	// begin inline asm
	dp4a.u32.u32 %r1373, %r1374, %r4191, %r1369;
	// end inline asm
	ld.const.u32 	%r1378, [matrix+1244];
	// begin inline asm
	dp4a.u32.u32 %r1377, %r1378, %r4195, %r1373;
	// end inline asm
	ld.const.u32 	%r1382, [matrix+1248];
	// begin inline asm
	dp4a.u32.u32 %r1381, %r1382, %r4199, %r1377;
	// end inline asm
	ld.const.u32 	%r1386, [matrix+1252];
	// begin inline asm
	dp4a.u32.u32 %r1385, %r1386, %r4203, %r1381;
	// end inline asm
	ld.const.u32 	%r1390, [matrix+1256];
	// begin inline asm
	dp4a.u32.u32 %r1389, %r1390, %r4207, %r1385;
	// end inline asm
	ld.const.u32 	%r1394, [matrix+1260];
	// begin inline asm
	dp4a.u32.u32 %r1393, %r1394, %r4211, %r1389;
	// end inline asm
	ld.const.u32 	%r1398, [matrix+1264];
	// begin inline asm
	dp4a.u32.u32 %r1397, %r1398, %r4215, %r1393;
	// end inline asm
	ld.const.u32 	%r1402, [matrix+1268];
	// begin inline asm
	dp4a.u32.u32 %r1401, %r1402, %r4219, %r1397;
	// end inline asm
	ld.const.u32 	%r1406, [matrix+1272];
	// begin inline asm
	dp4a.u32.u32 %r1405, %r1406, %r4223, %r1401;
	// end inline asm
	ld.const.u32 	%r1410, [matrix+1276];
	// begin inline asm
	dp4a.u32.u32 %r1409, %r1410, %r4227, %r1405;
	// end inline asm
	shr.u32 	%r4434, %r1345, 6;
	and.b32  	%r4435, %r4434, 240;
	shr.u32 	%r4436, %r1409, 10;
	or.b32  	%r4437, %r4436, %r4435;
	cvt.u64.u32 	%rd393, %r4437;
	xor.b64  	%rd394, %rd343, %rd393;
	ld.const.u32 	%r1414, [matrix+1280];
	// begin inline asm
	dp4a.u32.u32 %r1413, %r1414, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1418, [matrix+1284];
	// begin inline asm
	dp4a.u32.u32 %r1417, %r1418, %r4171, %r1413;
	// end inline asm
	ld.const.u32 	%r1422, [matrix+1288];
	// begin inline asm
	dp4a.u32.u32 %r1421, %r1422, %r4175, %r1417;
	// end inline asm
	ld.const.u32 	%r1426, [matrix+1292];
	// begin inline asm
	dp4a.u32.u32 %r1425, %r1426, %r4179, %r1421;
	// end inline asm
	ld.const.u32 	%r1430, [matrix+1296];
	// begin inline asm
	dp4a.u32.u32 %r1429, %r1430, %r4183, %r1425;
	// end inline asm
	ld.const.u32 	%r1434, [matrix+1300];
	// begin inline asm
	dp4a.u32.u32 %r1433, %r1434, %r4187, %r1429;
	// end inline asm
	ld.const.u32 	%r1438, [matrix+1304];
	// begin inline asm
	dp4a.u32.u32 %r1437, %r1438, %r4191, %r1433;
	// end inline asm
	ld.const.u32 	%r1442, [matrix+1308];
	// begin inline asm
	dp4a.u32.u32 %r1441, %r1442, %r4195, %r1437;
	// end inline asm
	ld.const.u32 	%r1446, [matrix+1312];
	// begin inline asm
	dp4a.u32.u32 %r1445, %r1446, %r4199, %r1441;
	// end inline asm
	ld.const.u32 	%r1450, [matrix+1316];
	// begin inline asm
	dp4a.u32.u32 %r1449, %r1450, %r4203, %r1445;
	// end inline asm
	ld.const.u32 	%r1454, [matrix+1320];
	// begin inline asm
	dp4a.u32.u32 %r1453, %r1454, %r4207, %r1449;
	// end inline asm
	ld.const.u32 	%r1458, [matrix+1324];
	// begin inline asm
	dp4a.u32.u32 %r1457, %r1458, %r4211, %r1453;
	// end inline asm
	ld.const.u32 	%r1462, [matrix+1328];
	// begin inline asm
	dp4a.u32.u32 %r1461, %r1462, %r4215, %r1457;
	// end inline asm
	ld.const.u32 	%r1466, [matrix+1332];
	// begin inline asm
	dp4a.u32.u32 %r1465, %r1466, %r4219, %r1461;
	// end inline asm
	ld.const.u32 	%r1470, [matrix+1336];
	// begin inline asm
	dp4a.u32.u32 %r1469, %r1470, %r4223, %r1465;
	// end inline asm
	ld.const.u32 	%r1474, [matrix+1340];
	// begin inline asm
	dp4a.u32.u32 %r1473, %r1474, %r4227, %r1469;
	// end inline asm
	ld.const.u32 	%r1478, [matrix+1344];
	// begin inline asm
	dp4a.u32.u32 %r1477, %r1478, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1482, [matrix+1348];
	// begin inline asm
	dp4a.u32.u32 %r1481, %r1482, %r4171, %r1477;
	// end inline asm
	ld.const.u32 	%r1486, [matrix+1352];
	// begin inline asm
	dp4a.u32.u32 %r1485, %r1486, %r4175, %r1481;
	// end inline asm
	ld.const.u32 	%r1490, [matrix+1356];
	// begin inline asm
	dp4a.u32.u32 %r1489, %r1490, %r4179, %r1485;
	// end inline asm
	ld.const.u32 	%r1494, [matrix+1360];
	// begin inline asm
	dp4a.u32.u32 %r1493, %r1494, %r4183, %r1489;
	// end inline asm
	ld.const.u32 	%r1498, [matrix+1364];
	// begin inline asm
	dp4a.u32.u32 %r1497, %r1498, %r4187, %r1493;
	// end inline asm
	ld.const.u32 	%r1502, [matrix+1368];
	// begin inline asm
	dp4a.u32.u32 %r1501, %r1502, %r4191, %r1497;
	// end inline asm
	ld.const.u32 	%r1506, [matrix+1372];
	// begin inline asm
	dp4a.u32.u32 %r1505, %r1506, %r4195, %r1501;
	// end inline asm
	ld.const.u32 	%r1510, [matrix+1376];
	// begin inline asm
	dp4a.u32.u32 %r1509, %r1510, %r4199, %r1505;
	// end inline asm
	ld.const.u32 	%r1514, [matrix+1380];
	// begin inline asm
	dp4a.u32.u32 %r1513, %r1514, %r4203, %r1509;
	// end inline asm
	ld.const.u32 	%r1518, [matrix+1384];
	// begin inline asm
	dp4a.u32.u32 %r1517, %r1518, %r4207, %r1513;
	// end inline asm
	ld.const.u32 	%r1522, [matrix+1388];
	// begin inline asm
	dp4a.u32.u32 %r1521, %r1522, %r4211, %r1517;
	// end inline asm
	ld.const.u32 	%r1526, [matrix+1392];
	// begin inline asm
	dp4a.u32.u32 %r1525, %r1526, %r4215, %r1521;
	// end inline asm
	ld.const.u32 	%r1530, [matrix+1396];
	// begin inline asm
	dp4a.u32.u32 %r1529, %r1530, %r4219, %r1525;
	// end inline asm
	ld.const.u32 	%r1534, [matrix+1400];
	// begin inline asm
	dp4a.u32.u32 %r1533, %r1534, %r4223, %r1529;
	// end inline asm
	ld.const.u32 	%r1538, [matrix+1404];
	// begin inline asm
	dp4a.u32.u32 %r1537, %r1538, %r4227, %r1533;
	// end inline asm
	shr.u32 	%r4438, %r1473, 6;
	and.b32  	%r4439, %r4438, 240;
	shr.u32 	%r4440, %r1537, 10;
	or.b32  	%r4441, %r4440, %r4439;
	cvt.u64.u32 	%rd395, %r4441;
	xor.b64  	%rd396, %rd344, %rd395;
	ld.const.u32 	%r1542, [matrix+1408];
	// begin inline asm
	dp4a.u32.u32 %r1541, %r1542, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1546, [matrix+1412];
	// begin inline asm
	dp4a.u32.u32 %r1545, %r1546, %r4171, %r1541;
	// end inline asm
	ld.const.u32 	%r1550, [matrix+1416];
	// begin inline asm
	dp4a.u32.u32 %r1549, %r1550, %r4175, %r1545;
	// end inline asm
	ld.const.u32 	%r1554, [matrix+1420];
	// begin inline asm
	dp4a.u32.u32 %r1553, %r1554, %r4179, %r1549;
	// end inline asm
	ld.const.u32 	%r1558, [matrix+1424];
	// begin inline asm
	dp4a.u32.u32 %r1557, %r1558, %r4183, %r1553;
	// end inline asm
	ld.const.u32 	%r1562, [matrix+1428];
	// begin inline asm
	dp4a.u32.u32 %r1561, %r1562, %r4187, %r1557;
	// end inline asm
	ld.const.u32 	%r1566, [matrix+1432];
	// begin inline asm
	dp4a.u32.u32 %r1565, %r1566, %r4191, %r1561;
	// end inline asm
	ld.const.u32 	%r1570, [matrix+1436];
	// begin inline asm
	dp4a.u32.u32 %r1569, %r1570, %r4195, %r1565;
	// end inline asm
	ld.const.u32 	%r1574, [matrix+1440];
	// begin inline asm
	dp4a.u32.u32 %r1573, %r1574, %r4199, %r1569;
	// end inline asm
	ld.const.u32 	%r1578, [matrix+1444];
	// begin inline asm
	dp4a.u32.u32 %r1577, %r1578, %r4203, %r1573;
	// end inline asm
	ld.const.u32 	%r1582, [matrix+1448];
	// begin inline asm
	dp4a.u32.u32 %r1581, %r1582, %r4207, %r1577;
	// end inline asm
	ld.const.u32 	%r1586, [matrix+1452];
	// begin inline asm
	dp4a.u32.u32 %r1585, %r1586, %r4211, %r1581;
	// end inline asm
	ld.const.u32 	%r1590, [matrix+1456];
	// begin inline asm
	dp4a.u32.u32 %r1589, %r1590, %r4215, %r1585;
	// end inline asm
	ld.const.u32 	%r1594, [matrix+1460];
	// begin inline asm
	dp4a.u32.u32 %r1593, %r1594, %r4219, %r1589;
	// end inline asm
	ld.const.u32 	%r1598, [matrix+1464];
	// begin inline asm
	dp4a.u32.u32 %r1597, %r1598, %r4223, %r1593;
	// end inline asm
	ld.const.u32 	%r1602, [matrix+1468];
	// begin inline asm
	dp4a.u32.u32 %r1601, %r1602, %r4227, %r1597;
	// end inline asm
	ld.const.u32 	%r1606, [matrix+1472];
	// begin inline asm
	dp4a.u32.u32 %r1605, %r1606, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1610, [matrix+1476];
	// begin inline asm
	dp4a.u32.u32 %r1609, %r1610, %r4171, %r1605;
	// end inline asm
	ld.const.u32 	%r1614, [matrix+1480];
	// begin inline asm
	dp4a.u32.u32 %r1613, %r1614, %r4175, %r1609;
	// end inline asm
	ld.const.u32 	%r1618, [matrix+1484];
	// begin inline asm
	dp4a.u32.u32 %r1617, %r1618, %r4179, %r1613;
	// end inline asm
	ld.const.u32 	%r1622, [matrix+1488];
	// begin inline asm
	dp4a.u32.u32 %r1621, %r1622, %r4183, %r1617;
	// end inline asm
	ld.const.u32 	%r1626, [matrix+1492];
	// begin inline asm
	dp4a.u32.u32 %r1625, %r1626, %r4187, %r1621;
	// end inline asm
	ld.const.u32 	%r1630, [matrix+1496];
	// begin inline asm
	dp4a.u32.u32 %r1629, %r1630, %r4191, %r1625;
	// end inline asm
	ld.const.u32 	%r1634, [matrix+1500];
	// begin inline asm
	dp4a.u32.u32 %r1633, %r1634, %r4195, %r1629;
	// end inline asm
	ld.const.u32 	%r1638, [matrix+1504];
	// begin inline asm
	dp4a.u32.u32 %r1637, %r1638, %r4199, %r1633;
	// end inline asm
	ld.const.u32 	%r1642, [matrix+1508];
	// begin inline asm
	dp4a.u32.u32 %r1641, %r1642, %r4203, %r1637;
	// end inline asm
	ld.const.u32 	%r1646, [matrix+1512];
	// begin inline asm
	dp4a.u32.u32 %r1645, %r1646, %r4207, %r1641;
	// end inline asm
	ld.const.u32 	%r1650, [matrix+1516];
	// begin inline asm
	dp4a.u32.u32 %r1649, %r1650, %r4211, %r1645;
	// end inline asm
	ld.const.u32 	%r1654, [matrix+1520];
	// begin inline asm
	dp4a.u32.u32 %r1653, %r1654, %r4215, %r1649;
	// end inline asm
	ld.const.u32 	%r1658, [matrix+1524];
	// begin inline asm
	dp4a.u32.u32 %r1657, %r1658, %r4219, %r1653;
	// end inline asm
	ld.const.u32 	%r1662, [matrix+1528];
	// begin inline asm
	dp4a.u32.u32 %r1661, %r1662, %r4223, %r1657;
	// end inline asm
	ld.const.u32 	%r1666, [matrix+1532];
	// begin inline asm
	dp4a.u32.u32 %r1665, %r1666, %r4227, %r1661;
	// end inline asm
	shr.u32 	%r4442, %r1601, 6;
	and.b32  	%r4443, %r4442, 240;
	shr.u32 	%r4444, %r1665, 10;
	or.b32  	%r4445, %r4444, %r4443;
	cvt.u64.u32 	%rd397, %r4445;
	xor.b64  	%rd398, %rd345, %rd397;
	ld.const.u32 	%r1670, [matrix+1536];
	// begin inline asm
	dp4a.u32.u32 %r1669, %r1670, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1674, [matrix+1540];
	// begin inline asm
	dp4a.u32.u32 %r1673, %r1674, %r4171, %r1669;
	// end inline asm
	ld.const.u32 	%r1678, [matrix+1544];
	// begin inline asm
	dp4a.u32.u32 %r1677, %r1678, %r4175, %r1673;
	// end inline asm
	ld.const.u32 	%r1682, [matrix+1548];
	// begin inline asm
	dp4a.u32.u32 %r1681, %r1682, %r4179, %r1677;
	// end inline asm
	ld.const.u32 	%r1686, [matrix+1552];
	// begin inline asm
	dp4a.u32.u32 %r1685, %r1686, %r4183, %r1681;
	// end inline asm
	ld.const.u32 	%r1690, [matrix+1556];
	// begin inline asm
	dp4a.u32.u32 %r1689, %r1690, %r4187, %r1685;
	// end inline asm
	ld.const.u32 	%r1694, [matrix+1560];
	// begin inline asm
	dp4a.u32.u32 %r1693, %r1694, %r4191, %r1689;
	// end inline asm
	ld.const.u32 	%r1698, [matrix+1564];
	// begin inline asm
	dp4a.u32.u32 %r1697, %r1698, %r4195, %r1693;
	// end inline asm
	ld.const.u32 	%r1702, [matrix+1568];
	// begin inline asm
	dp4a.u32.u32 %r1701, %r1702, %r4199, %r1697;
	// end inline asm
	ld.const.u32 	%r1706, [matrix+1572];
	// begin inline asm
	dp4a.u32.u32 %r1705, %r1706, %r4203, %r1701;
	// end inline asm
	ld.const.u32 	%r1710, [matrix+1576];
	// begin inline asm
	dp4a.u32.u32 %r1709, %r1710, %r4207, %r1705;
	// end inline asm
	ld.const.u32 	%r1714, [matrix+1580];
	// begin inline asm
	dp4a.u32.u32 %r1713, %r1714, %r4211, %r1709;
	// end inline asm
	ld.const.u32 	%r1718, [matrix+1584];
	// begin inline asm
	dp4a.u32.u32 %r1717, %r1718, %r4215, %r1713;
	// end inline asm
	ld.const.u32 	%r1722, [matrix+1588];
	// begin inline asm
	dp4a.u32.u32 %r1721, %r1722, %r4219, %r1717;
	// end inline asm
	ld.const.u32 	%r1726, [matrix+1592];
	// begin inline asm
	dp4a.u32.u32 %r1725, %r1726, %r4223, %r1721;
	// end inline asm
	ld.const.u32 	%r1730, [matrix+1596];
	// begin inline asm
	dp4a.u32.u32 %r1729, %r1730, %r4227, %r1725;
	// end inline asm
	ld.const.u32 	%r1734, [matrix+1600];
	// begin inline asm
	dp4a.u32.u32 %r1733, %r1734, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1738, [matrix+1604];
	// begin inline asm
	dp4a.u32.u32 %r1737, %r1738, %r4171, %r1733;
	// end inline asm
	ld.const.u32 	%r1742, [matrix+1608];
	// begin inline asm
	dp4a.u32.u32 %r1741, %r1742, %r4175, %r1737;
	// end inline asm
	ld.const.u32 	%r1746, [matrix+1612];
	// begin inline asm
	dp4a.u32.u32 %r1745, %r1746, %r4179, %r1741;
	// end inline asm
	ld.const.u32 	%r1750, [matrix+1616];
	// begin inline asm
	dp4a.u32.u32 %r1749, %r1750, %r4183, %r1745;
	// end inline asm
	ld.const.u32 	%r1754, [matrix+1620];
	// begin inline asm
	dp4a.u32.u32 %r1753, %r1754, %r4187, %r1749;
	// end inline asm
	ld.const.u32 	%r1758, [matrix+1624];
	// begin inline asm
	dp4a.u32.u32 %r1757, %r1758, %r4191, %r1753;
	// end inline asm
	ld.const.u32 	%r1762, [matrix+1628];
	// begin inline asm
	dp4a.u32.u32 %r1761, %r1762, %r4195, %r1757;
	// end inline asm
	ld.const.u32 	%r1766, [matrix+1632];
	// begin inline asm
	dp4a.u32.u32 %r1765, %r1766, %r4199, %r1761;
	// end inline asm
	ld.const.u32 	%r1770, [matrix+1636];
	// begin inline asm
	dp4a.u32.u32 %r1769, %r1770, %r4203, %r1765;
	// end inline asm
	ld.const.u32 	%r1774, [matrix+1640];
	// begin inline asm
	dp4a.u32.u32 %r1773, %r1774, %r4207, %r1769;
	// end inline asm
	ld.const.u32 	%r1778, [matrix+1644];
	// begin inline asm
	dp4a.u32.u32 %r1777, %r1778, %r4211, %r1773;
	// end inline asm
	ld.const.u32 	%r1782, [matrix+1648];
	// begin inline asm
	dp4a.u32.u32 %r1781, %r1782, %r4215, %r1777;
	// end inline asm
	ld.const.u32 	%r1786, [matrix+1652];
	// begin inline asm
	dp4a.u32.u32 %r1785, %r1786, %r4219, %r1781;
	// end inline asm
	ld.const.u32 	%r1790, [matrix+1656];
	// begin inline asm
	dp4a.u32.u32 %r1789, %r1790, %r4223, %r1785;
	// end inline asm
	ld.const.u32 	%r1794, [matrix+1660];
	// begin inline asm
	dp4a.u32.u32 %r1793, %r1794, %r4227, %r1789;
	// end inline asm
	shr.u32 	%r4446, %r1729, 6;
	and.b32  	%r4447, %r4446, 240;
	shr.u32 	%r4448, %r1793, 10;
	or.b32  	%r4449, %r4448, %r4447;
	cvt.u64.u32 	%rd399, %r4449;
	xor.b64  	%rd400, %rd346, %rd399;
	ld.const.u32 	%r1798, [matrix+1664];
	// begin inline asm
	dp4a.u32.u32 %r1797, %r1798, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1802, [matrix+1668];
	// begin inline asm
	dp4a.u32.u32 %r1801, %r1802, %r4171, %r1797;
	// end inline asm
	ld.const.u32 	%r1806, [matrix+1672];
	// begin inline asm
	dp4a.u32.u32 %r1805, %r1806, %r4175, %r1801;
	// end inline asm
	ld.const.u32 	%r1810, [matrix+1676];
	// begin inline asm
	dp4a.u32.u32 %r1809, %r1810, %r4179, %r1805;
	// end inline asm
	ld.const.u32 	%r1814, [matrix+1680];
	// begin inline asm
	dp4a.u32.u32 %r1813, %r1814, %r4183, %r1809;
	// end inline asm
	ld.const.u32 	%r1818, [matrix+1684];
	// begin inline asm
	dp4a.u32.u32 %r1817, %r1818, %r4187, %r1813;
	// end inline asm
	ld.const.u32 	%r1822, [matrix+1688];
	// begin inline asm
	dp4a.u32.u32 %r1821, %r1822, %r4191, %r1817;
	// end inline asm
	ld.const.u32 	%r1826, [matrix+1692];
	// begin inline asm
	dp4a.u32.u32 %r1825, %r1826, %r4195, %r1821;
	// end inline asm
	ld.const.u32 	%r1830, [matrix+1696];
	// begin inline asm
	dp4a.u32.u32 %r1829, %r1830, %r4199, %r1825;
	// end inline asm
	ld.const.u32 	%r1834, [matrix+1700];
	// begin inline asm
	dp4a.u32.u32 %r1833, %r1834, %r4203, %r1829;
	// end inline asm
	ld.const.u32 	%r1838, [matrix+1704];
	// begin inline asm
	dp4a.u32.u32 %r1837, %r1838, %r4207, %r1833;
	// end inline asm
	ld.const.u32 	%r1842, [matrix+1708];
	// begin inline asm
	dp4a.u32.u32 %r1841, %r1842, %r4211, %r1837;
	// end inline asm
	ld.const.u32 	%r1846, [matrix+1712];
	// begin inline asm
	dp4a.u32.u32 %r1845, %r1846, %r4215, %r1841;
	// end inline asm
	ld.const.u32 	%r1850, [matrix+1716];
	// begin inline asm
	dp4a.u32.u32 %r1849, %r1850, %r4219, %r1845;
	// end inline asm
	ld.const.u32 	%r1854, [matrix+1720];
	// begin inline asm
	dp4a.u32.u32 %r1853, %r1854, %r4223, %r1849;
	// end inline asm
	ld.const.u32 	%r1858, [matrix+1724];
	// begin inline asm
	dp4a.u32.u32 %r1857, %r1858, %r4227, %r1853;
	// end inline asm
	ld.const.u32 	%r1862, [matrix+1728];
	// begin inline asm
	dp4a.u32.u32 %r1861, %r1862, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1866, [matrix+1732];
	// begin inline asm
	dp4a.u32.u32 %r1865, %r1866, %r4171, %r1861;
	// end inline asm
	ld.const.u32 	%r1870, [matrix+1736];
	// begin inline asm
	dp4a.u32.u32 %r1869, %r1870, %r4175, %r1865;
	// end inline asm
	ld.const.u32 	%r1874, [matrix+1740];
	// begin inline asm
	dp4a.u32.u32 %r1873, %r1874, %r4179, %r1869;
	// end inline asm
	ld.const.u32 	%r1878, [matrix+1744];
	// begin inline asm
	dp4a.u32.u32 %r1877, %r1878, %r4183, %r1873;
	// end inline asm
	ld.const.u32 	%r1882, [matrix+1748];
	// begin inline asm
	dp4a.u32.u32 %r1881, %r1882, %r4187, %r1877;
	// end inline asm
	ld.const.u32 	%r1886, [matrix+1752];
	// begin inline asm
	dp4a.u32.u32 %r1885, %r1886, %r4191, %r1881;
	// end inline asm
	ld.const.u32 	%r1890, [matrix+1756];
	// begin inline asm
	dp4a.u32.u32 %r1889, %r1890, %r4195, %r1885;
	// end inline asm
	ld.const.u32 	%r1894, [matrix+1760];
	// begin inline asm
	dp4a.u32.u32 %r1893, %r1894, %r4199, %r1889;
	// end inline asm
	ld.const.u32 	%r1898, [matrix+1764];
	// begin inline asm
	dp4a.u32.u32 %r1897, %r1898, %r4203, %r1893;
	// end inline asm
	ld.const.u32 	%r1902, [matrix+1768];
	// begin inline asm
	dp4a.u32.u32 %r1901, %r1902, %r4207, %r1897;
	// end inline asm
	ld.const.u32 	%r1906, [matrix+1772];
	// begin inline asm
	dp4a.u32.u32 %r1905, %r1906, %r4211, %r1901;
	// end inline asm
	ld.const.u32 	%r1910, [matrix+1776];
	// begin inline asm
	dp4a.u32.u32 %r1909, %r1910, %r4215, %r1905;
	// end inline asm
	ld.const.u32 	%r1914, [matrix+1780];
	// begin inline asm
	dp4a.u32.u32 %r1913, %r1914, %r4219, %r1909;
	// end inline asm
	ld.const.u32 	%r1918, [matrix+1784];
	// begin inline asm
	dp4a.u32.u32 %r1917, %r1918, %r4223, %r1913;
	// end inline asm
	ld.const.u32 	%r1922, [matrix+1788];
	// begin inline asm
	dp4a.u32.u32 %r1921, %r1922, %r4227, %r1917;
	// end inline asm
	shr.u32 	%r4450, %r1857, 6;
	and.b32  	%r4451, %r4450, 240;
	shr.u32 	%r4452, %r1921, 10;
	or.b32  	%r4453, %r4452, %r4451;
	cvt.u64.u32 	%rd401, %r4453;
	xor.b64  	%rd402, %rd347, %rd401;
	ld.const.u32 	%r1926, [matrix+1792];
	// begin inline asm
	dp4a.u32.u32 %r1925, %r1926, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1930, [matrix+1796];
	// begin inline asm
	dp4a.u32.u32 %r1929, %r1930, %r4171, %r1925;
	// end inline asm
	ld.const.u32 	%r1934, [matrix+1800];
	// begin inline asm
	dp4a.u32.u32 %r1933, %r1934, %r4175, %r1929;
	// end inline asm
	ld.const.u32 	%r1938, [matrix+1804];
	// begin inline asm
	dp4a.u32.u32 %r1937, %r1938, %r4179, %r1933;
	// end inline asm
	ld.const.u32 	%r1942, [matrix+1808];
	// begin inline asm
	dp4a.u32.u32 %r1941, %r1942, %r4183, %r1937;
	// end inline asm
	ld.const.u32 	%r1946, [matrix+1812];
	// begin inline asm
	dp4a.u32.u32 %r1945, %r1946, %r4187, %r1941;
	// end inline asm
	ld.const.u32 	%r1950, [matrix+1816];
	// begin inline asm
	dp4a.u32.u32 %r1949, %r1950, %r4191, %r1945;
	// end inline asm
	ld.const.u32 	%r1954, [matrix+1820];
	// begin inline asm
	dp4a.u32.u32 %r1953, %r1954, %r4195, %r1949;
	// end inline asm
	ld.const.u32 	%r1958, [matrix+1824];
	// begin inline asm
	dp4a.u32.u32 %r1957, %r1958, %r4199, %r1953;
	// end inline asm
	ld.const.u32 	%r1962, [matrix+1828];
	// begin inline asm
	dp4a.u32.u32 %r1961, %r1962, %r4203, %r1957;
	// end inline asm
	ld.const.u32 	%r1966, [matrix+1832];
	// begin inline asm
	dp4a.u32.u32 %r1965, %r1966, %r4207, %r1961;
	// end inline asm
	ld.const.u32 	%r1970, [matrix+1836];
	// begin inline asm
	dp4a.u32.u32 %r1969, %r1970, %r4211, %r1965;
	// end inline asm
	ld.const.u32 	%r1974, [matrix+1840];
	// begin inline asm
	dp4a.u32.u32 %r1973, %r1974, %r4215, %r1969;
	// end inline asm
	ld.const.u32 	%r1978, [matrix+1844];
	// begin inline asm
	dp4a.u32.u32 %r1977, %r1978, %r4219, %r1973;
	// end inline asm
	ld.const.u32 	%r1982, [matrix+1848];
	// begin inline asm
	dp4a.u32.u32 %r1981, %r1982, %r4223, %r1977;
	// end inline asm
	ld.const.u32 	%r1986, [matrix+1852];
	// begin inline asm
	dp4a.u32.u32 %r1985, %r1986, %r4227, %r1981;
	// end inline asm
	ld.const.u32 	%r1990, [matrix+1856];
	// begin inline asm
	dp4a.u32.u32 %r1989, %r1990, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r1994, [matrix+1860];
	// begin inline asm
	dp4a.u32.u32 %r1993, %r1994, %r4171, %r1989;
	// end inline asm
	ld.const.u32 	%r1998, [matrix+1864];
	// begin inline asm
	dp4a.u32.u32 %r1997, %r1998, %r4175, %r1993;
	// end inline asm
	ld.const.u32 	%r2002, [matrix+1868];
	// begin inline asm
	dp4a.u32.u32 %r2001, %r2002, %r4179, %r1997;
	// end inline asm
	ld.const.u32 	%r2006, [matrix+1872];
	// begin inline asm
	dp4a.u32.u32 %r2005, %r2006, %r4183, %r2001;
	// end inline asm
	ld.const.u32 	%r2010, [matrix+1876];
	// begin inline asm
	dp4a.u32.u32 %r2009, %r2010, %r4187, %r2005;
	// end inline asm
	ld.const.u32 	%r2014, [matrix+1880];
	// begin inline asm
	dp4a.u32.u32 %r2013, %r2014, %r4191, %r2009;
	// end inline asm
	ld.const.u32 	%r2018, [matrix+1884];
	// begin inline asm
	dp4a.u32.u32 %r2017, %r2018, %r4195, %r2013;
	// end inline asm
	ld.const.u32 	%r2022, [matrix+1888];
	// begin inline asm
	dp4a.u32.u32 %r2021, %r2022, %r4199, %r2017;
	// end inline asm
	ld.const.u32 	%r2026, [matrix+1892];
	// begin inline asm
	dp4a.u32.u32 %r2025, %r2026, %r4203, %r2021;
	// end inline asm
	ld.const.u32 	%r2030, [matrix+1896];
	// begin inline asm
	dp4a.u32.u32 %r2029, %r2030, %r4207, %r2025;
	// end inline asm
	ld.const.u32 	%r2034, [matrix+1900];
	// begin inline asm
	dp4a.u32.u32 %r2033, %r2034, %r4211, %r2029;
	// end inline asm
	ld.const.u32 	%r2038, [matrix+1904];
	// begin inline asm
	dp4a.u32.u32 %r2037, %r2038, %r4215, %r2033;
	// end inline asm
	ld.const.u32 	%r2042, [matrix+1908];
	// begin inline asm
	dp4a.u32.u32 %r2041, %r2042, %r4219, %r2037;
	// end inline asm
	ld.const.u32 	%r2046, [matrix+1912];
	// begin inline asm
	dp4a.u32.u32 %r2045, %r2046, %r4223, %r2041;
	// end inline asm
	ld.const.u32 	%r2050, [matrix+1916];
	// begin inline asm
	dp4a.u32.u32 %r2049, %r2050, %r4227, %r2045;
	// end inline asm
	shr.u32 	%r4454, %r1985, 6;
	and.b32  	%r4455, %r4454, 240;
	shr.u32 	%r4456, %r2049, 10;
	or.b32  	%r4457, %r4456, %r4455;
	cvt.u64.u32 	%rd403, %r4457;
	xor.b64  	%rd404, %rd348, %rd403;
	ld.const.u32 	%r2054, [matrix+1920];
	// begin inline asm
	dp4a.u32.u32 %r2053, %r2054, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2058, [matrix+1924];
	// begin inline asm
	dp4a.u32.u32 %r2057, %r2058, %r4171, %r2053;
	// end inline asm
	ld.const.u32 	%r2062, [matrix+1928];
	// begin inline asm
	dp4a.u32.u32 %r2061, %r2062, %r4175, %r2057;
	// end inline asm
	ld.const.u32 	%r2066, [matrix+1932];
	// begin inline asm
	dp4a.u32.u32 %r2065, %r2066, %r4179, %r2061;
	// end inline asm
	ld.const.u32 	%r2070, [matrix+1936];
	// begin inline asm
	dp4a.u32.u32 %r2069, %r2070, %r4183, %r2065;
	// end inline asm
	ld.const.u32 	%r2074, [matrix+1940];
	// begin inline asm
	dp4a.u32.u32 %r2073, %r2074, %r4187, %r2069;
	// end inline asm
	ld.const.u32 	%r2078, [matrix+1944];
	// begin inline asm
	dp4a.u32.u32 %r2077, %r2078, %r4191, %r2073;
	// end inline asm
	ld.const.u32 	%r2082, [matrix+1948];
	// begin inline asm
	dp4a.u32.u32 %r2081, %r2082, %r4195, %r2077;
	// end inline asm
	ld.const.u32 	%r2086, [matrix+1952];
	// begin inline asm
	dp4a.u32.u32 %r2085, %r2086, %r4199, %r2081;
	// end inline asm
	ld.const.u32 	%r2090, [matrix+1956];
	// begin inline asm
	dp4a.u32.u32 %r2089, %r2090, %r4203, %r2085;
	// end inline asm
	ld.const.u32 	%r2094, [matrix+1960];
	// begin inline asm
	dp4a.u32.u32 %r2093, %r2094, %r4207, %r2089;
	// end inline asm
	ld.const.u32 	%r2098, [matrix+1964];
	// begin inline asm
	dp4a.u32.u32 %r2097, %r2098, %r4211, %r2093;
	// end inline asm
	ld.const.u32 	%r2102, [matrix+1968];
	// begin inline asm
	dp4a.u32.u32 %r2101, %r2102, %r4215, %r2097;
	// end inline asm
	ld.const.u32 	%r2106, [matrix+1972];
	// begin inline asm
	dp4a.u32.u32 %r2105, %r2106, %r4219, %r2101;
	// end inline asm
	ld.const.u32 	%r2110, [matrix+1976];
	// begin inline asm
	dp4a.u32.u32 %r2109, %r2110, %r4223, %r2105;
	// end inline asm
	ld.const.u32 	%r2114, [matrix+1980];
	// begin inline asm
	dp4a.u32.u32 %r2113, %r2114, %r4227, %r2109;
	// end inline asm
	ld.const.u32 	%r2118, [matrix+1984];
	// begin inline asm
	dp4a.u32.u32 %r2117, %r2118, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2122, [matrix+1988];
	// begin inline asm
	dp4a.u32.u32 %r2121, %r2122, %r4171, %r2117;
	// end inline asm
	ld.const.u32 	%r2126, [matrix+1992];
	// begin inline asm
	dp4a.u32.u32 %r2125, %r2126, %r4175, %r2121;
	// end inline asm
	ld.const.u32 	%r2130, [matrix+1996];
	// begin inline asm
	dp4a.u32.u32 %r2129, %r2130, %r4179, %r2125;
	// end inline asm
	ld.const.u32 	%r2134, [matrix+2000];
	// begin inline asm
	dp4a.u32.u32 %r2133, %r2134, %r4183, %r2129;
	// end inline asm
	ld.const.u32 	%r2138, [matrix+2004];
	// begin inline asm
	dp4a.u32.u32 %r2137, %r2138, %r4187, %r2133;
	// end inline asm
	ld.const.u32 	%r2142, [matrix+2008];
	// begin inline asm
	dp4a.u32.u32 %r2141, %r2142, %r4191, %r2137;
	// end inline asm
	ld.const.u32 	%r2146, [matrix+2012];
	// begin inline asm
	dp4a.u32.u32 %r2145, %r2146, %r4195, %r2141;
	// end inline asm
	ld.const.u32 	%r2150, [matrix+2016];
	// begin inline asm
	dp4a.u32.u32 %r2149, %r2150, %r4199, %r2145;
	// end inline asm
	ld.const.u32 	%r2154, [matrix+2020];
	// begin inline asm
	dp4a.u32.u32 %r2153, %r2154, %r4203, %r2149;
	// end inline asm
	ld.const.u32 	%r2158, [matrix+2024];
	// begin inline asm
	dp4a.u32.u32 %r2157, %r2158, %r4207, %r2153;
	// end inline asm
	ld.const.u32 	%r2162, [matrix+2028];
	// begin inline asm
	dp4a.u32.u32 %r2161, %r2162, %r4211, %r2157;
	// end inline asm
	ld.const.u32 	%r2166, [matrix+2032];
	// begin inline asm
	dp4a.u32.u32 %r2165, %r2166, %r4215, %r2161;
	// end inline asm
	ld.const.u32 	%r2170, [matrix+2036];
	// begin inline asm
	dp4a.u32.u32 %r2169, %r2170, %r4219, %r2165;
	// end inline asm
	ld.const.u32 	%r2174, [matrix+2040];
	// begin inline asm
	dp4a.u32.u32 %r2173, %r2174, %r4223, %r2169;
	// end inline asm
	ld.const.u32 	%r2178, [matrix+2044];
	// begin inline asm
	dp4a.u32.u32 %r2177, %r2178, %r4227, %r2173;
	// end inline asm
	shr.u32 	%r4458, %r2113, 6;
	and.b32  	%r4459, %r4458, 240;
	shr.u32 	%r4460, %r2177, 10;
	or.b32  	%r4461, %r4460, %r4459;
	cvt.u64.u32 	%rd405, %r4461;
	ld.const.u32 	%r2182, [matrix+2048];
	// begin inline asm
	dp4a.u32.u32 %r2181, %r2182, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2186, [matrix+2052];
	// begin inline asm
	dp4a.u32.u32 %r2185, %r2186, %r4171, %r2181;
	// end inline asm
	ld.const.u32 	%r2190, [matrix+2056];
	// begin inline asm
	dp4a.u32.u32 %r2189, %r2190, %r4175, %r2185;
	// end inline asm
	ld.const.u32 	%r2194, [matrix+2060];
	// begin inline asm
	dp4a.u32.u32 %r2193, %r2194, %r4179, %r2189;
	// end inline asm
	ld.const.u32 	%r2198, [matrix+2064];
	// begin inline asm
	dp4a.u32.u32 %r2197, %r2198, %r4183, %r2193;
	// end inline asm
	ld.const.u32 	%r2202, [matrix+2068];
	// begin inline asm
	dp4a.u32.u32 %r2201, %r2202, %r4187, %r2197;
	// end inline asm
	ld.const.u32 	%r2206, [matrix+2072];
	// begin inline asm
	dp4a.u32.u32 %r2205, %r2206, %r4191, %r2201;
	// end inline asm
	ld.const.u32 	%r2210, [matrix+2076];
	// begin inline asm
	dp4a.u32.u32 %r2209, %r2210, %r4195, %r2205;
	// end inline asm
	ld.const.u32 	%r2214, [matrix+2080];
	// begin inline asm
	dp4a.u32.u32 %r2213, %r2214, %r4199, %r2209;
	// end inline asm
	ld.const.u32 	%r2218, [matrix+2084];
	// begin inline asm
	dp4a.u32.u32 %r2217, %r2218, %r4203, %r2213;
	// end inline asm
	ld.const.u32 	%r2222, [matrix+2088];
	// begin inline asm
	dp4a.u32.u32 %r2221, %r2222, %r4207, %r2217;
	// end inline asm
	ld.const.u32 	%r2226, [matrix+2092];
	// begin inline asm
	dp4a.u32.u32 %r2225, %r2226, %r4211, %r2221;
	// end inline asm
	ld.const.u32 	%r2230, [matrix+2096];
	// begin inline asm
	dp4a.u32.u32 %r2229, %r2230, %r4215, %r2225;
	// end inline asm
	ld.const.u32 	%r2234, [matrix+2100];
	// begin inline asm
	dp4a.u32.u32 %r2233, %r2234, %r4219, %r2229;
	// end inline asm
	ld.const.u32 	%r2238, [matrix+2104];
	// begin inline asm
	dp4a.u32.u32 %r2237, %r2238, %r4223, %r2233;
	// end inline asm
	ld.const.u32 	%r2242, [matrix+2108];
	// begin inline asm
	dp4a.u32.u32 %r2241, %r2242, %r4227, %r2237;
	// end inline asm
	ld.const.u32 	%r2246, [matrix+2112];
	// begin inline asm
	dp4a.u32.u32 %r2245, %r2246, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2250, [matrix+2116];
	// begin inline asm
	dp4a.u32.u32 %r2249, %r2250, %r4171, %r2245;
	// end inline asm
	ld.const.u32 	%r2254, [matrix+2120];
	// begin inline asm
	dp4a.u32.u32 %r2253, %r2254, %r4175, %r2249;
	// end inline asm
	ld.const.u32 	%r2258, [matrix+2124];
	// begin inline asm
	dp4a.u32.u32 %r2257, %r2258, %r4179, %r2253;
	// end inline asm
	ld.const.u32 	%r2262, [matrix+2128];
	// begin inline asm
	dp4a.u32.u32 %r2261, %r2262, %r4183, %r2257;
	// end inline asm
	ld.const.u32 	%r2266, [matrix+2132];
	// begin inline asm
	dp4a.u32.u32 %r2265, %r2266, %r4187, %r2261;
	// end inline asm
	ld.const.u32 	%r2270, [matrix+2136];
	// begin inline asm
	dp4a.u32.u32 %r2269, %r2270, %r4191, %r2265;
	// end inline asm
	ld.const.u32 	%r2274, [matrix+2140];
	// begin inline asm
	dp4a.u32.u32 %r2273, %r2274, %r4195, %r2269;
	// end inline asm
	ld.const.u32 	%r2278, [matrix+2144];
	// begin inline asm
	dp4a.u32.u32 %r2277, %r2278, %r4199, %r2273;
	// end inline asm
	ld.const.u32 	%r2282, [matrix+2148];
	// begin inline asm
	dp4a.u32.u32 %r2281, %r2282, %r4203, %r2277;
	// end inline asm
	ld.const.u32 	%r2286, [matrix+2152];
	// begin inline asm
	dp4a.u32.u32 %r2285, %r2286, %r4207, %r2281;
	// end inline asm
	ld.const.u32 	%r2290, [matrix+2156];
	// begin inline asm
	dp4a.u32.u32 %r2289, %r2290, %r4211, %r2285;
	// end inline asm
	ld.const.u32 	%r2294, [matrix+2160];
	// begin inline asm
	dp4a.u32.u32 %r2293, %r2294, %r4215, %r2289;
	// end inline asm
	ld.const.u32 	%r2298, [matrix+2164];
	// begin inline asm
	dp4a.u32.u32 %r2297, %r2298, %r4219, %r2293;
	// end inline asm
	ld.const.u32 	%r2302, [matrix+2168];
	// begin inline asm
	dp4a.u32.u32 %r2301, %r2302, %r4223, %r2297;
	// end inline asm
	ld.const.u32 	%r2306, [matrix+2172];
	// begin inline asm
	dp4a.u32.u32 %r2305, %r2306, %r4227, %r2301;
	// end inline asm
	shr.u32 	%r4462, %r2241, 6;
	and.b32  	%r4463, %r4462, 240;
	shr.u32 	%r4464, %r2305, 10;
	or.b32  	%r4465, %r4464, %r4463;
	cvt.u64.u32 	%rd406, %r4465;
	xor.b64  	%rd407, %rd675, %rd406;
	ld.const.u32 	%r2310, [matrix+2176];
	// begin inline asm
	dp4a.u32.u32 %r2309, %r2310, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2314, [matrix+2180];
	// begin inline asm
	dp4a.u32.u32 %r2313, %r2314, %r4171, %r2309;
	// end inline asm
	ld.const.u32 	%r2318, [matrix+2184];
	// begin inline asm
	dp4a.u32.u32 %r2317, %r2318, %r4175, %r2313;
	// end inline asm
	ld.const.u32 	%r2322, [matrix+2188];
	// begin inline asm
	dp4a.u32.u32 %r2321, %r2322, %r4179, %r2317;
	// end inline asm
	ld.const.u32 	%r2326, [matrix+2192];
	// begin inline asm
	dp4a.u32.u32 %r2325, %r2326, %r4183, %r2321;
	// end inline asm
	ld.const.u32 	%r2330, [matrix+2196];
	// begin inline asm
	dp4a.u32.u32 %r2329, %r2330, %r4187, %r2325;
	// end inline asm
	ld.const.u32 	%r2334, [matrix+2200];
	// begin inline asm
	dp4a.u32.u32 %r2333, %r2334, %r4191, %r2329;
	// end inline asm
	ld.const.u32 	%r2338, [matrix+2204];
	// begin inline asm
	dp4a.u32.u32 %r2337, %r2338, %r4195, %r2333;
	// end inline asm
	ld.const.u32 	%r2342, [matrix+2208];
	// begin inline asm
	dp4a.u32.u32 %r2341, %r2342, %r4199, %r2337;
	// end inline asm
	ld.const.u32 	%r2346, [matrix+2212];
	// begin inline asm
	dp4a.u32.u32 %r2345, %r2346, %r4203, %r2341;
	// end inline asm
	ld.const.u32 	%r2350, [matrix+2216];
	// begin inline asm
	dp4a.u32.u32 %r2349, %r2350, %r4207, %r2345;
	// end inline asm
	ld.const.u32 	%r2354, [matrix+2220];
	// begin inline asm
	dp4a.u32.u32 %r2353, %r2354, %r4211, %r2349;
	// end inline asm
	ld.const.u32 	%r2358, [matrix+2224];
	// begin inline asm
	dp4a.u32.u32 %r2357, %r2358, %r4215, %r2353;
	// end inline asm
	ld.const.u32 	%r2362, [matrix+2228];
	// begin inline asm
	dp4a.u32.u32 %r2361, %r2362, %r4219, %r2357;
	// end inline asm
	ld.const.u32 	%r2366, [matrix+2232];
	// begin inline asm
	dp4a.u32.u32 %r2365, %r2366, %r4223, %r2361;
	// end inline asm
	ld.const.u32 	%r2370, [matrix+2236];
	// begin inline asm
	dp4a.u32.u32 %r2369, %r2370, %r4227, %r2365;
	// end inline asm
	ld.const.u32 	%r2374, [matrix+2240];
	// begin inline asm
	dp4a.u32.u32 %r2373, %r2374, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2378, [matrix+2244];
	// begin inline asm
	dp4a.u32.u32 %r2377, %r2378, %r4171, %r2373;
	// end inline asm
	ld.const.u32 	%r2382, [matrix+2248];
	// begin inline asm
	dp4a.u32.u32 %r2381, %r2382, %r4175, %r2377;
	// end inline asm
	ld.const.u32 	%r2386, [matrix+2252];
	// begin inline asm
	dp4a.u32.u32 %r2385, %r2386, %r4179, %r2381;
	// end inline asm
	ld.const.u32 	%r2390, [matrix+2256];
	// begin inline asm
	dp4a.u32.u32 %r2389, %r2390, %r4183, %r2385;
	// end inline asm
	ld.const.u32 	%r2394, [matrix+2260];
	// begin inline asm
	dp4a.u32.u32 %r2393, %r2394, %r4187, %r2389;
	// end inline asm
	ld.const.u32 	%r2398, [matrix+2264];
	// begin inline asm
	dp4a.u32.u32 %r2397, %r2398, %r4191, %r2393;
	// end inline asm
	ld.const.u32 	%r2402, [matrix+2268];
	// begin inline asm
	dp4a.u32.u32 %r2401, %r2402, %r4195, %r2397;
	// end inline asm
	ld.const.u32 	%r2406, [matrix+2272];
	// begin inline asm
	dp4a.u32.u32 %r2405, %r2406, %r4199, %r2401;
	// end inline asm
	ld.const.u32 	%r2410, [matrix+2276];
	// begin inline asm
	dp4a.u32.u32 %r2409, %r2410, %r4203, %r2405;
	// end inline asm
	ld.const.u32 	%r2414, [matrix+2280];
	// begin inline asm
	dp4a.u32.u32 %r2413, %r2414, %r4207, %r2409;
	// end inline asm
	ld.const.u32 	%r2418, [matrix+2284];
	// begin inline asm
	dp4a.u32.u32 %r2417, %r2418, %r4211, %r2413;
	// end inline asm
	ld.const.u32 	%r2422, [matrix+2288];
	// begin inline asm
	dp4a.u32.u32 %r2421, %r2422, %r4215, %r2417;
	// end inline asm
	ld.const.u32 	%r2426, [matrix+2292];
	// begin inline asm
	dp4a.u32.u32 %r2425, %r2426, %r4219, %r2421;
	// end inline asm
	ld.const.u32 	%r2430, [matrix+2296];
	// begin inline asm
	dp4a.u32.u32 %r2429, %r2430, %r4223, %r2425;
	// end inline asm
	ld.const.u32 	%r2434, [matrix+2300];
	// begin inline asm
	dp4a.u32.u32 %r2433, %r2434, %r4227, %r2429;
	// end inline asm
	shr.u32 	%r4466, %r2369, 6;
	and.b32  	%r4467, %r4466, 240;
	shr.u32 	%r4468, %r2433, 10;
	or.b32  	%r4469, %r4468, %r4467;
	cvt.u64.u32 	%rd408, %r4469;
	xor.b64  	%rd409, %rd350, %rd408;
	ld.const.u32 	%r2438, [matrix+2304];
	// begin inline asm
	dp4a.u32.u32 %r2437, %r2438, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2442, [matrix+2308];
	// begin inline asm
	dp4a.u32.u32 %r2441, %r2442, %r4171, %r2437;
	// end inline asm
	ld.const.u32 	%r2446, [matrix+2312];
	// begin inline asm
	dp4a.u32.u32 %r2445, %r2446, %r4175, %r2441;
	// end inline asm
	ld.const.u32 	%r2450, [matrix+2316];
	// begin inline asm
	dp4a.u32.u32 %r2449, %r2450, %r4179, %r2445;
	// end inline asm
	ld.const.u32 	%r2454, [matrix+2320];
	// begin inline asm
	dp4a.u32.u32 %r2453, %r2454, %r4183, %r2449;
	// end inline asm
	ld.const.u32 	%r2458, [matrix+2324];
	// begin inline asm
	dp4a.u32.u32 %r2457, %r2458, %r4187, %r2453;
	// end inline asm
	ld.const.u32 	%r2462, [matrix+2328];
	// begin inline asm
	dp4a.u32.u32 %r2461, %r2462, %r4191, %r2457;
	// end inline asm
	ld.const.u32 	%r2466, [matrix+2332];
	// begin inline asm
	dp4a.u32.u32 %r2465, %r2466, %r4195, %r2461;
	// end inline asm
	ld.const.u32 	%r2470, [matrix+2336];
	// begin inline asm
	dp4a.u32.u32 %r2469, %r2470, %r4199, %r2465;
	// end inline asm
	ld.const.u32 	%r2474, [matrix+2340];
	// begin inline asm
	dp4a.u32.u32 %r2473, %r2474, %r4203, %r2469;
	// end inline asm
	ld.const.u32 	%r2478, [matrix+2344];
	// begin inline asm
	dp4a.u32.u32 %r2477, %r2478, %r4207, %r2473;
	// end inline asm
	ld.const.u32 	%r2482, [matrix+2348];
	// begin inline asm
	dp4a.u32.u32 %r2481, %r2482, %r4211, %r2477;
	// end inline asm
	ld.const.u32 	%r2486, [matrix+2352];
	// begin inline asm
	dp4a.u32.u32 %r2485, %r2486, %r4215, %r2481;
	// end inline asm
	ld.const.u32 	%r2490, [matrix+2356];
	// begin inline asm
	dp4a.u32.u32 %r2489, %r2490, %r4219, %r2485;
	// end inline asm
	ld.const.u32 	%r2494, [matrix+2360];
	// begin inline asm
	dp4a.u32.u32 %r2493, %r2494, %r4223, %r2489;
	// end inline asm
	ld.const.u32 	%r2498, [matrix+2364];
	// begin inline asm
	dp4a.u32.u32 %r2497, %r2498, %r4227, %r2493;
	// end inline asm
	ld.const.u32 	%r2502, [matrix+2368];
	// begin inline asm
	dp4a.u32.u32 %r2501, %r2502, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2506, [matrix+2372];
	// begin inline asm
	dp4a.u32.u32 %r2505, %r2506, %r4171, %r2501;
	// end inline asm
	ld.const.u32 	%r2510, [matrix+2376];
	// begin inline asm
	dp4a.u32.u32 %r2509, %r2510, %r4175, %r2505;
	// end inline asm
	ld.const.u32 	%r2514, [matrix+2380];
	// begin inline asm
	dp4a.u32.u32 %r2513, %r2514, %r4179, %r2509;
	// end inline asm
	ld.const.u32 	%r2518, [matrix+2384];
	// begin inline asm
	dp4a.u32.u32 %r2517, %r2518, %r4183, %r2513;
	// end inline asm
	ld.const.u32 	%r2522, [matrix+2388];
	// begin inline asm
	dp4a.u32.u32 %r2521, %r2522, %r4187, %r2517;
	// end inline asm
	ld.const.u32 	%r2526, [matrix+2392];
	// begin inline asm
	dp4a.u32.u32 %r2525, %r2526, %r4191, %r2521;
	// end inline asm
	ld.const.u32 	%r2530, [matrix+2396];
	// begin inline asm
	dp4a.u32.u32 %r2529, %r2530, %r4195, %r2525;
	// end inline asm
	ld.const.u32 	%r2534, [matrix+2400];
	// begin inline asm
	dp4a.u32.u32 %r2533, %r2534, %r4199, %r2529;
	// end inline asm
	ld.const.u32 	%r2538, [matrix+2404];
	// begin inline asm
	dp4a.u32.u32 %r2537, %r2538, %r4203, %r2533;
	// end inline asm
	ld.const.u32 	%r2542, [matrix+2408];
	// begin inline asm
	dp4a.u32.u32 %r2541, %r2542, %r4207, %r2537;
	// end inline asm
	ld.const.u32 	%r2546, [matrix+2412];
	// begin inline asm
	dp4a.u32.u32 %r2545, %r2546, %r4211, %r2541;
	// end inline asm
	ld.const.u32 	%r2550, [matrix+2416];
	// begin inline asm
	dp4a.u32.u32 %r2549, %r2550, %r4215, %r2545;
	// end inline asm
	ld.const.u32 	%r2554, [matrix+2420];
	// begin inline asm
	dp4a.u32.u32 %r2553, %r2554, %r4219, %r2549;
	// end inline asm
	ld.const.u32 	%r2558, [matrix+2424];
	// begin inline asm
	dp4a.u32.u32 %r2557, %r2558, %r4223, %r2553;
	// end inline asm
	ld.const.u32 	%r2562, [matrix+2428];
	// begin inline asm
	dp4a.u32.u32 %r2561, %r2562, %r4227, %r2557;
	// end inline asm
	shr.u32 	%r4470, %r2497, 6;
	and.b32  	%r4471, %r4470, 240;
	shr.u32 	%r4472, %r2561, 10;
	or.b32  	%r4473, %r4472, %r4471;
	cvt.u64.u32 	%rd410, %r4473;
	xor.b64  	%rd411, %rd351, %rd410;
	ld.const.u32 	%r2566, [matrix+2432];
	// begin inline asm
	dp4a.u32.u32 %r2565, %r2566, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2570, [matrix+2436];
	// begin inline asm
	dp4a.u32.u32 %r2569, %r2570, %r4171, %r2565;
	// end inline asm
	ld.const.u32 	%r2574, [matrix+2440];
	// begin inline asm
	dp4a.u32.u32 %r2573, %r2574, %r4175, %r2569;
	// end inline asm
	ld.const.u32 	%r2578, [matrix+2444];
	// begin inline asm
	dp4a.u32.u32 %r2577, %r2578, %r4179, %r2573;
	// end inline asm
	ld.const.u32 	%r2582, [matrix+2448];
	// begin inline asm
	dp4a.u32.u32 %r2581, %r2582, %r4183, %r2577;
	// end inline asm
	ld.const.u32 	%r2586, [matrix+2452];
	// begin inline asm
	dp4a.u32.u32 %r2585, %r2586, %r4187, %r2581;
	// end inline asm
	ld.const.u32 	%r2590, [matrix+2456];
	// begin inline asm
	dp4a.u32.u32 %r2589, %r2590, %r4191, %r2585;
	// end inline asm
	ld.const.u32 	%r2594, [matrix+2460];
	// begin inline asm
	dp4a.u32.u32 %r2593, %r2594, %r4195, %r2589;
	// end inline asm
	ld.const.u32 	%r2598, [matrix+2464];
	// begin inline asm
	dp4a.u32.u32 %r2597, %r2598, %r4199, %r2593;
	// end inline asm
	ld.const.u32 	%r2602, [matrix+2468];
	// begin inline asm
	dp4a.u32.u32 %r2601, %r2602, %r4203, %r2597;
	// end inline asm
	ld.const.u32 	%r2606, [matrix+2472];
	// begin inline asm
	dp4a.u32.u32 %r2605, %r2606, %r4207, %r2601;
	// end inline asm
	ld.const.u32 	%r2610, [matrix+2476];
	// begin inline asm
	dp4a.u32.u32 %r2609, %r2610, %r4211, %r2605;
	// end inline asm
	ld.const.u32 	%r2614, [matrix+2480];
	// begin inline asm
	dp4a.u32.u32 %r2613, %r2614, %r4215, %r2609;
	// end inline asm
	ld.const.u32 	%r2618, [matrix+2484];
	// begin inline asm
	dp4a.u32.u32 %r2617, %r2618, %r4219, %r2613;
	// end inline asm
	ld.const.u32 	%r2622, [matrix+2488];
	// begin inline asm
	dp4a.u32.u32 %r2621, %r2622, %r4223, %r2617;
	// end inline asm
	ld.const.u32 	%r2626, [matrix+2492];
	// begin inline asm
	dp4a.u32.u32 %r2625, %r2626, %r4227, %r2621;
	// end inline asm
	ld.const.u32 	%r2630, [matrix+2496];
	// begin inline asm
	dp4a.u32.u32 %r2629, %r2630, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2634, [matrix+2500];
	// begin inline asm
	dp4a.u32.u32 %r2633, %r2634, %r4171, %r2629;
	// end inline asm
	ld.const.u32 	%r2638, [matrix+2504];
	// begin inline asm
	dp4a.u32.u32 %r2637, %r2638, %r4175, %r2633;
	// end inline asm
	ld.const.u32 	%r2642, [matrix+2508];
	// begin inline asm
	dp4a.u32.u32 %r2641, %r2642, %r4179, %r2637;
	// end inline asm
	ld.const.u32 	%r2646, [matrix+2512];
	// begin inline asm
	dp4a.u32.u32 %r2645, %r2646, %r4183, %r2641;
	// end inline asm
	ld.const.u32 	%r2650, [matrix+2516];
	// begin inline asm
	dp4a.u32.u32 %r2649, %r2650, %r4187, %r2645;
	// end inline asm
	ld.const.u32 	%r2654, [matrix+2520];
	// begin inline asm
	dp4a.u32.u32 %r2653, %r2654, %r4191, %r2649;
	// end inline asm
	ld.const.u32 	%r2658, [matrix+2524];
	// begin inline asm
	dp4a.u32.u32 %r2657, %r2658, %r4195, %r2653;
	// end inline asm
	ld.const.u32 	%r2662, [matrix+2528];
	// begin inline asm
	dp4a.u32.u32 %r2661, %r2662, %r4199, %r2657;
	// end inline asm
	ld.const.u32 	%r2666, [matrix+2532];
	// begin inline asm
	dp4a.u32.u32 %r2665, %r2666, %r4203, %r2661;
	// end inline asm
	ld.const.u32 	%r2670, [matrix+2536];
	// begin inline asm
	dp4a.u32.u32 %r2669, %r2670, %r4207, %r2665;
	// end inline asm
	ld.const.u32 	%r2674, [matrix+2540];
	// begin inline asm
	dp4a.u32.u32 %r2673, %r2674, %r4211, %r2669;
	// end inline asm
	ld.const.u32 	%r2678, [matrix+2544];
	// begin inline asm
	dp4a.u32.u32 %r2677, %r2678, %r4215, %r2673;
	// end inline asm
	ld.const.u32 	%r2682, [matrix+2548];
	// begin inline asm
	dp4a.u32.u32 %r2681, %r2682, %r4219, %r2677;
	// end inline asm
	ld.const.u32 	%r2686, [matrix+2552];
	// begin inline asm
	dp4a.u32.u32 %r2685, %r2686, %r4223, %r2681;
	// end inline asm
	ld.const.u32 	%r2690, [matrix+2556];
	// begin inline asm
	dp4a.u32.u32 %r2689, %r2690, %r4227, %r2685;
	// end inline asm
	shr.u32 	%r4474, %r2625, 6;
	and.b32  	%r4475, %r4474, 240;
	shr.u32 	%r4476, %r2689, 10;
	or.b32  	%r4477, %r4476, %r4475;
	cvt.u64.u32 	%rd412, %r4477;
	xor.b64  	%rd413, %rd352, %rd412;
	ld.const.u32 	%r2694, [matrix+2560];
	// begin inline asm
	dp4a.u32.u32 %r2693, %r2694, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2698, [matrix+2564];
	// begin inline asm
	dp4a.u32.u32 %r2697, %r2698, %r4171, %r2693;
	// end inline asm
	ld.const.u32 	%r2702, [matrix+2568];
	// begin inline asm
	dp4a.u32.u32 %r2701, %r2702, %r4175, %r2697;
	// end inline asm
	ld.const.u32 	%r2706, [matrix+2572];
	// begin inline asm
	dp4a.u32.u32 %r2705, %r2706, %r4179, %r2701;
	// end inline asm
	ld.const.u32 	%r2710, [matrix+2576];
	// begin inline asm
	dp4a.u32.u32 %r2709, %r2710, %r4183, %r2705;
	// end inline asm
	ld.const.u32 	%r2714, [matrix+2580];
	// begin inline asm
	dp4a.u32.u32 %r2713, %r2714, %r4187, %r2709;
	// end inline asm
	ld.const.u32 	%r2718, [matrix+2584];
	// begin inline asm
	dp4a.u32.u32 %r2717, %r2718, %r4191, %r2713;
	// end inline asm
	ld.const.u32 	%r2722, [matrix+2588];
	// begin inline asm
	dp4a.u32.u32 %r2721, %r2722, %r4195, %r2717;
	// end inline asm
	ld.const.u32 	%r2726, [matrix+2592];
	// begin inline asm
	dp4a.u32.u32 %r2725, %r2726, %r4199, %r2721;
	// end inline asm
	ld.const.u32 	%r2730, [matrix+2596];
	// begin inline asm
	dp4a.u32.u32 %r2729, %r2730, %r4203, %r2725;
	// end inline asm
	ld.const.u32 	%r2734, [matrix+2600];
	// begin inline asm
	dp4a.u32.u32 %r2733, %r2734, %r4207, %r2729;
	// end inline asm
	ld.const.u32 	%r2738, [matrix+2604];
	// begin inline asm
	dp4a.u32.u32 %r2737, %r2738, %r4211, %r2733;
	// end inline asm
	ld.const.u32 	%r2742, [matrix+2608];
	// begin inline asm
	dp4a.u32.u32 %r2741, %r2742, %r4215, %r2737;
	// end inline asm
	ld.const.u32 	%r2746, [matrix+2612];
	// begin inline asm
	dp4a.u32.u32 %r2745, %r2746, %r4219, %r2741;
	// end inline asm
	ld.const.u32 	%r2750, [matrix+2616];
	// begin inline asm
	dp4a.u32.u32 %r2749, %r2750, %r4223, %r2745;
	// end inline asm
	ld.const.u32 	%r2754, [matrix+2620];
	// begin inline asm
	dp4a.u32.u32 %r2753, %r2754, %r4227, %r2749;
	// end inline asm
	ld.const.u32 	%r2758, [matrix+2624];
	// begin inline asm
	dp4a.u32.u32 %r2757, %r2758, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2762, [matrix+2628];
	// begin inline asm
	dp4a.u32.u32 %r2761, %r2762, %r4171, %r2757;
	// end inline asm
	ld.const.u32 	%r2766, [matrix+2632];
	// begin inline asm
	dp4a.u32.u32 %r2765, %r2766, %r4175, %r2761;
	// end inline asm
	ld.const.u32 	%r2770, [matrix+2636];
	// begin inline asm
	dp4a.u32.u32 %r2769, %r2770, %r4179, %r2765;
	// end inline asm
	ld.const.u32 	%r2774, [matrix+2640];
	// begin inline asm
	dp4a.u32.u32 %r2773, %r2774, %r4183, %r2769;
	// end inline asm
	ld.const.u32 	%r2778, [matrix+2644];
	// begin inline asm
	dp4a.u32.u32 %r2777, %r2778, %r4187, %r2773;
	// end inline asm
	ld.const.u32 	%r2782, [matrix+2648];
	// begin inline asm
	dp4a.u32.u32 %r2781, %r2782, %r4191, %r2777;
	// end inline asm
	ld.const.u32 	%r2786, [matrix+2652];
	// begin inline asm
	dp4a.u32.u32 %r2785, %r2786, %r4195, %r2781;
	// end inline asm
	ld.const.u32 	%r2790, [matrix+2656];
	// begin inline asm
	dp4a.u32.u32 %r2789, %r2790, %r4199, %r2785;
	// end inline asm
	ld.const.u32 	%r2794, [matrix+2660];
	// begin inline asm
	dp4a.u32.u32 %r2793, %r2794, %r4203, %r2789;
	// end inline asm
	ld.const.u32 	%r2798, [matrix+2664];
	// begin inline asm
	dp4a.u32.u32 %r2797, %r2798, %r4207, %r2793;
	// end inline asm
	ld.const.u32 	%r2802, [matrix+2668];
	// begin inline asm
	dp4a.u32.u32 %r2801, %r2802, %r4211, %r2797;
	// end inline asm
	ld.const.u32 	%r2806, [matrix+2672];
	// begin inline asm
	dp4a.u32.u32 %r2805, %r2806, %r4215, %r2801;
	// end inline asm
	ld.const.u32 	%r2810, [matrix+2676];
	// begin inline asm
	dp4a.u32.u32 %r2809, %r2810, %r4219, %r2805;
	// end inline asm
	ld.const.u32 	%r2814, [matrix+2680];
	// begin inline asm
	dp4a.u32.u32 %r2813, %r2814, %r4223, %r2809;
	// end inline asm
	ld.const.u32 	%r2818, [matrix+2684];
	// begin inline asm
	dp4a.u32.u32 %r2817, %r2818, %r4227, %r2813;
	// end inline asm
	shr.u32 	%r4478, %r2753, 6;
	and.b32  	%r4479, %r4478, 240;
	shr.u32 	%r4480, %r2817, 10;
	or.b32  	%r4481, %r4480, %r4479;
	cvt.u64.u32 	%rd414, %r4481;
	xor.b64  	%rd415, %rd353, %rd414;
	ld.const.u32 	%r2822, [matrix+2688];
	// begin inline asm
	dp4a.u32.u32 %r2821, %r2822, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2826, [matrix+2692];
	// begin inline asm
	dp4a.u32.u32 %r2825, %r2826, %r4171, %r2821;
	// end inline asm
	ld.const.u32 	%r2830, [matrix+2696];
	// begin inline asm
	dp4a.u32.u32 %r2829, %r2830, %r4175, %r2825;
	// end inline asm
	ld.const.u32 	%r2834, [matrix+2700];
	// begin inline asm
	dp4a.u32.u32 %r2833, %r2834, %r4179, %r2829;
	// end inline asm
	ld.const.u32 	%r2838, [matrix+2704];
	// begin inline asm
	dp4a.u32.u32 %r2837, %r2838, %r4183, %r2833;
	// end inline asm
	ld.const.u32 	%r2842, [matrix+2708];
	// begin inline asm
	dp4a.u32.u32 %r2841, %r2842, %r4187, %r2837;
	// end inline asm
	ld.const.u32 	%r2846, [matrix+2712];
	// begin inline asm
	dp4a.u32.u32 %r2845, %r2846, %r4191, %r2841;
	// end inline asm
	ld.const.u32 	%r2850, [matrix+2716];
	// begin inline asm
	dp4a.u32.u32 %r2849, %r2850, %r4195, %r2845;
	// end inline asm
	ld.const.u32 	%r2854, [matrix+2720];
	// begin inline asm
	dp4a.u32.u32 %r2853, %r2854, %r4199, %r2849;
	// end inline asm
	ld.const.u32 	%r2858, [matrix+2724];
	// begin inline asm
	dp4a.u32.u32 %r2857, %r2858, %r4203, %r2853;
	// end inline asm
	ld.const.u32 	%r2862, [matrix+2728];
	// begin inline asm
	dp4a.u32.u32 %r2861, %r2862, %r4207, %r2857;
	// end inline asm
	ld.const.u32 	%r2866, [matrix+2732];
	// begin inline asm
	dp4a.u32.u32 %r2865, %r2866, %r4211, %r2861;
	// end inline asm
	ld.const.u32 	%r2870, [matrix+2736];
	// begin inline asm
	dp4a.u32.u32 %r2869, %r2870, %r4215, %r2865;
	// end inline asm
	ld.const.u32 	%r2874, [matrix+2740];
	// begin inline asm
	dp4a.u32.u32 %r2873, %r2874, %r4219, %r2869;
	// end inline asm
	ld.const.u32 	%r2878, [matrix+2744];
	// begin inline asm
	dp4a.u32.u32 %r2877, %r2878, %r4223, %r2873;
	// end inline asm
	ld.const.u32 	%r2882, [matrix+2748];
	// begin inline asm
	dp4a.u32.u32 %r2881, %r2882, %r4227, %r2877;
	// end inline asm
	ld.const.u32 	%r2886, [matrix+2752];
	// begin inline asm
	dp4a.u32.u32 %r2885, %r2886, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2890, [matrix+2756];
	// begin inline asm
	dp4a.u32.u32 %r2889, %r2890, %r4171, %r2885;
	// end inline asm
	ld.const.u32 	%r2894, [matrix+2760];
	// begin inline asm
	dp4a.u32.u32 %r2893, %r2894, %r4175, %r2889;
	// end inline asm
	ld.const.u32 	%r2898, [matrix+2764];
	// begin inline asm
	dp4a.u32.u32 %r2897, %r2898, %r4179, %r2893;
	// end inline asm
	ld.const.u32 	%r2902, [matrix+2768];
	// begin inline asm
	dp4a.u32.u32 %r2901, %r2902, %r4183, %r2897;
	// end inline asm
	ld.const.u32 	%r2906, [matrix+2772];
	// begin inline asm
	dp4a.u32.u32 %r2905, %r2906, %r4187, %r2901;
	// end inline asm
	ld.const.u32 	%r2910, [matrix+2776];
	// begin inline asm
	dp4a.u32.u32 %r2909, %r2910, %r4191, %r2905;
	// end inline asm
	ld.const.u32 	%r2914, [matrix+2780];
	// begin inline asm
	dp4a.u32.u32 %r2913, %r2914, %r4195, %r2909;
	// end inline asm
	ld.const.u32 	%r2918, [matrix+2784];
	// begin inline asm
	dp4a.u32.u32 %r2917, %r2918, %r4199, %r2913;
	// end inline asm
	ld.const.u32 	%r2922, [matrix+2788];
	// begin inline asm
	dp4a.u32.u32 %r2921, %r2922, %r4203, %r2917;
	// end inline asm
	ld.const.u32 	%r2926, [matrix+2792];
	// begin inline asm
	dp4a.u32.u32 %r2925, %r2926, %r4207, %r2921;
	// end inline asm
	ld.const.u32 	%r2930, [matrix+2796];
	// begin inline asm
	dp4a.u32.u32 %r2929, %r2930, %r4211, %r2925;
	// end inline asm
	ld.const.u32 	%r2934, [matrix+2800];
	// begin inline asm
	dp4a.u32.u32 %r2933, %r2934, %r4215, %r2929;
	// end inline asm
	ld.const.u32 	%r2938, [matrix+2804];
	// begin inline asm
	dp4a.u32.u32 %r2937, %r2938, %r4219, %r2933;
	// end inline asm
	ld.const.u32 	%r2942, [matrix+2808];
	// begin inline asm
	dp4a.u32.u32 %r2941, %r2942, %r4223, %r2937;
	// end inline asm
	ld.const.u32 	%r2946, [matrix+2812];
	// begin inline asm
	dp4a.u32.u32 %r2945, %r2946, %r4227, %r2941;
	// end inline asm
	shr.u32 	%r4482, %r2881, 6;
	and.b32  	%r4483, %r4482, 240;
	shr.u32 	%r4484, %r2945, 10;
	or.b32  	%r4485, %r4484, %r4483;
	cvt.u64.u32 	%rd416, %r4485;
	xor.b64  	%rd417, %rd354, %rd416;
	ld.const.u32 	%r2950, [matrix+2816];
	// begin inline asm
	dp4a.u32.u32 %r2949, %r2950, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r2954, [matrix+2820];
	// begin inline asm
	dp4a.u32.u32 %r2953, %r2954, %r4171, %r2949;
	// end inline asm
	ld.const.u32 	%r2958, [matrix+2824];
	// begin inline asm
	dp4a.u32.u32 %r2957, %r2958, %r4175, %r2953;
	// end inline asm
	ld.const.u32 	%r2962, [matrix+2828];
	// begin inline asm
	dp4a.u32.u32 %r2961, %r2962, %r4179, %r2957;
	// end inline asm
	ld.const.u32 	%r2966, [matrix+2832];
	// begin inline asm
	dp4a.u32.u32 %r2965, %r2966, %r4183, %r2961;
	// end inline asm
	ld.const.u32 	%r2970, [matrix+2836];
	// begin inline asm
	dp4a.u32.u32 %r2969, %r2970, %r4187, %r2965;
	// end inline asm
	ld.const.u32 	%r2974, [matrix+2840];
	// begin inline asm
	dp4a.u32.u32 %r2973, %r2974, %r4191, %r2969;
	// end inline asm
	ld.const.u32 	%r2978, [matrix+2844];
	// begin inline asm
	dp4a.u32.u32 %r2977, %r2978, %r4195, %r2973;
	// end inline asm
	ld.const.u32 	%r2982, [matrix+2848];
	// begin inline asm
	dp4a.u32.u32 %r2981, %r2982, %r4199, %r2977;
	// end inline asm
	ld.const.u32 	%r2986, [matrix+2852];
	// begin inline asm
	dp4a.u32.u32 %r2985, %r2986, %r4203, %r2981;
	// end inline asm
	ld.const.u32 	%r2990, [matrix+2856];
	// begin inline asm
	dp4a.u32.u32 %r2989, %r2990, %r4207, %r2985;
	// end inline asm
	ld.const.u32 	%r2994, [matrix+2860];
	// begin inline asm
	dp4a.u32.u32 %r2993, %r2994, %r4211, %r2989;
	// end inline asm
	ld.const.u32 	%r2998, [matrix+2864];
	// begin inline asm
	dp4a.u32.u32 %r2997, %r2998, %r4215, %r2993;
	// end inline asm
	ld.const.u32 	%r3002, [matrix+2868];
	// begin inline asm
	dp4a.u32.u32 %r3001, %r3002, %r4219, %r2997;
	// end inline asm
	ld.const.u32 	%r3006, [matrix+2872];
	// begin inline asm
	dp4a.u32.u32 %r3005, %r3006, %r4223, %r3001;
	// end inline asm
	ld.const.u32 	%r3010, [matrix+2876];
	// begin inline asm
	dp4a.u32.u32 %r3009, %r3010, %r4227, %r3005;
	// end inline asm
	ld.const.u32 	%r3014, [matrix+2880];
	// begin inline asm
	dp4a.u32.u32 %r3013, %r3014, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3018, [matrix+2884];
	// begin inline asm
	dp4a.u32.u32 %r3017, %r3018, %r4171, %r3013;
	// end inline asm
	ld.const.u32 	%r3022, [matrix+2888];
	// begin inline asm
	dp4a.u32.u32 %r3021, %r3022, %r4175, %r3017;
	// end inline asm
	ld.const.u32 	%r3026, [matrix+2892];
	// begin inline asm
	dp4a.u32.u32 %r3025, %r3026, %r4179, %r3021;
	// end inline asm
	ld.const.u32 	%r3030, [matrix+2896];
	// begin inline asm
	dp4a.u32.u32 %r3029, %r3030, %r4183, %r3025;
	// end inline asm
	ld.const.u32 	%r3034, [matrix+2900];
	// begin inline asm
	dp4a.u32.u32 %r3033, %r3034, %r4187, %r3029;
	// end inline asm
	ld.const.u32 	%r3038, [matrix+2904];
	// begin inline asm
	dp4a.u32.u32 %r3037, %r3038, %r4191, %r3033;
	// end inline asm
	ld.const.u32 	%r3042, [matrix+2908];
	// begin inline asm
	dp4a.u32.u32 %r3041, %r3042, %r4195, %r3037;
	// end inline asm
	ld.const.u32 	%r3046, [matrix+2912];
	// begin inline asm
	dp4a.u32.u32 %r3045, %r3046, %r4199, %r3041;
	// end inline asm
	ld.const.u32 	%r3050, [matrix+2916];
	// begin inline asm
	dp4a.u32.u32 %r3049, %r3050, %r4203, %r3045;
	// end inline asm
	ld.const.u32 	%r3054, [matrix+2920];
	// begin inline asm
	dp4a.u32.u32 %r3053, %r3054, %r4207, %r3049;
	// end inline asm
	ld.const.u32 	%r3058, [matrix+2924];
	// begin inline asm
	dp4a.u32.u32 %r3057, %r3058, %r4211, %r3053;
	// end inline asm
	ld.const.u32 	%r3062, [matrix+2928];
	// begin inline asm
	dp4a.u32.u32 %r3061, %r3062, %r4215, %r3057;
	// end inline asm
	ld.const.u32 	%r3066, [matrix+2932];
	// begin inline asm
	dp4a.u32.u32 %r3065, %r3066, %r4219, %r3061;
	// end inline asm
	ld.const.u32 	%r3070, [matrix+2936];
	// begin inline asm
	dp4a.u32.u32 %r3069, %r3070, %r4223, %r3065;
	// end inline asm
	ld.const.u32 	%r3074, [matrix+2940];
	// begin inline asm
	dp4a.u32.u32 %r3073, %r3074, %r4227, %r3069;
	// end inline asm
	shr.u32 	%r4486, %r3009, 6;
	and.b32  	%r4487, %r4486, 240;
	shr.u32 	%r4488, %r3073, 10;
	or.b32  	%r4489, %r4488, %r4487;
	cvt.u64.u32 	%rd418, %r4489;
	xor.b64  	%rd419, %rd355, %rd418;
	ld.const.u32 	%r3078, [matrix+2944];
	// begin inline asm
	dp4a.u32.u32 %r3077, %r3078, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3082, [matrix+2948];
	// begin inline asm
	dp4a.u32.u32 %r3081, %r3082, %r4171, %r3077;
	// end inline asm
	ld.const.u32 	%r3086, [matrix+2952];
	// begin inline asm
	dp4a.u32.u32 %r3085, %r3086, %r4175, %r3081;
	// end inline asm
	ld.const.u32 	%r3090, [matrix+2956];
	// begin inline asm
	dp4a.u32.u32 %r3089, %r3090, %r4179, %r3085;
	// end inline asm
	ld.const.u32 	%r3094, [matrix+2960];
	// begin inline asm
	dp4a.u32.u32 %r3093, %r3094, %r4183, %r3089;
	// end inline asm
	ld.const.u32 	%r3098, [matrix+2964];
	// begin inline asm
	dp4a.u32.u32 %r3097, %r3098, %r4187, %r3093;
	// end inline asm
	ld.const.u32 	%r3102, [matrix+2968];
	// begin inline asm
	dp4a.u32.u32 %r3101, %r3102, %r4191, %r3097;
	// end inline asm
	ld.const.u32 	%r3106, [matrix+2972];
	// begin inline asm
	dp4a.u32.u32 %r3105, %r3106, %r4195, %r3101;
	// end inline asm
	ld.const.u32 	%r3110, [matrix+2976];
	// begin inline asm
	dp4a.u32.u32 %r3109, %r3110, %r4199, %r3105;
	// end inline asm
	ld.const.u32 	%r3114, [matrix+2980];
	// begin inline asm
	dp4a.u32.u32 %r3113, %r3114, %r4203, %r3109;
	// end inline asm
	ld.const.u32 	%r3118, [matrix+2984];
	// begin inline asm
	dp4a.u32.u32 %r3117, %r3118, %r4207, %r3113;
	// end inline asm
	ld.const.u32 	%r3122, [matrix+2988];
	// begin inline asm
	dp4a.u32.u32 %r3121, %r3122, %r4211, %r3117;
	// end inline asm
	ld.const.u32 	%r3126, [matrix+2992];
	// begin inline asm
	dp4a.u32.u32 %r3125, %r3126, %r4215, %r3121;
	// end inline asm
	ld.const.u32 	%r3130, [matrix+2996];
	// begin inline asm
	dp4a.u32.u32 %r3129, %r3130, %r4219, %r3125;
	// end inline asm
	ld.const.u32 	%r3134, [matrix+3000];
	// begin inline asm
	dp4a.u32.u32 %r3133, %r3134, %r4223, %r3129;
	// end inline asm
	ld.const.u32 	%r3138, [matrix+3004];
	// begin inline asm
	dp4a.u32.u32 %r3137, %r3138, %r4227, %r3133;
	// end inline asm
	ld.const.u32 	%r3142, [matrix+3008];
	// begin inline asm
	dp4a.u32.u32 %r3141, %r3142, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3146, [matrix+3012];
	// begin inline asm
	dp4a.u32.u32 %r3145, %r3146, %r4171, %r3141;
	// end inline asm
	ld.const.u32 	%r3150, [matrix+3016];
	// begin inline asm
	dp4a.u32.u32 %r3149, %r3150, %r4175, %r3145;
	// end inline asm
	ld.const.u32 	%r3154, [matrix+3020];
	// begin inline asm
	dp4a.u32.u32 %r3153, %r3154, %r4179, %r3149;
	// end inline asm
	ld.const.u32 	%r3158, [matrix+3024];
	// begin inline asm
	dp4a.u32.u32 %r3157, %r3158, %r4183, %r3153;
	// end inline asm
	ld.const.u32 	%r3162, [matrix+3028];
	// begin inline asm
	dp4a.u32.u32 %r3161, %r3162, %r4187, %r3157;
	// end inline asm
	ld.const.u32 	%r3166, [matrix+3032];
	// begin inline asm
	dp4a.u32.u32 %r3165, %r3166, %r4191, %r3161;
	// end inline asm
	ld.const.u32 	%r3170, [matrix+3036];
	// begin inline asm
	dp4a.u32.u32 %r3169, %r3170, %r4195, %r3165;
	// end inline asm
	ld.const.u32 	%r3174, [matrix+3040];
	// begin inline asm
	dp4a.u32.u32 %r3173, %r3174, %r4199, %r3169;
	// end inline asm
	ld.const.u32 	%r3178, [matrix+3044];
	// begin inline asm
	dp4a.u32.u32 %r3177, %r3178, %r4203, %r3173;
	// end inline asm
	ld.const.u32 	%r3182, [matrix+3048];
	// begin inline asm
	dp4a.u32.u32 %r3181, %r3182, %r4207, %r3177;
	// end inline asm
	ld.const.u32 	%r3186, [matrix+3052];
	// begin inline asm
	dp4a.u32.u32 %r3185, %r3186, %r4211, %r3181;
	// end inline asm
	ld.const.u32 	%r3190, [matrix+3056];
	// begin inline asm
	dp4a.u32.u32 %r3189, %r3190, %r4215, %r3185;
	// end inline asm
	ld.const.u32 	%r3194, [matrix+3060];
	// begin inline asm
	dp4a.u32.u32 %r3193, %r3194, %r4219, %r3189;
	// end inline asm
	ld.const.u32 	%r3198, [matrix+3064];
	// begin inline asm
	dp4a.u32.u32 %r3197, %r3198, %r4223, %r3193;
	// end inline asm
	ld.const.u32 	%r3202, [matrix+3068];
	// begin inline asm
	dp4a.u32.u32 %r3201, %r3202, %r4227, %r3197;
	// end inline asm
	shr.u32 	%r4490, %r3137, 6;
	and.b32  	%r4491, %r4490, 240;
	shr.u32 	%r4492, %r3201, 10;
	or.b32  	%r4493, %r4492, %r4491;
	cvt.u64.u32 	%rd420, %r4493;
	ld.const.u32 	%r3206, [matrix+3072];
	// begin inline asm
	dp4a.u32.u32 %r3205, %r3206, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3210, [matrix+3076];
	// begin inline asm
	dp4a.u32.u32 %r3209, %r3210, %r4171, %r3205;
	// end inline asm
	ld.const.u32 	%r3214, [matrix+3080];
	// begin inline asm
	dp4a.u32.u32 %r3213, %r3214, %r4175, %r3209;
	// end inline asm
	ld.const.u32 	%r3218, [matrix+3084];
	// begin inline asm
	dp4a.u32.u32 %r3217, %r3218, %r4179, %r3213;
	// end inline asm
	ld.const.u32 	%r3222, [matrix+3088];
	// begin inline asm
	dp4a.u32.u32 %r3221, %r3222, %r4183, %r3217;
	// end inline asm
	ld.const.u32 	%r3226, [matrix+3092];
	// begin inline asm
	dp4a.u32.u32 %r3225, %r3226, %r4187, %r3221;
	// end inline asm
	ld.const.u32 	%r3230, [matrix+3096];
	// begin inline asm
	dp4a.u32.u32 %r3229, %r3230, %r4191, %r3225;
	// end inline asm
	ld.const.u32 	%r3234, [matrix+3100];
	// begin inline asm
	dp4a.u32.u32 %r3233, %r3234, %r4195, %r3229;
	// end inline asm
	ld.const.u32 	%r3238, [matrix+3104];
	// begin inline asm
	dp4a.u32.u32 %r3237, %r3238, %r4199, %r3233;
	// end inline asm
	ld.const.u32 	%r3242, [matrix+3108];
	// begin inline asm
	dp4a.u32.u32 %r3241, %r3242, %r4203, %r3237;
	// end inline asm
	ld.const.u32 	%r3246, [matrix+3112];
	// begin inline asm
	dp4a.u32.u32 %r3245, %r3246, %r4207, %r3241;
	// end inline asm
	ld.const.u32 	%r3250, [matrix+3116];
	// begin inline asm
	dp4a.u32.u32 %r3249, %r3250, %r4211, %r3245;
	// end inline asm
	ld.const.u32 	%r3254, [matrix+3120];
	// begin inline asm
	dp4a.u32.u32 %r3253, %r3254, %r4215, %r3249;
	// end inline asm
	ld.const.u32 	%r3258, [matrix+3124];
	// begin inline asm
	dp4a.u32.u32 %r3257, %r3258, %r4219, %r3253;
	// end inline asm
	ld.const.u32 	%r3262, [matrix+3128];
	// begin inline asm
	dp4a.u32.u32 %r3261, %r3262, %r4223, %r3257;
	// end inline asm
	ld.const.u32 	%r3266, [matrix+3132];
	// begin inline asm
	dp4a.u32.u32 %r3265, %r3266, %r4227, %r3261;
	// end inline asm
	ld.const.u32 	%r3270, [matrix+3136];
	// begin inline asm
	dp4a.u32.u32 %r3269, %r3270, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3274, [matrix+3140];
	// begin inline asm
	dp4a.u32.u32 %r3273, %r3274, %r4171, %r3269;
	// end inline asm
	ld.const.u32 	%r3278, [matrix+3144];
	// begin inline asm
	dp4a.u32.u32 %r3277, %r3278, %r4175, %r3273;
	// end inline asm
	ld.const.u32 	%r3282, [matrix+3148];
	// begin inline asm
	dp4a.u32.u32 %r3281, %r3282, %r4179, %r3277;
	// end inline asm
	ld.const.u32 	%r3286, [matrix+3152];
	// begin inline asm
	dp4a.u32.u32 %r3285, %r3286, %r4183, %r3281;
	// end inline asm
	ld.const.u32 	%r3290, [matrix+3156];
	// begin inline asm
	dp4a.u32.u32 %r3289, %r3290, %r4187, %r3285;
	// end inline asm
	ld.const.u32 	%r3294, [matrix+3160];
	// begin inline asm
	dp4a.u32.u32 %r3293, %r3294, %r4191, %r3289;
	// end inline asm
	ld.const.u32 	%r3298, [matrix+3164];
	// begin inline asm
	dp4a.u32.u32 %r3297, %r3298, %r4195, %r3293;
	// end inline asm
	ld.const.u32 	%r3302, [matrix+3168];
	// begin inline asm
	dp4a.u32.u32 %r3301, %r3302, %r4199, %r3297;
	// end inline asm
	ld.const.u32 	%r3306, [matrix+3172];
	// begin inline asm
	dp4a.u32.u32 %r3305, %r3306, %r4203, %r3301;
	// end inline asm
	ld.const.u32 	%r3310, [matrix+3176];
	// begin inline asm
	dp4a.u32.u32 %r3309, %r3310, %r4207, %r3305;
	// end inline asm
	ld.const.u32 	%r3314, [matrix+3180];
	// begin inline asm
	dp4a.u32.u32 %r3313, %r3314, %r4211, %r3309;
	// end inline asm
	ld.const.u32 	%r3318, [matrix+3184];
	// begin inline asm
	dp4a.u32.u32 %r3317, %r3318, %r4215, %r3313;
	// end inline asm
	ld.const.u32 	%r3322, [matrix+3188];
	// begin inline asm
	dp4a.u32.u32 %r3321, %r3322, %r4219, %r3317;
	// end inline asm
	ld.const.u32 	%r3326, [matrix+3192];
	// begin inline asm
	dp4a.u32.u32 %r3325, %r3326, %r4223, %r3321;
	// end inline asm
	ld.const.u32 	%r3330, [matrix+3196];
	// begin inline asm
	dp4a.u32.u32 %r3329, %r3330, %r4227, %r3325;
	// end inline asm
	shr.u32 	%r4494, %r3265, 6;
	and.b32  	%r4495, %r4494, 240;
	bfe.u32 	%r4496, %r3329, 10, 8;
	or.b32  	%r4497, %r4496, %r4495;
	cvt.u64.u32 	%rd421, %r4497;
	ld.const.u32 	%r3334, [matrix+3200];
	// begin inline asm
	dp4a.u32.u32 %r3333, %r3334, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3338, [matrix+3204];
	// begin inline asm
	dp4a.u32.u32 %r3337, %r3338, %r4171, %r3333;
	// end inline asm
	ld.const.u32 	%r3342, [matrix+3208];
	// begin inline asm
	dp4a.u32.u32 %r3341, %r3342, %r4175, %r3337;
	// end inline asm
	ld.const.u32 	%r3346, [matrix+3212];
	// begin inline asm
	dp4a.u32.u32 %r3345, %r3346, %r4179, %r3341;
	// end inline asm
	ld.const.u32 	%r3350, [matrix+3216];
	// begin inline asm
	dp4a.u32.u32 %r3349, %r3350, %r4183, %r3345;
	// end inline asm
	ld.const.u32 	%r3354, [matrix+3220];
	// begin inline asm
	dp4a.u32.u32 %r3353, %r3354, %r4187, %r3349;
	// end inline asm
	ld.const.u32 	%r3358, [matrix+3224];
	// begin inline asm
	dp4a.u32.u32 %r3357, %r3358, %r4191, %r3353;
	// end inline asm
	ld.const.u32 	%r3362, [matrix+3228];
	// begin inline asm
	dp4a.u32.u32 %r3361, %r3362, %r4195, %r3357;
	// end inline asm
	ld.const.u32 	%r3366, [matrix+3232];
	// begin inline asm
	dp4a.u32.u32 %r3365, %r3366, %r4199, %r3361;
	// end inline asm
	ld.const.u32 	%r3370, [matrix+3236];
	// begin inline asm
	dp4a.u32.u32 %r3369, %r3370, %r4203, %r3365;
	// end inline asm
	ld.const.u32 	%r3374, [matrix+3240];
	// begin inline asm
	dp4a.u32.u32 %r3373, %r3374, %r4207, %r3369;
	// end inline asm
	ld.const.u32 	%r3378, [matrix+3244];
	// begin inline asm
	dp4a.u32.u32 %r3377, %r3378, %r4211, %r3373;
	// end inline asm
	ld.const.u32 	%r3382, [matrix+3248];
	// begin inline asm
	dp4a.u32.u32 %r3381, %r3382, %r4215, %r3377;
	// end inline asm
	ld.const.u32 	%r3386, [matrix+3252];
	// begin inline asm
	dp4a.u32.u32 %r3385, %r3386, %r4219, %r3381;
	// end inline asm
	ld.const.u32 	%r3390, [matrix+3256];
	// begin inline asm
	dp4a.u32.u32 %r3389, %r3390, %r4223, %r3385;
	// end inline asm
	ld.const.u32 	%r3394, [matrix+3260];
	// begin inline asm
	dp4a.u32.u32 %r3393, %r3394, %r4227, %r3389;
	// end inline asm
	ld.const.u32 	%r3398, [matrix+3264];
	// begin inline asm
	dp4a.u32.u32 %r3397, %r3398, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3402, [matrix+3268];
	// begin inline asm
	dp4a.u32.u32 %r3401, %r3402, %r4171, %r3397;
	// end inline asm
	ld.const.u32 	%r3406, [matrix+3272];
	// begin inline asm
	dp4a.u32.u32 %r3405, %r3406, %r4175, %r3401;
	// end inline asm
	ld.const.u32 	%r3410, [matrix+3276];
	// begin inline asm
	dp4a.u32.u32 %r3409, %r3410, %r4179, %r3405;
	// end inline asm
	ld.const.u32 	%r3414, [matrix+3280];
	// begin inline asm
	dp4a.u32.u32 %r3413, %r3414, %r4183, %r3409;
	// end inline asm
	ld.const.u32 	%r3418, [matrix+3284];
	// begin inline asm
	dp4a.u32.u32 %r3417, %r3418, %r4187, %r3413;
	// end inline asm
	ld.const.u32 	%r3422, [matrix+3288];
	// begin inline asm
	dp4a.u32.u32 %r3421, %r3422, %r4191, %r3417;
	// end inline asm
	ld.const.u32 	%r3426, [matrix+3292];
	// begin inline asm
	dp4a.u32.u32 %r3425, %r3426, %r4195, %r3421;
	// end inline asm
	ld.const.u32 	%r3430, [matrix+3296];
	// begin inline asm
	dp4a.u32.u32 %r3429, %r3430, %r4199, %r3425;
	// end inline asm
	ld.const.u32 	%r3434, [matrix+3300];
	// begin inline asm
	dp4a.u32.u32 %r3433, %r3434, %r4203, %r3429;
	// end inline asm
	ld.const.u32 	%r3438, [matrix+3304];
	// begin inline asm
	dp4a.u32.u32 %r3437, %r3438, %r4207, %r3433;
	// end inline asm
	ld.const.u32 	%r3442, [matrix+3308];
	// begin inline asm
	dp4a.u32.u32 %r3441, %r3442, %r4211, %r3437;
	// end inline asm
	ld.const.u32 	%r3446, [matrix+3312];
	// begin inline asm
	dp4a.u32.u32 %r3445, %r3446, %r4215, %r3441;
	// end inline asm
	ld.const.u32 	%r3450, [matrix+3316];
	// begin inline asm
	dp4a.u32.u32 %r3449, %r3450, %r4219, %r3445;
	// end inline asm
	ld.const.u32 	%r3454, [matrix+3320];
	// begin inline asm
	dp4a.u32.u32 %r3453, %r3454, %r4223, %r3449;
	// end inline asm
	ld.const.u32 	%r3458, [matrix+3324];
	// begin inline asm
	dp4a.u32.u32 %r3457, %r3458, %r4227, %r3453;
	// end inline asm
	shr.u32 	%r4498, %r3393, 6;
	and.b32  	%r4499, %r4498, 240;
	shr.u32 	%r4500, %r3457, 10;
	or.b32  	%r4501, %r4500, %r4499;
	cvt.u64.u32 	%rd422, %r4501;
	xor.b64  	%rd423, %rd366, %rd422;
	and.b64  	%rd424, %rd670, 255;
	xor.b64  	%rd425, %rd424, %rd421;
	ld.const.u32 	%r3462, [matrix+3328];
	// begin inline asm
	dp4a.u32.u32 %r3461, %r3462, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3466, [matrix+3332];
	// begin inline asm
	dp4a.u32.u32 %r3465, %r3466, %r4171, %r3461;
	// end inline asm
	ld.const.u32 	%r3470, [matrix+3336];
	// begin inline asm
	dp4a.u32.u32 %r3469, %r3470, %r4175, %r3465;
	// end inline asm
	ld.const.u32 	%r3474, [matrix+3340];
	// begin inline asm
	dp4a.u32.u32 %r3473, %r3474, %r4179, %r3469;
	// end inline asm
	ld.const.u32 	%r3478, [matrix+3344];
	// begin inline asm
	dp4a.u32.u32 %r3477, %r3478, %r4183, %r3473;
	// end inline asm
	ld.const.u32 	%r3482, [matrix+3348];
	// begin inline asm
	dp4a.u32.u32 %r3481, %r3482, %r4187, %r3477;
	// end inline asm
	ld.const.u32 	%r3486, [matrix+3352];
	// begin inline asm
	dp4a.u32.u32 %r3485, %r3486, %r4191, %r3481;
	// end inline asm
	ld.const.u32 	%r3490, [matrix+3356];
	// begin inline asm
	dp4a.u32.u32 %r3489, %r3490, %r4195, %r3485;
	// end inline asm
	ld.const.u32 	%r3494, [matrix+3360];
	// begin inline asm
	dp4a.u32.u32 %r3493, %r3494, %r4199, %r3489;
	// end inline asm
	ld.const.u32 	%r3498, [matrix+3364];
	// begin inline asm
	dp4a.u32.u32 %r3497, %r3498, %r4203, %r3493;
	// end inline asm
	ld.const.u32 	%r3502, [matrix+3368];
	// begin inline asm
	dp4a.u32.u32 %r3501, %r3502, %r4207, %r3497;
	// end inline asm
	ld.const.u32 	%r3506, [matrix+3372];
	// begin inline asm
	dp4a.u32.u32 %r3505, %r3506, %r4211, %r3501;
	// end inline asm
	ld.const.u32 	%r3510, [matrix+3376];
	// begin inline asm
	dp4a.u32.u32 %r3509, %r3510, %r4215, %r3505;
	// end inline asm
	ld.const.u32 	%r3514, [matrix+3380];
	// begin inline asm
	dp4a.u32.u32 %r3513, %r3514, %r4219, %r3509;
	// end inline asm
	ld.const.u32 	%r3518, [matrix+3384];
	// begin inline asm
	dp4a.u32.u32 %r3517, %r3518, %r4223, %r3513;
	// end inline asm
	ld.const.u32 	%r3522, [matrix+3388];
	// begin inline asm
	dp4a.u32.u32 %r3521, %r3522, %r4227, %r3517;
	// end inline asm
	ld.const.u32 	%r3526, [matrix+3392];
	// begin inline asm
	dp4a.u32.u32 %r3525, %r3526, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3530, [matrix+3396];
	// begin inline asm
	dp4a.u32.u32 %r3529, %r3530, %r4171, %r3525;
	// end inline asm
	ld.const.u32 	%r3534, [matrix+3400];
	// begin inline asm
	dp4a.u32.u32 %r3533, %r3534, %r4175, %r3529;
	// end inline asm
	ld.const.u32 	%r3538, [matrix+3404];
	// begin inline asm
	dp4a.u32.u32 %r3537, %r3538, %r4179, %r3533;
	// end inline asm
	ld.const.u32 	%r3542, [matrix+3408];
	// begin inline asm
	dp4a.u32.u32 %r3541, %r3542, %r4183, %r3537;
	// end inline asm
	ld.const.u32 	%r3546, [matrix+3412];
	// begin inline asm
	dp4a.u32.u32 %r3545, %r3546, %r4187, %r3541;
	// end inline asm
	ld.const.u32 	%r3550, [matrix+3416];
	// begin inline asm
	dp4a.u32.u32 %r3549, %r3550, %r4191, %r3545;
	// end inline asm
	ld.const.u32 	%r3554, [matrix+3420];
	// begin inline asm
	dp4a.u32.u32 %r3553, %r3554, %r4195, %r3549;
	// end inline asm
	ld.const.u32 	%r3558, [matrix+3424];
	// begin inline asm
	dp4a.u32.u32 %r3557, %r3558, %r4199, %r3553;
	// end inline asm
	ld.const.u32 	%r3562, [matrix+3428];
	// begin inline asm
	dp4a.u32.u32 %r3561, %r3562, %r4203, %r3557;
	// end inline asm
	ld.const.u32 	%r3566, [matrix+3432];
	// begin inline asm
	dp4a.u32.u32 %r3565, %r3566, %r4207, %r3561;
	// end inline asm
	ld.const.u32 	%r3570, [matrix+3436];
	// begin inline asm
	dp4a.u32.u32 %r3569, %r3570, %r4211, %r3565;
	// end inline asm
	ld.const.u32 	%r3574, [matrix+3440];
	// begin inline asm
	dp4a.u32.u32 %r3573, %r3574, %r4215, %r3569;
	// end inline asm
	ld.const.u32 	%r3578, [matrix+3444];
	// begin inline asm
	dp4a.u32.u32 %r3577, %r3578, %r4219, %r3573;
	// end inline asm
	ld.const.u32 	%r3582, [matrix+3448];
	// begin inline asm
	dp4a.u32.u32 %r3581, %r3582, %r4223, %r3577;
	// end inline asm
	ld.const.u32 	%r3586, [matrix+3452];
	// begin inline asm
	dp4a.u32.u32 %r3585, %r3586, %r4227, %r3581;
	// end inline asm
	shr.u32 	%r4502, %r3521, 6;
	and.b32  	%r4503, %r4502, 240;
	shr.u32 	%r4504, %r3585, 10;
	or.b32  	%r4505, %r4504, %r4503;
	cvt.u64.u32 	%rd426, %r4505;
	xor.b64  	%rd427, %rd367, %rd426;
	ld.const.u32 	%r3590, [matrix+3456];
	// begin inline asm
	dp4a.u32.u32 %r3589, %r3590, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3594, [matrix+3460];
	// begin inline asm
	dp4a.u32.u32 %r3593, %r3594, %r4171, %r3589;
	// end inline asm
	ld.const.u32 	%r3598, [matrix+3464];
	// begin inline asm
	dp4a.u32.u32 %r3597, %r3598, %r4175, %r3593;
	// end inline asm
	ld.const.u32 	%r3602, [matrix+3468];
	// begin inline asm
	dp4a.u32.u32 %r3601, %r3602, %r4179, %r3597;
	// end inline asm
	ld.const.u32 	%r3606, [matrix+3472];
	// begin inline asm
	dp4a.u32.u32 %r3605, %r3606, %r4183, %r3601;
	// end inline asm
	ld.const.u32 	%r3610, [matrix+3476];
	// begin inline asm
	dp4a.u32.u32 %r3609, %r3610, %r4187, %r3605;
	// end inline asm
	ld.const.u32 	%r3614, [matrix+3480];
	// begin inline asm
	dp4a.u32.u32 %r3613, %r3614, %r4191, %r3609;
	// end inline asm
	ld.const.u32 	%r3618, [matrix+3484];
	// begin inline asm
	dp4a.u32.u32 %r3617, %r3618, %r4195, %r3613;
	// end inline asm
	ld.const.u32 	%r3622, [matrix+3488];
	// begin inline asm
	dp4a.u32.u32 %r3621, %r3622, %r4199, %r3617;
	// end inline asm
	ld.const.u32 	%r3626, [matrix+3492];
	// begin inline asm
	dp4a.u32.u32 %r3625, %r3626, %r4203, %r3621;
	// end inline asm
	ld.const.u32 	%r3630, [matrix+3496];
	// begin inline asm
	dp4a.u32.u32 %r3629, %r3630, %r4207, %r3625;
	// end inline asm
	ld.const.u32 	%r3634, [matrix+3500];
	// begin inline asm
	dp4a.u32.u32 %r3633, %r3634, %r4211, %r3629;
	// end inline asm
	ld.const.u32 	%r3638, [matrix+3504];
	// begin inline asm
	dp4a.u32.u32 %r3637, %r3638, %r4215, %r3633;
	// end inline asm
	ld.const.u32 	%r3642, [matrix+3508];
	// begin inline asm
	dp4a.u32.u32 %r3641, %r3642, %r4219, %r3637;
	// end inline asm
	ld.const.u32 	%r3646, [matrix+3512];
	// begin inline asm
	dp4a.u32.u32 %r3645, %r3646, %r4223, %r3641;
	// end inline asm
	ld.const.u32 	%r3650, [matrix+3516];
	// begin inline asm
	dp4a.u32.u32 %r3649, %r3650, %r4227, %r3645;
	// end inline asm
	ld.const.u32 	%r3654, [matrix+3520];
	// begin inline asm
	dp4a.u32.u32 %r3653, %r3654, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3658, [matrix+3524];
	// begin inline asm
	dp4a.u32.u32 %r3657, %r3658, %r4171, %r3653;
	// end inline asm
	ld.const.u32 	%r3662, [matrix+3528];
	// begin inline asm
	dp4a.u32.u32 %r3661, %r3662, %r4175, %r3657;
	// end inline asm
	ld.const.u32 	%r3666, [matrix+3532];
	// begin inline asm
	dp4a.u32.u32 %r3665, %r3666, %r4179, %r3661;
	// end inline asm
	ld.const.u32 	%r3670, [matrix+3536];
	// begin inline asm
	dp4a.u32.u32 %r3669, %r3670, %r4183, %r3665;
	// end inline asm
	ld.const.u32 	%r3674, [matrix+3540];
	// begin inline asm
	dp4a.u32.u32 %r3673, %r3674, %r4187, %r3669;
	// end inline asm
	ld.const.u32 	%r3678, [matrix+3544];
	// begin inline asm
	dp4a.u32.u32 %r3677, %r3678, %r4191, %r3673;
	// end inline asm
	ld.const.u32 	%r3682, [matrix+3548];
	// begin inline asm
	dp4a.u32.u32 %r3681, %r3682, %r4195, %r3677;
	// end inline asm
	ld.const.u32 	%r3686, [matrix+3552];
	// begin inline asm
	dp4a.u32.u32 %r3685, %r3686, %r4199, %r3681;
	// end inline asm
	ld.const.u32 	%r3690, [matrix+3556];
	// begin inline asm
	dp4a.u32.u32 %r3689, %r3690, %r4203, %r3685;
	// end inline asm
	ld.const.u32 	%r3694, [matrix+3560];
	// begin inline asm
	dp4a.u32.u32 %r3693, %r3694, %r4207, %r3689;
	// end inline asm
	ld.const.u32 	%r3698, [matrix+3564];
	// begin inline asm
	dp4a.u32.u32 %r3697, %r3698, %r4211, %r3693;
	// end inline asm
	ld.const.u32 	%r3702, [matrix+3568];
	// begin inline asm
	dp4a.u32.u32 %r3701, %r3702, %r4215, %r3697;
	// end inline asm
	ld.const.u32 	%r3706, [matrix+3572];
	// begin inline asm
	dp4a.u32.u32 %r3705, %r3706, %r4219, %r3701;
	// end inline asm
	ld.const.u32 	%r3710, [matrix+3576];
	// begin inline asm
	dp4a.u32.u32 %r3709, %r3710, %r4223, %r3705;
	// end inline asm
	ld.const.u32 	%r3714, [matrix+3580];
	// begin inline asm
	dp4a.u32.u32 %r3713, %r3714, %r4227, %r3709;
	// end inline asm
	shr.u32 	%r4506, %r3649, 6;
	and.b32  	%r4507, %r4506, 240;
	shr.u32 	%r4508, %r3713, 10;
	or.b32  	%r4509, %r4508, %r4507;
	cvt.u64.u32 	%rd428, %r4509;
	xor.b64  	%rd429, %rd368, %rd428;
	ld.const.u32 	%r3718, [matrix+3584];
	// begin inline asm
	dp4a.u32.u32 %r3717, %r3718, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3722, [matrix+3588];
	// begin inline asm
	dp4a.u32.u32 %r3721, %r3722, %r4171, %r3717;
	// end inline asm
	ld.const.u32 	%r3726, [matrix+3592];
	// begin inline asm
	dp4a.u32.u32 %r3725, %r3726, %r4175, %r3721;
	// end inline asm
	ld.const.u32 	%r3730, [matrix+3596];
	// begin inline asm
	dp4a.u32.u32 %r3729, %r3730, %r4179, %r3725;
	// end inline asm
	ld.const.u32 	%r3734, [matrix+3600];
	// begin inline asm
	dp4a.u32.u32 %r3733, %r3734, %r4183, %r3729;
	// end inline asm
	ld.const.u32 	%r3738, [matrix+3604];
	// begin inline asm
	dp4a.u32.u32 %r3737, %r3738, %r4187, %r3733;
	// end inline asm
	ld.const.u32 	%r3742, [matrix+3608];
	// begin inline asm
	dp4a.u32.u32 %r3741, %r3742, %r4191, %r3737;
	// end inline asm
	ld.const.u32 	%r3746, [matrix+3612];
	// begin inline asm
	dp4a.u32.u32 %r3745, %r3746, %r4195, %r3741;
	// end inline asm
	ld.const.u32 	%r3750, [matrix+3616];
	// begin inline asm
	dp4a.u32.u32 %r3749, %r3750, %r4199, %r3745;
	// end inline asm
	ld.const.u32 	%r3754, [matrix+3620];
	// begin inline asm
	dp4a.u32.u32 %r3753, %r3754, %r4203, %r3749;
	// end inline asm
	ld.const.u32 	%r3758, [matrix+3624];
	// begin inline asm
	dp4a.u32.u32 %r3757, %r3758, %r4207, %r3753;
	// end inline asm
	ld.const.u32 	%r3762, [matrix+3628];
	// begin inline asm
	dp4a.u32.u32 %r3761, %r3762, %r4211, %r3757;
	// end inline asm
	ld.const.u32 	%r3766, [matrix+3632];
	// begin inline asm
	dp4a.u32.u32 %r3765, %r3766, %r4215, %r3761;
	// end inline asm
	ld.const.u32 	%r3770, [matrix+3636];
	// begin inline asm
	dp4a.u32.u32 %r3769, %r3770, %r4219, %r3765;
	// end inline asm
	ld.const.u32 	%r3774, [matrix+3640];
	// begin inline asm
	dp4a.u32.u32 %r3773, %r3774, %r4223, %r3769;
	// end inline asm
	ld.const.u32 	%r3778, [matrix+3644];
	// begin inline asm
	dp4a.u32.u32 %r3777, %r3778, %r4227, %r3773;
	// end inline asm
	ld.const.u32 	%r3782, [matrix+3648];
	// begin inline asm
	dp4a.u32.u32 %r3781, %r3782, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3786, [matrix+3652];
	// begin inline asm
	dp4a.u32.u32 %r3785, %r3786, %r4171, %r3781;
	// end inline asm
	ld.const.u32 	%r3790, [matrix+3656];
	// begin inline asm
	dp4a.u32.u32 %r3789, %r3790, %r4175, %r3785;
	// end inline asm
	ld.const.u32 	%r3794, [matrix+3660];
	// begin inline asm
	dp4a.u32.u32 %r3793, %r3794, %r4179, %r3789;
	// end inline asm
	ld.const.u32 	%r3798, [matrix+3664];
	// begin inline asm
	dp4a.u32.u32 %r3797, %r3798, %r4183, %r3793;
	// end inline asm
	ld.const.u32 	%r3802, [matrix+3668];
	// begin inline asm
	dp4a.u32.u32 %r3801, %r3802, %r4187, %r3797;
	// end inline asm
	ld.const.u32 	%r3806, [matrix+3672];
	// begin inline asm
	dp4a.u32.u32 %r3805, %r3806, %r4191, %r3801;
	// end inline asm
	ld.const.u32 	%r3810, [matrix+3676];
	// begin inline asm
	dp4a.u32.u32 %r3809, %r3810, %r4195, %r3805;
	// end inline asm
	ld.const.u32 	%r3814, [matrix+3680];
	// begin inline asm
	dp4a.u32.u32 %r3813, %r3814, %r4199, %r3809;
	// end inline asm
	ld.const.u32 	%r3818, [matrix+3684];
	// begin inline asm
	dp4a.u32.u32 %r3817, %r3818, %r4203, %r3813;
	// end inline asm
	ld.const.u32 	%r3822, [matrix+3688];
	// begin inline asm
	dp4a.u32.u32 %r3821, %r3822, %r4207, %r3817;
	// end inline asm
	ld.const.u32 	%r3826, [matrix+3692];
	// begin inline asm
	dp4a.u32.u32 %r3825, %r3826, %r4211, %r3821;
	// end inline asm
	ld.const.u32 	%r3830, [matrix+3696];
	// begin inline asm
	dp4a.u32.u32 %r3829, %r3830, %r4215, %r3825;
	// end inline asm
	ld.const.u32 	%r3834, [matrix+3700];
	// begin inline asm
	dp4a.u32.u32 %r3833, %r3834, %r4219, %r3829;
	// end inline asm
	ld.const.u32 	%r3838, [matrix+3704];
	// begin inline asm
	dp4a.u32.u32 %r3837, %r3838, %r4223, %r3833;
	// end inline asm
	ld.const.u32 	%r3842, [matrix+3708];
	// begin inline asm
	dp4a.u32.u32 %r3841, %r3842, %r4227, %r3837;
	// end inline asm
	shr.u32 	%r4510, %r3777, 6;
	and.b32  	%r4511, %r4510, 240;
	shr.u32 	%r4512, %r3841, 10;
	or.b32  	%r4513, %r4512, %r4511;
	cvt.u64.u32 	%rd430, %r4513;
	xor.b64  	%rd431, %rd369, %rd430;
	ld.const.u32 	%r3846, [matrix+3712];
	// begin inline asm
	dp4a.u32.u32 %r3845, %r3846, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3850, [matrix+3716];
	// begin inline asm
	dp4a.u32.u32 %r3849, %r3850, %r4171, %r3845;
	// end inline asm
	ld.const.u32 	%r3854, [matrix+3720];
	// begin inline asm
	dp4a.u32.u32 %r3853, %r3854, %r4175, %r3849;
	// end inline asm
	ld.const.u32 	%r3858, [matrix+3724];
	// begin inline asm
	dp4a.u32.u32 %r3857, %r3858, %r4179, %r3853;
	// end inline asm
	ld.const.u32 	%r3862, [matrix+3728];
	// begin inline asm
	dp4a.u32.u32 %r3861, %r3862, %r4183, %r3857;
	// end inline asm
	ld.const.u32 	%r3866, [matrix+3732];
	// begin inline asm
	dp4a.u32.u32 %r3865, %r3866, %r4187, %r3861;
	// end inline asm
	ld.const.u32 	%r3870, [matrix+3736];
	// begin inline asm
	dp4a.u32.u32 %r3869, %r3870, %r4191, %r3865;
	// end inline asm
	ld.const.u32 	%r3874, [matrix+3740];
	// begin inline asm
	dp4a.u32.u32 %r3873, %r3874, %r4195, %r3869;
	// end inline asm
	ld.const.u32 	%r3878, [matrix+3744];
	// begin inline asm
	dp4a.u32.u32 %r3877, %r3878, %r4199, %r3873;
	// end inline asm
	ld.const.u32 	%r3882, [matrix+3748];
	// begin inline asm
	dp4a.u32.u32 %r3881, %r3882, %r4203, %r3877;
	// end inline asm
	ld.const.u32 	%r3886, [matrix+3752];
	// begin inline asm
	dp4a.u32.u32 %r3885, %r3886, %r4207, %r3881;
	// end inline asm
	ld.const.u32 	%r3890, [matrix+3756];
	// begin inline asm
	dp4a.u32.u32 %r3889, %r3890, %r4211, %r3885;
	// end inline asm
	ld.const.u32 	%r3894, [matrix+3760];
	// begin inline asm
	dp4a.u32.u32 %r3893, %r3894, %r4215, %r3889;
	// end inline asm
	ld.const.u32 	%r3898, [matrix+3764];
	// begin inline asm
	dp4a.u32.u32 %r3897, %r3898, %r4219, %r3893;
	// end inline asm
	ld.const.u32 	%r3902, [matrix+3768];
	// begin inline asm
	dp4a.u32.u32 %r3901, %r3902, %r4223, %r3897;
	// end inline asm
	ld.const.u32 	%r3906, [matrix+3772];
	// begin inline asm
	dp4a.u32.u32 %r3905, %r3906, %r4227, %r3901;
	// end inline asm
	ld.const.u32 	%r3910, [matrix+3776];
	// begin inline asm
	dp4a.u32.u32 %r3909, %r3910, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3914, [matrix+3780];
	// begin inline asm
	dp4a.u32.u32 %r3913, %r3914, %r4171, %r3909;
	// end inline asm
	ld.const.u32 	%r3918, [matrix+3784];
	// begin inline asm
	dp4a.u32.u32 %r3917, %r3918, %r4175, %r3913;
	// end inline asm
	ld.const.u32 	%r3922, [matrix+3788];
	// begin inline asm
	dp4a.u32.u32 %r3921, %r3922, %r4179, %r3917;
	// end inline asm
	ld.const.u32 	%r3926, [matrix+3792];
	// begin inline asm
	dp4a.u32.u32 %r3925, %r3926, %r4183, %r3921;
	// end inline asm
	ld.const.u32 	%r3930, [matrix+3796];
	// begin inline asm
	dp4a.u32.u32 %r3929, %r3930, %r4187, %r3925;
	// end inline asm
	ld.const.u32 	%r3934, [matrix+3800];
	// begin inline asm
	dp4a.u32.u32 %r3933, %r3934, %r4191, %r3929;
	// end inline asm
	ld.const.u32 	%r3938, [matrix+3804];
	// begin inline asm
	dp4a.u32.u32 %r3937, %r3938, %r4195, %r3933;
	// end inline asm
	ld.const.u32 	%r3942, [matrix+3808];
	// begin inline asm
	dp4a.u32.u32 %r3941, %r3942, %r4199, %r3937;
	// end inline asm
	ld.const.u32 	%r3946, [matrix+3812];
	// begin inline asm
	dp4a.u32.u32 %r3945, %r3946, %r4203, %r3941;
	// end inline asm
	ld.const.u32 	%r3950, [matrix+3816];
	// begin inline asm
	dp4a.u32.u32 %r3949, %r3950, %r4207, %r3945;
	// end inline asm
	ld.const.u32 	%r3954, [matrix+3820];
	// begin inline asm
	dp4a.u32.u32 %r3953, %r3954, %r4211, %r3949;
	// end inline asm
	ld.const.u32 	%r3958, [matrix+3824];
	// begin inline asm
	dp4a.u32.u32 %r3957, %r3958, %r4215, %r3953;
	// end inline asm
	ld.const.u32 	%r3962, [matrix+3828];
	// begin inline asm
	dp4a.u32.u32 %r3961, %r3962, %r4219, %r3957;
	// end inline asm
	ld.const.u32 	%r3966, [matrix+3832];
	// begin inline asm
	dp4a.u32.u32 %r3965, %r3966, %r4223, %r3961;
	// end inline asm
	ld.const.u32 	%r3970, [matrix+3836];
	// begin inline asm
	dp4a.u32.u32 %r3969, %r3970, %r4227, %r3965;
	// end inline asm
	shr.u32 	%r4514, %r3905, 6;
	and.b32  	%r4515, %r4514, 240;
	shr.u32 	%r4516, %r3969, 10;
	or.b32  	%r4517, %r4516, %r4515;
	cvt.u64.u32 	%rd432, %r4517;
	xor.b64  	%rd433, %rd371, %rd432;
	ld.const.u32 	%r3974, [matrix+3840];
	// begin inline asm
	dp4a.u32.u32 %r3973, %r3974, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r3978, [matrix+3844];
	// begin inline asm
	dp4a.u32.u32 %r3977, %r3978, %r4171, %r3973;
	// end inline asm
	ld.const.u32 	%r3982, [matrix+3848];
	// begin inline asm
	dp4a.u32.u32 %r3981, %r3982, %r4175, %r3977;
	// end inline asm
	ld.const.u32 	%r3986, [matrix+3852];
	// begin inline asm
	dp4a.u32.u32 %r3985, %r3986, %r4179, %r3981;
	// end inline asm
	ld.const.u32 	%r3990, [matrix+3856];
	// begin inline asm
	dp4a.u32.u32 %r3989, %r3990, %r4183, %r3985;
	// end inline asm
	ld.const.u32 	%r3994, [matrix+3860];
	// begin inline asm
	dp4a.u32.u32 %r3993, %r3994, %r4187, %r3989;
	// end inline asm
	ld.const.u32 	%r3998, [matrix+3864];
	// begin inline asm
	dp4a.u32.u32 %r3997, %r3998, %r4191, %r3993;
	// end inline asm
	ld.const.u32 	%r4002, [matrix+3868];
	// begin inline asm
	dp4a.u32.u32 %r4001, %r4002, %r4195, %r3997;
	// end inline asm
	ld.const.u32 	%r4006, [matrix+3872];
	// begin inline asm
	dp4a.u32.u32 %r4005, %r4006, %r4199, %r4001;
	// end inline asm
	ld.const.u32 	%r4010, [matrix+3876];
	// begin inline asm
	dp4a.u32.u32 %r4009, %r4010, %r4203, %r4005;
	// end inline asm
	ld.const.u32 	%r4014, [matrix+3880];
	// begin inline asm
	dp4a.u32.u32 %r4013, %r4014, %r4207, %r4009;
	// end inline asm
	ld.const.u32 	%r4018, [matrix+3884];
	// begin inline asm
	dp4a.u32.u32 %r4017, %r4018, %r4211, %r4013;
	// end inline asm
	ld.const.u32 	%r4022, [matrix+3888];
	// begin inline asm
	dp4a.u32.u32 %r4021, %r4022, %r4215, %r4017;
	// end inline asm
	ld.const.u32 	%r4026, [matrix+3892];
	// begin inline asm
	dp4a.u32.u32 %r4025, %r4026, %r4219, %r4021;
	// end inline asm
	ld.const.u32 	%r4030, [matrix+3896];
	// begin inline asm
	dp4a.u32.u32 %r4029, %r4030, %r4223, %r4025;
	// end inline asm
	ld.const.u32 	%r4034, [matrix+3900];
	// begin inline asm
	dp4a.u32.u32 %r4033, %r4034, %r4227, %r4029;
	// end inline asm
	ld.const.u32 	%r4038, [matrix+3904];
	// begin inline asm
	dp4a.u32.u32 %r4037, %r4038, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r4042, [matrix+3908];
	// begin inline asm
	dp4a.u32.u32 %r4041, %r4042, %r4171, %r4037;
	// end inline asm
	ld.const.u32 	%r4046, [matrix+3912];
	// begin inline asm
	dp4a.u32.u32 %r4045, %r4046, %r4175, %r4041;
	// end inline asm
	ld.const.u32 	%r4050, [matrix+3916];
	// begin inline asm
	dp4a.u32.u32 %r4049, %r4050, %r4179, %r4045;
	// end inline asm
	ld.const.u32 	%r4054, [matrix+3920];
	// begin inline asm
	dp4a.u32.u32 %r4053, %r4054, %r4183, %r4049;
	// end inline asm
	ld.const.u32 	%r4058, [matrix+3924];
	// begin inline asm
	dp4a.u32.u32 %r4057, %r4058, %r4187, %r4053;
	// end inline asm
	ld.const.u32 	%r4062, [matrix+3928];
	// begin inline asm
	dp4a.u32.u32 %r4061, %r4062, %r4191, %r4057;
	// end inline asm
	ld.const.u32 	%r4066, [matrix+3932];
	// begin inline asm
	dp4a.u32.u32 %r4065, %r4066, %r4195, %r4061;
	// end inline asm
	ld.const.u32 	%r4070, [matrix+3936];
	// begin inline asm
	dp4a.u32.u32 %r4069, %r4070, %r4199, %r4065;
	// end inline asm
	ld.const.u32 	%r4074, [matrix+3940];
	// begin inline asm
	dp4a.u32.u32 %r4073, %r4074, %r4203, %r4069;
	// end inline asm
	ld.const.u32 	%r4078, [matrix+3944];
	// begin inline asm
	dp4a.u32.u32 %r4077, %r4078, %r4207, %r4073;
	// end inline asm
	ld.const.u32 	%r4082, [matrix+3948];
	// begin inline asm
	dp4a.u32.u32 %r4081, %r4082, %r4211, %r4077;
	// end inline asm
	ld.const.u32 	%r4086, [matrix+3952];
	// begin inline asm
	dp4a.u32.u32 %r4085, %r4086, %r4215, %r4081;
	// end inline asm
	ld.const.u32 	%r4090, [matrix+3956];
	// begin inline asm
	dp4a.u32.u32 %r4089, %r4090, %r4219, %r4085;
	// end inline asm
	ld.const.u32 	%r4094, [matrix+3960];
	// begin inline asm
	dp4a.u32.u32 %r4093, %r4094, %r4223, %r4089;
	// end inline asm
	ld.const.u32 	%r4098, [matrix+3964];
	// begin inline asm
	dp4a.u32.u32 %r4097, %r4098, %r4227, %r4093;
	// end inline asm
	shr.u32 	%r4518, %r4033, 6;
	and.b32  	%r4519, %r4518, 240;
	shr.u32 	%r4520, %r4097, 10;
	or.b32  	%r4521, %r4520, %r4519;
	cvt.u64.u32 	%rd434, %r4521;
	xor.b64  	%rd435, %rd373, %rd434;
	ld.const.u32 	%r4102, [matrix+3968];
	// begin inline asm
	dp4a.u32.u32 %r4101, %r4102, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r4106, [matrix+3972];
	// begin inline asm
	dp4a.u32.u32 %r4105, %r4106, %r4171, %r4101;
	// end inline asm
	ld.const.u32 	%r4110, [matrix+3976];
	// begin inline asm
	dp4a.u32.u32 %r4109, %r4110, %r4175, %r4105;
	// end inline asm
	ld.const.u32 	%r4114, [matrix+3980];
	// begin inline asm
	dp4a.u32.u32 %r4113, %r4114, %r4179, %r4109;
	// end inline asm
	ld.const.u32 	%r4118, [matrix+3984];
	// begin inline asm
	dp4a.u32.u32 %r4117, %r4118, %r4183, %r4113;
	// end inline asm
	ld.const.u32 	%r4122, [matrix+3988];
	// begin inline asm
	dp4a.u32.u32 %r4121, %r4122, %r4187, %r4117;
	// end inline asm
	ld.const.u32 	%r4126, [matrix+3992];
	// begin inline asm
	dp4a.u32.u32 %r4125, %r4126, %r4191, %r4121;
	// end inline asm
	ld.const.u32 	%r4130, [matrix+3996];
	// begin inline asm
	dp4a.u32.u32 %r4129, %r4130, %r4195, %r4125;
	// end inline asm
	ld.const.u32 	%r4134, [matrix+4000];
	// begin inline asm
	dp4a.u32.u32 %r4133, %r4134, %r4199, %r4129;
	// end inline asm
	ld.const.u32 	%r4138, [matrix+4004];
	// begin inline asm
	dp4a.u32.u32 %r4137, %r4138, %r4203, %r4133;
	// end inline asm
	ld.const.u32 	%r4142, [matrix+4008];
	// begin inline asm
	dp4a.u32.u32 %r4141, %r4142, %r4207, %r4137;
	// end inline asm
	ld.const.u32 	%r4146, [matrix+4012];
	// begin inline asm
	dp4a.u32.u32 %r4145, %r4146, %r4211, %r4141;
	// end inline asm
	ld.const.u32 	%r4150, [matrix+4016];
	// begin inline asm
	dp4a.u32.u32 %r4149, %r4150, %r4215, %r4145;
	// end inline asm
	ld.const.u32 	%r4154, [matrix+4020];
	// begin inline asm
	dp4a.u32.u32 %r4153, %r4154, %r4219, %r4149;
	// end inline asm
	ld.const.u32 	%r4158, [matrix+4024];
	// begin inline asm
	dp4a.u32.u32 %r4157, %r4158, %r4223, %r4153;
	// end inline asm
	ld.const.u32 	%r4162, [matrix+4028];
	// begin inline asm
	dp4a.u32.u32 %r4161, %r4162, %r4227, %r4157;
	// end inline asm
	ld.const.u32 	%r4166, [matrix+4032];
	// begin inline asm
	dp4a.u32.u32 %r4165, %r4166, %r4167, %r4643;
	// end inline asm
	ld.const.u32 	%r4170, [matrix+4036];
	// begin inline asm
	dp4a.u32.u32 %r4169, %r4170, %r4171, %r4165;
	// end inline asm
	ld.const.u32 	%r4174, [matrix+4040];
	// begin inline asm
	dp4a.u32.u32 %r4173, %r4174, %r4175, %r4169;
	// end inline asm
	ld.const.u32 	%r4178, [matrix+4044];
	// begin inline asm
	dp4a.u32.u32 %r4177, %r4178, %r4179, %r4173;
	// end inline asm
	ld.const.u32 	%r4182, [matrix+4048];
	// begin inline asm
	dp4a.u32.u32 %r4181, %r4182, %r4183, %r4177;
	// end inline asm
	ld.const.u32 	%r4186, [matrix+4052];
	// begin inline asm
	dp4a.u32.u32 %r4185, %r4186, %r4187, %r4181;
	// end inline asm
	ld.const.u32 	%r4190, [matrix+4056];
	// begin inline asm
	dp4a.u32.u32 %r4189, %r4190, %r4191, %r4185;
	// end inline asm
	ld.const.u32 	%r4194, [matrix+4060];
	// begin inline asm
	dp4a.u32.u32 %r4193, %r4194, %r4195, %r4189;
	// end inline asm
	ld.const.u32 	%r4198, [matrix+4064];
	// begin inline asm
	dp4a.u32.u32 %r4197, %r4198, %r4199, %r4193;
	// end inline asm
	ld.const.u32 	%r4202, [matrix+4068];
	// begin inline asm
	dp4a.u32.u32 %r4201, %r4202, %r4203, %r4197;
	// end inline asm
	ld.const.u32 	%r4206, [matrix+4072];
	// begin inline asm
	dp4a.u32.u32 %r4205, %r4206, %r4207, %r4201;
	// end inline asm
	ld.const.u32 	%r4210, [matrix+4076];
	// begin inline asm
	dp4a.u32.u32 %r4209, %r4210, %r4211, %r4205;
	// end inline asm
	ld.const.u32 	%r4214, [matrix+4080];
	// begin inline asm
	dp4a.u32.u32 %r4213, %r4214, %r4215, %r4209;
	// end inline asm
	ld.const.u32 	%r4218, [matrix+4084];
	// begin inline asm
	dp4a.u32.u32 %r4217, %r4218, %r4219, %r4213;
	// end inline asm
	ld.const.u32 	%r4222, [matrix+4088];
	// begin inline asm
	dp4a.u32.u32 %r4221, %r4222, %r4223, %r4217;
	// end inline asm
	ld.const.u32 	%r4226, [matrix+4092];
	// begin inline asm
	dp4a.u32.u32 %r4225, %r4226, %r4227, %r4221;
	// end inline asm
	shr.u32 	%r4522, %r4161, 6;
	and.b32  	%r4523, %r4522, 240;
	shr.u32 	%r4524, %r4225, 10;
	or.b32  	%r4525, %r4524, %r4523;
	cvt.u64.u32 	%rd436, %r4525;
	shl.b64 	%rd437, %rd436, 56;
	xor.b64  	%rd438, %rd342, %rd390;
	shl.b64 	%rd439, %rd383, 24;
	and.b64  	%rd440, %rd439, 4278190080;
	shl.b64 	%rd441, %rd381, 16;
	and.b64  	%rd442, %rd441, 16711680;
	shl.b64 	%rd443, %rd379, 8;
	and.b64  	%rd444, %rd443, 65280;
	xor.b64  	%rd445, %rd349, %rd405;
	shl.b64 	%rd446, %rd398, 24;
	and.b64  	%rd447, %rd446, 4278190080;
	shl.b64 	%rd448, %rd396, 16;
	and.b64  	%rd449, %rd448, 16711680;
	shl.b64 	%rd450, %rd394, 8;
	and.b64  	%rd451, %rd450, 65280;
	xor.b64  	%rd452, %rd356, %rd420;
	shl.b64 	%rd453, %rd413, 24;
	and.b64  	%rd454, %rd453, 4278190080;
	shl.b64 	%rd455, %rd411, 16;
	and.b64  	%rd456, %rd455, 16711680;
	shl.b64 	%rd457, %rd409, 8;
	and.b64  	%rd458, %rd457, 65280;
	and.b64  	%rd459, %rd670, -72057594037927936;
	xor.b64  	%rd460, %rd459, %rd437;
	shl.b64 	%rd461, %rd438, 56;
	shl.b64 	%rd462, %rd389, 48;
	and.b64  	%rd463, %rd462, 71776119061217280;
	or.b64  	%rd464, %rd461, %rd463;
	shl.b64 	%rd465, %rd387, 40;
	and.b64  	%rd466, %rd465, 280375465082880;
	or.b64  	%rd467, %rd464, %rd466;
	shl.b64 	%rd468, %rd385, 32;
	and.b64  	%rd469, %rd468, 1095216660480;
	or.b64  	%rd470, %rd467, %rd469;
	or.b64  	%rd471, %rd470, %rd440;
	or.b64  	%rd472, %rd471, %rd442;
	and.b64  	%rd473, %rd377, 255;
	or.b64  	%rd474, %rd472, %rd444;
	or.b64  	%rd475, %rd474, %rd473;
	xor.b64  	%rd124, %rd475, 4239941492252378377;
	shl.b64 	%rd476, %rd445, 56;
	shl.b64 	%rd477, %rd404, 48;
	and.b64  	%rd478, %rd477, 71776119061217280;
	or.b64  	%rd479, %rd476, %rd478;
	shl.b64 	%rd480, %rd402, 40;
	and.b64  	%rd481, %rd480, 280375465082880;
	or.b64  	%rd482, %rd479, %rd481;
	shl.b64 	%rd483, %rd400, 32;
	and.b64  	%rd484, %rd483, 1095216660480;
	or.b64  	%rd485, %rd482, %rd484;
	or.b64  	%rd486, %rd485, %rd447;
	or.b64  	%rd487, %rd486, %rd449;
	and.b64  	%rd488, %rd392, 255;
	or.b64  	%rd489, %rd487, %rd451;
	or.b64  	%rd490, %rd489, %rd488;
	xor.b64  	%rd706, %rd490, 8746723911537738262;
	shl.b64 	%rd491, %rd452, 56;
	shl.b64 	%rd492, %rd419, 48;
	and.b64  	%rd493, %rd492, 71776119061217280;
	or.b64  	%rd494, %rd491, %rd493;
	shl.b64 	%rd495, %rd417, 40;
	and.b64  	%rd496, %rd495, 280375465082880;
	or.b64  	%rd497, %rd494, %rd496;
	shl.b64 	%rd498, %rd415, 32;
	and.b64  	%rd499, %rd498, 1095216660480;
	or.b64  	%rd500, %rd497, %rd499;
	or.b64  	%rd501, %rd500, %rd454;
	or.b64  	%rd502, %rd501, %rd456;
	and.b64  	%rd503, %rd407, 255;
	or.b64  	%rd504, %rd502, %rd458;
	or.b64  	%rd505, %rd504, %rd503;
	xor.b64  	%rd701, %rd505, 8796936657246353646;
	shl.b64 	%rd506, %rd435, 48;
	and.b64  	%rd507, %rd506, 71776119061217280;
	or.b64  	%rd508, %rd460, %rd507;
	shl.b64 	%rd509, %rd433, 40;
	and.b64  	%rd510, %rd509, 280375465082880;
	or.b64  	%rd511, %rd508, %rd510;
	shl.b64 	%rd512, %rd431, 32;
	and.b64  	%rd513, %rd512, 1095216660480;
	or.b64  	%rd514, %rd511, %rd513;
	shl.b64 	%rd515, %rd429, 24;
	and.b64  	%rd516, %rd515, 4278190080;
	or.b64  	%rd517, %rd514, %rd516;
	shl.b64 	%rd518, %rd427, 16;
	and.b64  	%rd519, %rd518, 16711680;
	shl.b64 	%rd520, %rd423, 8;
	and.b64  	%rd521, %rd520, 65280;
	or.b64  	%rd522, %rd517, %rd519;
	or.b64  	%rd523, %rd522, %rd521;
	or.b64  	%rd524, %rd523, %rd425;
	xor.b64  	%rd696, %rd524, 1272090201925444760;
	mov.u64 	%rd710, 8270816933120786537;
	mov.u64 	%rd709, -850687345431043546;
	mov.u64 	%rd708, 8596393687355028144;
	mov.u64 	%rd707, -4073852189716399785;
	mov.u64 	%rd705, -4539347866060507718;
	mov.u64 	%rd704, -3233781605604422593;
	mov.u64 	%rd703, 570094237299545110;
	mov.u64 	%rd702, 5171152063242093102;
	mov.u64 	%rd700, 6782861118970774626;
	mov.u64 	%rd699, 7812475424661425213;
	mov.u64 	%rd698, 9119540418498120711;
	mov.u64 	%rd697, -7873636174015165430;
	mov.u64 	%rd695, -9207053471590684088;
	mov.u64 	%rd694, 3370482334374859748;
	mov.u64 	%rd693, -1544774801229058759;
	mov.u64 	%rd692, 6096431547456407061;
	mov.u64 	%rd691, -1792185402154627366;
	mov.u64 	%rd690, -6864424130110145268;
	mov.u64 	%rd689, 5690099369266491460;
	mov.u64 	%rd688, -5074726839974049192;
	mov.u64 	%rd687, 1592359455985097269;
	mov.u64 	%rd686, RC;

$L__BB0_9:
	xor.b64  	%rd525, %rd710, %rd124;
	xor.b64  	%rd526, %rd525, %rd709;
	xor.b64  	%rd527, %rd526, %rd708;
	xor.b64  	%rd528, %rd527, %rd707;
	xor.b64  	%rd529, %rd705, %rd706;
	xor.b64  	%rd530, %rd529, %rd704;
	xor.b64  	%rd531, %rd530, %rd703;
	xor.b64  	%rd532, %rd531, %rd702;
	xor.b64  	%rd533, %rd700, %rd701;
	xor.b64  	%rd534, %rd533, %rd699;
	xor.b64  	%rd535, %rd534, %rd698;
	xor.b64  	%rd536, %rd535, %rd697;
	xor.b64  	%rd537, %rd695, %rd696;
	xor.b64  	%rd538, %rd537, %rd694;
	xor.b64  	%rd539, %rd538, %rd693;
	xor.b64  	%rd540, %rd539, %rd692;
	xor.b64  	%rd541, %rd690, %rd691;
	xor.b64  	%rd542, %rd541, %rd689;
	xor.b64  	%rd543, %rd542, %rd688;
	xor.b64  	%rd544, %rd543, %rd687;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4526}, %rd532;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4527,%dummy}, %rd532;
	}
	shf.l.wrap.b32 	%r4528, %r4527, %r4526, 1;
	shf.l.wrap.b32 	%r4529, %r4526, %r4527, 1;
	mov.b64 	%rd545, {%r4529, %r4528};
	xor.b64  	%rd546, %rd544, %rd545;
	xor.b64  	%rd547, %rd546, %rd124;
	xor.b64  	%rd548, %rd710, %rd546;
	xor.b64  	%rd549, %rd709, %rd546;
	xor.b64  	%rd550, %rd708, %rd546;
	xor.b64  	%rd551, %rd707, %rd546;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4530}, %rd536;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4531,%dummy}, %rd536;
	}
	shf.l.wrap.b32 	%r4532, %r4531, %r4530, 1;
	shf.l.wrap.b32 	%r4533, %r4530, %r4531, 1;
	mov.b64 	%rd552, {%r4533, %r4532};
	xor.b64  	%rd553, %rd552, %rd528;
	xor.b64  	%rd554, %rd706, %rd553;
	xor.b64  	%rd555, %rd705, %rd553;
	xor.b64  	%rd556, %rd704, %rd553;
	xor.b64  	%rd557, %rd703, %rd553;
	xor.b64  	%rd558, %rd702, %rd553;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4534}, %rd540;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4535,%dummy}, %rd540;
	}
	shf.l.wrap.b32 	%r4536, %r4535, %r4534, 1;
	shf.l.wrap.b32 	%r4537, %r4534, %r4535, 1;
	mov.b64 	%rd559, {%r4537, %r4536};
	xor.b64  	%rd560, %rd559, %rd532;
	xor.b64  	%rd561, %rd701, %rd560;
	xor.b64  	%rd562, %rd700, %rd560;
	xor.b64  	%rd563, %rd699, %rd560;
	xor.b64  	%rd564, %rd698, %rd560;
	xor.b64  	%rd565, %rd697, %rd560;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4538}, %rd544;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4539,%dummy}, %rd544;
	}
	shf.l.wrap.b32 	%r4540, %r4539, %r4538, 1;
	shf.l.wrap.b32 	%r4541, %r4538, %r4539, 1;
	mov.b64 	%rd566, {%r4541, %r4540};
	xor.b64  	%rd567, %rd566, %rd536;
	xor.b64  	%rd568, %rd696, %rd567;
	xor.b64  	%rd569, %rd695, %rd567;
	xor.b64  	%rd570, %rd694, %rd567;
	xor.b64  	%rd571, %rd693, %rd567;
	xor.b64  	%rd572, %rd692, %rd567;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4542}, %rd528;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4543,%dummy}, %rd528;
	}
	shf.l.wrap.b32 	%r4544, %r4543, %r4542, 1;
	shf.l.wrap.b32 	%r4545, %r4542, %r4543, 1;
	mov.b64 	%rd573, {%r4545, %r4544};
	xor.b64  	%rd574, %rd540, %rd573;
	xor.b64  	%rd575, %rd691, %rd574;
	xor.b64  	%rd576, %rd690, %rd574;
	xor.b64  	%rd577, %rd689, %rd574;
	xor.b64  	%rd578, %rd688, %rd574;
	xor.b64  	%rd579, %rd687, %rd574;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4546}, %rd554;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4547,%dummy}, %rd554;
	}
	shf.l.wrap.b32 	%r4548, %r4547, %r4546, 1;
	shf.l.wrap.b32 	%r4549, %r4546, %r4547, 1;
	mov.b64 	%rd580, {%r4549, %r4548};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4550}, %rd549;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4551,%dummy}, %rd549;
	}
	shf.l.wrap.b32 	%r4552, %r4551, %r4550, 3;
	shf.l.wrap.b32 	%r4553, %r4550, %r4551, 3;
	mov.b64 	%rd581, {%r4553, %r4552};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4554}, %rd562;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4555,%dummy}, %rd562;
	}
	shf.l.wrap.b32 	%r4556, %r4555, %r4554, 6;
	shf.l.wrap.b32 	%r4557, %r4554, %r4555, 6;
	mov.b64 	%rd582, {%r4557, %r4556};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4558}, %rd556;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4559,%dummy}, %rd556;
	}
	shf.l.wrap.b32 	%r4560, %r4559, %r4558, 10;
	shf.l.wrap.b32 	%r4561, %r4558, %r4559, 10;
	mov.b64 	%rd583, {%r4561, %r4560};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4562}, %rd564;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4563,%dummy}, %rd564;
	}
	shf.l.wrap.b32 	%r4564, %r4563, %r4562, 15;
	shf.l.wrap.b32 	%r4565, %r4562, %r4563, 15;
	mov.b64 	%rd584, {%r4565, %r4564};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4566}, %rd571;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4567,%dummy}, %rd571;
	}
	shf.l.wrap.b32 	%r4568, %r4567, %r4566, 21;
	shf.l.wrap.b32 	%r4569, %r4566, %r4567, 21;
	mov.b64 	%rd585, {%r4569, %r4568};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4570}, %rd568;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4571,%dummy}, %rd568;
	}
	shf.l.wrap.b32 	%r4572, %r4571, %r4570, 28;
	shf.l.wrap.b32 	%r4573, %r4570, %r4571, 28;
	mov.b64 	%rd586, {%r4573, %r4572};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4574,%dummy}, %rd548;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4575}, %rd548;
	}
	shf.r.wrap.b32 	%r4576, %r4575, %r4574, 28;
	shf.r.wrap.b32 	%r4577, %r4574, %r4575, 28;
	mov.b64 	%rd587, {%r4577, %r4576};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4578,%dummy}, %rd557;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4579}, %rd557;
	}
	shf.r.wrap.b32 	%r4580, %r4579, %r4578, 19;
	shf.r.wrap.b32 	%r4581, %r4578, %r4579, 19;
	mov.b64 	%rd588, {%r4581, %r4580};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4582,%dummy}, %rd569;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4583}, %rd569;
	}
	shf.r.wrap.b32 	%r4584, %r4583, %r4582, 9;
	shf.r.wrap.b32 	%r4585, %r4582, %r4583, 9;
	mov.b64 	%rd589, {%r4585, %r4584};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4586}, %rd558;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4587,%dummy}, %rd558;
	}
	shf.l.wrap.b32 	%r4588, %r4587, %r4586, 2;
	shf.l.wrap.b32 	%r4589, %r4586, %r4587, 2;
	mov.b64 	%rd590, {%r4589, %r4588};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4590}, %rd579;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4591,%dummy}, %rd579;
	}
	shf.l.wrap.b32 	%r4592, %r4591, %r4590, 14;
	shf.l.wrap.b32 	%r4593, %r4590, %r4591, 14;
	mov.b64 	%rd591, {%r4593, %r4592};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4594}, %rd575;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4595,%dummy}, %rd575;
	}
	shf.l.wrap.b32 	%r4596, %r4595, %r4594, 27;
	shf.l.wrap.b32 	%r4597, %r4594, %r4595, 27;
	mov.b64 	%rd592, {%r4597, %r4596};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4598,%dummy}, %rd550;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4599}, %rd550;
	}
	shf.r.wrap.b32 	%r4600, %r4599, %r4598, 23;
	shf.r.wrap.b32 	%r4601, %r4598, %r4599, 23;
	mov.b64 	%rd593, {%r4601, %r4600};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4602,%dummy}, %rd572;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4603}, %rd572;
	}
	shf.r.wrap.b32 	%r4604, %r4603, %r4602, 8;
	shf.r.wrap.b32 	%r4605, %r4602, %r4603, 8;
	mov.b64 	%rd594, {%r4605, %r4604};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4606}, %rd578;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4607,%dummy}, %rd578;
	}
	shf.l.wrap.b32 	%r4608, %r4607, %r4606, 8;
	shf.l.wrap.b32 	%r4609, %r4606, %r4607, 8;
	mov.b64 	%rd595, {%r4609, %r4608};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4610}, %rd570;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4611,%dummy}, %rd570;
	}
	shf.l.wrap.b32 	%r4612, %r4611, %r4610, 25;
	shf.l.wrap.b32 	%r4613, %r4610, %r4611, 25;
	mov.b64 	%rd596, {%r4613, %r4612};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4614,%dummy}, %rd563;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4615}, %rd563;
	}
	shf.r.wrap.b32 	%r4616, %r4615, %r4614, 21;
	shf.r.wrap.b32 	%r4617, %r4614, %r4615, 21;
	mov.b64 	%rd597, {%r4617, %r4616};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4618,%dummy}, %rd561;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4619}, %rd561;
	}
	shf.r.wrap.b32 	%r4620, %r4619, %r4618, 2;
	shf.r.wrap.b32 	%r4621, %r4618, %r4619, 2;
	mov.b64 	%rd598, {%r4621, %r4620};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4622}, %rd551;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4623,%dummy}, %rd551;
	}
	shf.l.wrap.b32 	%r4624, %r4623, %r4622, 18;
	shf.l.wrap.b32 	%r4625, %r4622, %r4623, 18;
	mov.b64 	%rd599, {%r4625, %r4624};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4626,%dummy}, %rd577;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4627}, %rd577;
	}
	shf.r.wrap.b32 	%r4628, %r4627, %r4626, 25;
	shf.r.wrap.b32 	%r4629, %r4626, %r4627, 25;
	mov.b64 	%rd600, {%r4629, %r4628};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4630,%dummy}, %rd565;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4631}, %rd565;
	}
	shf.r.wrap.b32 	%r4632, %r4631, %r4630, 3;
	shf.r.wrap.b32 	%r4633, %r4630, %r4631, 3;
	mov.b64 	%rd601, {%r4633, %r4632};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4634}, %rd576;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4635,%dummy}, %rd576;
	}
	shf.l.wrap.b32 	%r4636, %r4635, %r4634, 20;
	shf.l.wrap.b32 	%r4637, %r4634, %r4635, 20;
	mov.b64 	%rd602, {%r4637, %r4636};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4638,%dummy}, %rd555;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4639}, %rd555;
	}
	shf.r.wrap.b32 	%r4640, %r4639, %r4638, 20;
	shf.r.wrap.b32 	%r4641, %r4638, %r4639, 20;
	mov.b64 	%rd603, {%r4641, %r4640};
	not.b64 	%rd604, %rd603;
	and.b64  	%rd605, %rd597, %rd604;
	xor.b64  	%rd606, %rd605, %rd547;
	not.b64 	%rd607, %rd597;
	and.b64  	%rd608, %rd585, %rd607;
	xor.b64  	%rd706, %rd608, %rd603;
	not.b64 	%rd609, %rd585;
	and.b64  	%rd610, %rd591, %rd609;
	xor.b64  	%rd701, %rd610, %rd597;
	not.b64 	%rd611, %rd591;
	and.b64  	%rd612, %rd547, %rd611;
	xor.b64  	%rd696, %rd612, %rd585;
	not.b64 	%rd613, %rd547;
	and.b64  	%rd614, %rd603, %rd613;
	xor.b64  	%rd691, %rd591, %rd614;
	not.b64 	%rd615, %rd602;
	and.b64  	%rd616, %rd581, %rd615;
	xor.b64  	%rd710, %rd616, %rd586;
	not.b64 	%rd617, %rd581;
	and.b64  	%rd618, %rd588, %rd617;
	xor.b64  	%rd705, %rd618, %rd602;
	not.b64 	%rd619, %rd588;
	and.b64  	%rd620, %rd601, %rd619;
	xor.b64  	%rd700, %rd620, %rd581;
	not.b64 	%rd621, %rd601;
	and.b64  	%rd622, %rd586, %rd621;
	xor.b64  	%rd695, %rd622, %rd588;
	not.b64 	%rd623, %rd586;
	and.b64  	%rd624, %rd602, %rd623;
	xor.b64  	%rd690, %rd601, %rd624;
	not.b64 	%rd625, %rd582;
	and.b64  	%rd626, %rd596, %rd625;
	xor.b64  	%rd709, %rd626, %rd580;
	not.b64 	%rd627, %rd596;
	and.b64  	%rd628, %rd595, %rd627;
	xor.b64  	%rd704, %rd628, %rd582;
	not.b64 	%rd629, %rd595;
	and.b64  	%rd630, %rd599, %rd629;
	xor.b64  	%rd699, %rd630, %rd596;
	not.b64 	%rd631, %rd599;
	and.b64  	%rd632, %rd580, %rd631;
	xor.b64  	%rd694, %rd632, %rd595;
	not.b64 	%rd633, %rd580;
	and.b64  	%rd634, %rd582, %rd633;
	xor.b64  	%rd689, %rd599, %rd634;
	not.b64 	%rd635, %rd587;
	and.b64  	%rd636, %rd583, %rd635;
	xor.b64  	%rd708, %rd636, %rd592;
	not.b64 	%rd637, %rd583;
	and.b64  	%rd638, %rd584, %rd637;
	xor.b64  	%rd703, %rd638, %rd587;
	not.b64 	%rd639, %rd584;
	and.b64  	%rd640, %rd594, %rd639;
	xor.b64  	%rd698, %rd640, %rd583;
	not.b64 	%rd641, %rd594;
	and.b64  	%rd642, %rd592, %rd641;
	xor.b64  	%rd693, %rd642, %rd584;
	not.b64 	%rd643, %rd592;
	and.b64  	%rd644, %rd587, %rd643;
	xor.b64  	%rd688, %rd594, %rd644;
	not.b64 	%rd645, %rd589;
	and.b64  	%rd646, %rd600, %rd645;
	xor.b64  	%rd707, %rd646, %rd598;
	not.b64 	%rd647, %rd600;
	and.b64  	%rd648, %rd593, %rd647;
	xor.b64  	%rd702, %rd648, %rd589;
	not.b64 	%rd649, %rd593;
	and.b64  	%rd650, %rd590, %rd649;
	xor.b64  	%rd697, %rd650, %rd600;
	not.b64 	%rd651, %rd590;
	and.b64  	%rd652, %rd598, %rd651;
	xor.b64  	%rd692, %rd652, %rd593;
	not.b64 	%rd653, %rd598;
	and.b64  	%rd654, %rd589, %rd653;
	xor.b64  	%rd687, %rd590, %rd654;
	ld.global.nc.u64 	%rd655, [%rd686];
	xor.b64  	%rd124, %rd606, %rd655;
	add.s64 	%rd686, %rd686, 8;
	add.s32 	%r4643, %r4643, 1;
	setp.ne.s32 	%p10, %r4643, 24;
	@%p10 bra 	$L__BB0_9;

	ld.const.u64 	%rd126, [target+24];
	setp.eq.s64 	%p11, %rd696, %rd126;
	@%p11 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_11;

$L__BB0_12:
	ld.const.u64 	%rd127, [target+16];
	setp.eq.s64 	%p12, %rd701, %rd127;
	@%p12 bra 	$L__BB0_14;
	bra.uni 	$L__BB0_13;

$L__BB0_14:
	ld.const.u64 	%rd128, [target+8];
	setp.eq.s64 	%p13, %rd706, %rd128;
	@%p13 bra 	$L__BB0_16;
	bra.uni 	$L__BB0_15;

$L__BB0_16:
	ld.const.u64 	%rd656, [target];
	setp.lt.u64 	%p15, %rd124, %rd656;
	bra.uni 	$L__BB0_17;

$L__BB0_11:
	setp.lt.u64 	%p15, %rd696, %rd126;
	bra.uni 	$L__BB0_17;

$L__BB0_13:
	setp.lt.u64 	%p15, %rd701, %rd127;
	bra.uni 	$L__BB0_17;

$L__BB0_15:
	setp.lt.u64 	%p15, %rd706, %rd128;

$L__BB0_17:
	not.pred 	%p14, %p15;
	@%p14 bra 	$L__BB0_19;

	mov.u64 	%rd657, 0;
	atom.global.cas.b64 	%rd658, [%rd2], %rd657, %rd7;

$L__BB0_19:
	ret;

}

