//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29618528
// Cuda compilation tools, release 11.2, V11.2.152
// Based on NVVM 7.0.1
//

.version 7.2
.target sm_61
.address_size 64

	// .globl	heavy_hash
.global .align 1 .b8 rho[24] = {1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 2, 14, 27, 41, 56, 8, 25, 43, 62, 18, 39, 61, 20, 44};
.global .align 1 .b8 pi[24] = {10, 7, 11, 17, 18, 3, 5, 16, 8, 21, 24, 4, 15, 23, 19, 13, 12, 2, 20, 14, 22, 9, 6, 1};
.global .align 8 .b8 RC[192] = {1, 0, 0, 0, 0, 0, 0, 0, 130, 128, 0, 0, 0, 0, 0, 0, 138, 128, 0, 0, 0, 0, 0, 128, 0, 128, 0, 128, 0, 0, 0, 128, 139, 128, 0, 0, 0, 0, 0, 0, 1, 0, 0, 128, 0, 0, 0, 0, 129, 128, 0, 128, 0, 0, 0, 128, 9, 128, 0, 0, 0, 0, 0, 128, 138, 0, 0, 0, 0, 0, 0, 0, 136, 0, 0, 0, 0, 0, 0, 0, 9, 128, 0, 128, 0, 0, 0, 0, 10, 0, 0, 128, 0, 0, 0, 0, 139, 128, 0, 128, 0, 0, 0, 0, 139, 0, 0, 0, 0, 0, 0, 128, 137, 128, 0, 0, 0, 0, 0, 128, 3, 128, 0, 0, 0, 0, 0, 128, 2, 128, 0, 0, 0, 0, 0, 128, 128, 0, 0, 0, 0, 0, 0, 128, 10, 128, 0, 0, 0, 0, 0, 0, 10, 0, 0, 128, 0, 0, 0, 128, 129, 128, 0, 128, 0, 0, 0, 128, 128, 128, 0, 0, 0, 0, 0, 128, 1, 0, 0, 128, 0, 0, 0, 0, 8, 128, 0, 128, 0, 0, 0, 128};
.global .align 8 .b8 _ZZ15xoshiro256_jumpP10ulonglong4E4JUMP[32] = {186, 10, 253, 60, 211, 198, 14, 24, 44, 57, 201, 240, 102, 18, 166, 213, 170, 201, 63, 224, 24, 38, 88, 169, 28, 102, 177, 41, 69, 220, 171, 57};
.global .align 8 .b8 _ZZ20xoshiro256_long_jumpP10ulonglong4E9LONG_JUMP[32] = {191, 203, 253, 254, 62, 93, 225, 118, 179, 47, 82, 28, 68, 78, 0, 197, 65, 226, 78, 133, 105, 0, 113, 119, 53, 230, 203, 42, 176, 155, 16, 57};
.const .align 4 .b8 matrix[4096];
.const .align 8 .b8 hash_header[72];
.const .align 8 .b8 target[32];
.const .align 1 .b8 powP[200] = {61, 216, 246, 161, 13, 255, 60, 17, 60, 126, 2, 183, 85, 136, 191, 41, 210, 68, 251, 14, 114, 46, 95, 30, 160, 105, 152, 245, 163, 164, 165, 27, 101, 45, 94, 135, 202, 175, 47, 123, 70, 226, 220, 41, 214, 97, 239, 74, 16, 91, 65, 173, 30, 152, 58, 24, 156, 194, 155, 120, 12, 246, 107, 119, 64, 49, 102, 136, 51, 241, 235, 248, 240, 95, 40, 67, 60, 28, 101, 46, 10, 74, 241, 64, 5, 7, 150, 15, 82, 145, 41, 91, 135, 103, 227, 68, 21, 55, 177, 37, 164, 241, 112, 236, 137, 218, 233, 130, 143, 93, 200, 230, 35, 178, 180, 133, 31, 96, 26, 178, 70, 106, 163, 100, 144, 84, 133, 52, 26, 133, 47, 122, 28, 221, 6, 15, 66, 177, 59, 86, 29, 2, 162, 193, 228, 104, 22, 69, 228, 229, 29, 186, 141, 95, 9, 5, 65, 87, 2, 209, 74, 207, 206, 155, 132, 78, 202, 137, 219, 46, 116, 168, 39, 148, 176, 72, 114, 82, 139, 231, 156, 206, 252, 177, 188, 165, 175, 130, 207, 41, 17, 93, 131, 67, 130, 111, 120, 124, 185, 2};
.const .align 1 .b8 heavyP[200] = {9, 133, 36, 178, 82, 76, 215, 58, 22, 66, 159, 47, 14, 155, 98, 121, 238, 248, 199, 22, 72, 255, 20, 122, 152, 100, 5, 128, 76, 95, 167, 17, 218, 206, 238, 68, 223, 224, 32, 231, 105, 64, 243, 20, 46, 216, 199, 114, 186, 53, 137, 147, 42, 255, 0, 193, 98, 196, 15, 37, 64, 144, 33, 94, 72, 106, 207, 13, 166, 249, 57, 128, 12, 61, 42, 121, 159, 170, 188, 160, 38, 162, 169, 208, 93, 192, 49, 244, 63, 140, 193, 84, 195, 76, 31, 211, 61, 204, 105, 167, 1, 125, 107, 108, 228, 147, 36, 86, 211, 91, 198, 46, 68, 176, 205, 153, 58, 75, 247, 78, 176, 242, 52, 84, 131, 134, 76, 119, 22, 148, 188, 54, 176, 97, 233, 7, 7, 204, 101, 119, 177, 29, 143, 126, 57, 109, 196, 186, 128, 219, 143, 234, 88, 202, 52, 123, 211, 242, 146, 185, 87, 185, 129, 132, 4, 197, 118, 199, 46, 194, 18, 81, 103, 159, 195, 71, 10, 12, 41, 181, 157, 57, 187, 146, 21, 198, 159, 47, 49, 224, 154, 84, 53, 218, 185, 16, 125, 50, 25, 22};

.visible .entry heavy_hash(
	.param .u64 heavy_hash_param_0,
	.param .u64 heavy_hash_param_1,
	.param .u64 heavy_hash_param_2,
	.param .u8 heavy_hash_param_3,
	.param .u64 heavy_hash_param_4,
	.param .u64 heavy_hash_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<4696>;
	.reg .b64 	%rd<648>;


	ld.param.u8 	%rs1, [heavy_hash_param_3];
	ld.param.u64 	%rd128, [heavy_hash_param_0];
	ld.param.u64 	%rd129, [heavy_hash_param_1];
	ld.param.u64 	%rd131, [heavy_hash_param_2];
	ld.param.u64 	%rd130, [heavy_hash_param_4];
	ld.param.u64 	%rd132, [heavy_hash_param_5];
	cvta.to.global.u64 	%rd1, %rd132;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r8, %r6, %r5, %r7;
	cvt.s64.s32 	%rd2, %r8;
	setp.ge.u64 	%p6, %rd2, %rd131;
	@%p6 bra 	LBB0_19;

	cvt.u32.u64 	%r9, %rd2;
	setp.ne.s32 	%p7, %r9, 0;
	@%p7 bra 	LBB0_3;

	mov.u64 	%rd133, 0;
	st.global.u64 	[%rd1], %rd133;

LBB0_3:
	setp.eq.s16 	%p8, %rs1, 0;
	@%p8 bra 	LBB0_5;

	cvta.to.global.u64 	%rd134, %rd130;
	shl.b64 	%rd135, %rd2, 5;
	add.s64 	%rd136, %rd134, %rd135;
	ld.global.u64 	%rd137, [%rd136+8];
	mul.lo.s64 	%rd138, %rd137, 5;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd138, 7;
	shr.b64 	%rhs, %rd138, 57;
	add.u64 	%rd139, %lhs, %rhs;
	}
	mul.lo.s64 	%rd595, %rd139, 9;
	shl.b64 	%rd140, %rd137, 17;
	ld.global.u64 	%rd141, [%rd136+16];
	ld.global.u64 	%rd142, [%rd136];
	xor.b64  	%rd143, %rd141, %rd142;
	ld.global.u64 	%rd144, [%rd136+24];
	xor.b64  	%rd145, %rd144, %rd137;
	xor.b64  	%rd146, %rd137, %rd143;
	st.global.u64 	[%rd136+8], %rd146;
	xor.b64  	%rd147, %rd142, %rd145;
	st.global.u64 	[%rd136], %rd147;
	xor.b64  	%rd148, %rd143, %rd140;
	st.global.u64 	[%rd136+16], %rd148;
	{
	.reg .b32 %dummy;
	mov.b64 	{%r10,%dummy}, %rd145;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r11}, %rd145;
	}
	shf.r.wrap.b32 	%r12, %r11, %r10, 19;
	shf.r.wrap.b32 	%r13, %r10, %r11, 19;
	mov.b64 	%rd149, {%r13, %r12};
	st.global.u64 	[%rd136+24], %rd149;
	bra.uni 	LBB0_6;

LBB0_5:
	cvta.to.global.u64 	%rd150, %rd130;
	brev.b32 	%r15, %r9;
	cvt.u64.u32 	%rd151, %r15;
	shl.b64 	%rd152, %rd151, 32;
	ld.global.u64 	%rd153, [%rd150];
	xor.b64  	%rd595, %rd153, %rd152;

LBB0_6:
	and.b64  	%rd170, %rd595, %rd128;
	or.b64  	%rd6, %rd170, %rd129;
	ld.const.u64 	%rd171, [hash_header];
	xor.b64  	%rd621, %rd171, 1242148031264380989;
	ld.const.u64 	%rd172, [hash_header+8];
	xor.b64  	%rd616, %rd172, 3008272977830772284;
	ld.const.u64 	%rd173, [hash_header+16];
	xor.b64  	%rd611, %rd173, 2188519011337848018;
	ld.const.u64 	%rd174, [hash_header+24];
	xor.b64  	%rd606, %rd174, 1992179434288343456;
	ld.const.u64 	%rd175, [hash_header+32];
	xor.b64  	%rd601, %rd175, 8876506674959887717;
	ld.const.u64 	%rd176, [hash_header+40];
	xor.b64  	%rd620, %rd176, 5399642050693751366;
	ld.const.u64 	%rd177, [hash_header+48];
	xor.b64  	%rd615, %rd177, 1745875063082670864;
	ld.const.u64 	%rd178, [hash_header+56];
	xor.b64  	%rd610, %rd178, 8605242046444978844;
	ld.const.u64 	%rd179, [hash_header+64];
	xor.b64  	%rd605, %rd179, -510048929142394560;
	xor.b64  	%rd600, %rd6, 3343109343542796272;
	mov.u32 	%r4694, 0;
	mov.u64 	%rd619, 1123092876221303306;
	mov.u64 	%rd618, 3784524041015224902;
	mov.u64 	%rd617, -8517909413761200310;
	mov.u64 	%rd614, 4963925045340115282;
	mov.u64 	%rd613, 1082795874807940378;
	mov.u64 	%rd612, 5237849264682708699;
	mov.u64 	%rd609, -1409360996057663723;
	mov.u64 	%rd608, -4494027153138273982;
	mov.u64 	%rd607, -5621391061570334094;
	mov.u64 	%rd604, -1817099578685924727;
	mov.u64 	%rd603, -5035616039755945756;
	mov.u64 	%rd602, 6706187291358897596;
	mov.u64 	%rd599, -5613068297060437469;
	mov.u64 	%rd598, -3386048033060200563;
	mov.u64 	%rd597, 196324915476054915;
	mov.u64 	%rd596, RC;

LBB0_7:
	xor.b64  	%rd180, %rd620, %rd621;
	xor.b64  	%rd181, %rd180, %rd619;
	xor.b64  	%rd182, %rd181, %rd618;
	xor.b64  	%rd183, %rd182, %rd617;
	xor.b64  	%rd184, %rd615, %rd616;
	xor.b64  	%rd185, %rd184, %rd614;
	xor.b64  	%rd186, %rd185, %rd613;
	xor.b64  	%rd187, %rd186, %rd612;
	xor.b64  	%rd188, %rd610, %rd611;
	xor.b64  	%rd189, %rd188, %rd609;
	xor.b64  	%rd190, %rd189, %rd608;
	xor.b64  	%rd191, %rd190, %rd607;
	xor.b64  	%rd192, %rd605, %rd606;
	xor.b64  	%rd193, %rd192, %rd604;
	xor.b64  	%rd194, %rd193, %rd603;
	xor.b64  	%rd195, %rd194, %rd602;
	xor.b64  	%rd196, %rd600, %rd601;
	xor.b64  	%rd197, %rd196, %rd599;
	xor.b64  	%rd198, %rd197, %rd598;
	xor.b64  	%rd199, %rd198, %rd597;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r17}, %rd187;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r18,%dummy}, %rd187;
	}
	shf.l.wrap.b32 	%r19, %r18, %r17, 1;
	shf.l.wrap.b32 	%r20, %r17, %r18, 1;
	mov.b64 	%rd200, {%r20, %r19};
	xor.b64  	%rd201, %rd199, %rd200;
	xor.b64  	%rd202, %rd201, %rd621;
	xor.b64  	%rd203, %rd620, %rd201;
	xor.b64  	%rd204, %rd619, %rd201;
	xor.b64  	%rd205, %rd618, %rd201;
	xor.b64  	%rd206, %rd617, %rd201;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r21}, %rd191;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r22,%dummy}, %rd191;
	}
	shf.l.wrap.b32 	%r23, %r22, %r21, 1;
	shf.l.wrap.b32 	%r24, %r21, %r22, 1;
	mov.b64 	%rd207, {%r24, %r23};
	xor.b64  	%rd208, %rd207, %rd183;
	xor.b64  	%rd209, %rd616, %rd208;
	xor.b64  	%rd210, %rd615, %rd208;
	xor.b64  	%rd211, %rd614, %rd208;
	xor.b64  	%rd212, %rd613, %rd208;
	xor.b64  	%rd213, %rd612, %rd208;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r25}, %rd195;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r26,%dummy}, %rd195;
	}
	shf.l.wrap.b32 	%r27, %r26, %r25, 1;
	shf.l.wrap.b32 	%r28, %r25, %r26, 1;
	mov.b64 	%rd214, {%r28, %r27};
	xor.b64  	%rd215, %rd214, %rd187;
	xor.b64  	%rd216, %rd611, %rd215;
	xor.b64  	%rd217, %rd610, %rd215;
	xor.b64  	%rd218, %rd609, %rd215;
	xor.b64  	%rd219, %rd608, %rd215;
	xor.b64  	%rd220, %rd607, %rd215;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r29}, %rd199;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r30,%dummy}, %rd199;
	}
	shf.l.wrap.b32 	%r31, %r30, %r29, 1;
	shf.l.wrap.b32 	%r32, %r29, %r30, 1;
	mov.b64 	%rd221, {%r32, %r31};
	xor.b64  	%rd222, %rd221, %rd191;
	xor.b64  	%rd223, %rd606, %rd222;
	xor.b64  	%rd224, %rd605, %rd222;
	xor.b64  	%rd225, %rd604, %rd222;
	xor.b64  	%rd226, %rd603, %rd222;
	xor.b64  	%rd227, %rd602, %rd222;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r33}, %rd183;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r34,%dummy}, %rd183;
	}
	shf.l.wrap.b32 	%r35, %r34, %r33, 1;
	shf.l.wrap.b32 	%r36, %r33, %r34, 1;
	mov.b64 	%rd228, {%r36, %r35};
	xor.b64  	%rd229, %rd195, %rd228;
	xor.b64  	%rd230, %rd601, %rd229;
	xor.b64  	%rd231, %rd600, %rd229;
	xor.b64  	%rd232, %rd599, %rd229;
	xor.b64  	%rd233, %rd598, %rd229;
	xor.b64  	%rd234, %rd597, %rd229;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r37}, %rd209;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r38,%dummy}, %rd209;
	}
	shf.l.wrap.b32 	%r39, %r38, %r37, 1;
	shf.l.wrap.b32 	%r40, %r37, %r38, 1;
	mov.b64 	%rd235, {%r40, %r39};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r41}, %rd204;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r42,%dummy}, %rd204;
	}
	shf.l.wrap.b32 	%r43, %r42, %r41, 3;
	shf.l.wrap.b32 	%r44, %r41, %r42, 3;
	mov.b64 	%rd236, {%r44, %r43};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r45}, %rd217;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r46,%dummy}, %rd217;
	}
	shf.l.wrap.b32 	%r47, %r46, %r45, 6;
	shf.l.wrap.b32 	%r48, %r45, %r46, 6;
	mov.b64 	%rd237, {%r48, %r47};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r49}, %rd211;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r50,%dummy}, %rd211;
	}
	shf.l.wrap.b32 	%r51, %r50, %r49, 10;
	shf.l.wrap.b32 	%r52, %r49, %r50, 10;
	mov.b64 	%rd238, {%r52, %r51};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r53}, %rd219;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r54,%dummy}, %rd219;
	}
	shf.l.wrap.b32 	%r55, %r54, %r53, 15;
	shf.l.wrap.b32 	%r56, %r53, %r54, 15;
	mov.b64 	%rd239, {%r56, %r55};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r57}, %rd226;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r58,%dummy}, %rd226;
	}
	shf.l.wrap.b32 	%r59, %r58, %r57, 21;
	shf.l.wrap.b32 	%r60, %r57, %r58, 21;
	mov.b64 	%rd240, {%r60, %r59};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r61}, %rd223;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r62,%dummy}, %rd223;
	}
	shf.l.wrap.b32 	%r63, %r62, %r61, 28;
	shf.l.wrap.b32 	%r64, %r61, %r62, 28;
	mov.b64 	%rd241, {%r64, %r63};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r65,%dummy}, %rd203;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r66}, %rd203;
	}
	shf.r.wrap.b32 	%r67, %r66, %r65, 28;
	shf.r.wrap.b32 	%r68, %r65, %r66, 28;
	mov.b64 	%rd242, {%r68, %r67};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r69,%dummy}, %rd212;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r70}, %rd212;
	}
	shf.r.wrap.b32 	%r71, %r70, %r69, 19;
	shf.r.wrap.b32 	%r72, %r69, %r70, 19;
	mov.b64 	%rd243, {%r72, %r71};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r73,%dummy}, %rd224;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r74}, %rd224;
	}
	shf.r.wrap.b32 	%r75, %r74, %r73, 9;
	shf.r.wrap.b32 	%r76, %r73, %r74, 9;
	mov.b64 	%rd244, {%r76, %r75};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r77}, %rd213;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r78,%dummy}, %rd213;
	}
	shf.l.wrap.b32 	%r79, %r78, %r77, 2;
	shf.l.wrap.b32 	%r80, %r77, %r78, 2;
	mov.b64 	%rd245, {%r80, %r79};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r81}, %rd234;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r82,%dummy}, %rd234;
	}
	shf.l.wrap.b32 	%r83, %r82, %r81, 14;
	shf.l.wrap.b32 	%r84, %r81, %r82, 14;
	mov.b64 	%rd246, {%r84, %r83};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r85}, %rd230;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r86,%dummy}, %rd230;
	}
	shf.l.wrap.b32 	%r87, %r86, %r85, 27;
	shf.l.wrap.b32 	%r88, %r85, %r86, 27;
	mov.b64 	%rd247, {%r88, %r87};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r89,%dummy}, %rd205;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r90}, %rd205;
	}
	shf.r.wrap.b32 	%r91, %r90, %r89, 23;
	shf.r.wrap.b32 	%r92, %r89, %r90, 23;
	mov.b64 	%rd248, {%r92, %r91};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r93,%dummy}, %rd227;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r94}, %rd227;
	}
	shf.r.wrap.b32 	%r95, %r94, %r93, 8;
	shf.r.wrap.b32 	%r96, %r93, %r94, 8;
	mov.b64 	%rd249, {%r96, %r95};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r97}, %rd233;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r98,%dummy}, %rd233;
	}
	shf.l.wrap.b32 	%r99, %r98, %r97, 8;
	shf.l.wrap.b32 	%r100, %r97, %r98, 8;
	mov.b64 	%rd250, {%r100, %r99};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r101}, %rd225;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r102,%dummy}, %rd225;
	}
	shf.l.wrap.b32 	%r103, %r102, %r101, 25;
	shf.l.wrap.b32 	%r104, %r101, %r102, 25;
	mov.b64 	%rd251, {%r104, %r103};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r105,%dummy}, %rd218;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r106}, %rd218;
	}
	shf.r.wrap.b32 	%r107, %r106, %r105, 21;
	shf.r.wrap.b32 	%r108, %r105, %r106, 21;
	mov.b64 	%rd252, {%r108, %r107};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r109,%dummy}, %rd216;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r110}, %rd216;
	}
	shf.r.wrap.b32 	%r111, %r110, %r109, 2;
	shf.r.wrap.b32 	%r112, %r109, %r110, 2;
	mov.b64 	%rd253, {%r112, %r111};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r113}, %rd206;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r114,%dummy}, %rd206;
	}
	shf.l.wrap.b32 	%r115, %r114, %r113, 18;
	shf.l.wrap.b32 	%r116, %r113, %r114, 18;
	mov.b64 	%rd254, {%r116, %r115};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r117,%dummy}, %rd232;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r118}, %rd232;
	}
	shf.r.wrap.b32 	%r119, %r118, %r117, 25;
	shf.r.wrap.b32 	%r120, %r117, %r118, 25;
	mov.b64 	%rd255, {%r120, %r119};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r121,%dummy}, %rd220;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r122}, %rd220;
	}
	shf.r.wrap.b32 	%r123, %r122, %r121, 3;
	shf.r.wrap.b32 	%r124, %r121, %r122, 3;
	mov.b64 	%rd256, {%r124, %r123};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r125}, %rd231;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r126,%dummy}, %rd231;
	}
	shf.l.wrap.b32 	%r127, %r126, %r125, 20;
	shf.l.wrap.b32 	%r128, %r125, %r126, 20;
	mov.b64 	%rd257, {%r128, %r127};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r129,%dummy}, %rd210;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r130}, %rd210;
	}
	shf.r.wrap.b32 	%r131, %r130, %r129, 20;
	shf.r.wrap.b32 	%r132, %r129, %r130, 20;
	mov.b64 	%rd258, {%r132, %r131};
	not.b64 	%rd259, %rd258;
	and.b64  	%rd260, %rd252, %rd259;
	xor.b64  	%rd261, %rd260, %rd202;
	not.b64 	%rd262, %rd252;
	and.b64  	%rd263, %rd240, %rd262;
	xor.b64  	%rd616, %rd263, %rd258;
	not.b64 	%rd264, %rd240;
	and.b64  	%rd265, %rd246, %rd264;
	xor.b64  	%rd611, %rd265, %rd252;
	not.b64 	%rd266, %rd246;
	and.b64  	%rd267, %rd202, %rd266;
	xor.b64  	%rd606, %rd267, %rd240;
	not.b64 	%rd268, %rd202;
	and.b64  	%rd269, %rd258, %rd268;
	xor.b64  	%rd601, %rd246, %rd269;
	not.b64 	%rd270, %rd257;
	and.b64  	%rd271, %rd236, %rd270;
	xor.b64  	%rd620, %rd271, %rd241;
	not.b64 	%rd272, %rd236;
	and.b64  	%rd273, %rd243, %rd272;
	xor.b64  	%rd615, %rd273, %rd257;
	not.b64 	%rd274, %rd243;
	and.b64  	%rd275, %rd256, %rd274;
	xor.b64  	%rd610, %rd275, %rd236;
	not.b64 	%rd276, %rd256;
	and.b64  	%rd277, %rd241, %rd276;
	xor.b64  	%rd605, %rd277, %rd243;
	not.b64 	%rd278, %rd241;
	and.b64  	%rd279, %rd257, %rd278;
	xor.b64  	%rd600, %rd256, %rd279;
	not.b64 	%rd280, %rd237;
	and.b64  	%rd281, %rd251, %rd280;
	xor.b64  	%rd619, %rd281, %rd235;
	not.b64 	%rd282, %rd251;
	and.b64  	%rd283, %rd250, %rd282;
	xor.b64  	%rd614, %rd283, %rd237;
	not.b64 	%rd284, %rd250;
	and.b64  	%rd285, %rd254, %rd284;
	xor.b64  	%rd609, %rd285, %rd251;
	not.b64 	%rd286, %rd254;
	and.b64  	%rd287, %rd235, %rd286;
	xor.b64  	%rd604, %rd287, %rd250;
	not.b64 	%rd288, %rd235;
	and.b64  	%rd289, %rd237, %rd288;
	xor.b64  	%rd599, %rd254, %rd289;
	not.b64 	%rd290, %rd242;
	and.b64  	%rd291, %rd238, %rd290;
	xor.b64  	%rd618, %rd291, %rd247;
	not.b64 	%rd292, %rd238;
	and.b64  	%rd293, %rd239, %rd292;
	xor.b64  	%rd613, %rd293, %rd242;
	not.b64 	%rd294, %rd239;
	and.b64  	%rd295, %rd249, %rd294;
	xor.b64  	%rd608, %rd295, %rd238;
	not.b64 	%rd296, %rd249;
	and.b64  	%rd297, %rd247, %rd296;
	xor.b64  	%rd603, %rd297, %rd239;
	not.b64 	%rd298, %rd247;
	and.b64  	%rd299, %rd242, %rd298;
	xor.b64  	%rd598, %rd249, %rd299;
	not.b64 	%rd300, %rd244;
	and.b64  	%rd301, %rd255, %rd300;
	xor.b64  	%rd617, %rd301, %rd253;
	not.b64 	%rd302, %rd255;
	and.b64  	%rd303, %rd248, %rd302;
	xor.b64  	%rd612, %rd303, %rd244;
	not.b64 	%rd304, %rd248;
	and.b64  	%rd305, %rd245, %rd304;
	xor.b64  	%rd607, %rd305, %rd255;
	not.b64 	%rd306, %rd245;
	and.b64  	%rd307, %rd253, %rd306;
	xor.b64  	%rd602, %rd307, %rd248;
	not.b64 	%rd308, %rd253;
	and.b64  	%rd309, %rd244, %rd308;
	xor.b64  	%rd597, %rd245, %rd309;
	ld.global.nc.u64 	%rd310, [%rd596];
	xor.b64  	%rd621, %rd261, %rd310;
	add.s64 	%rd596, %rd596, 8;
	add.s32 	%r4694, %r4694, 1;
	setp.ne.s32 	%p9, %r4694, 24;
	@%p9 bra 	LBB0_7;

	cvt.u16.u64 	%rs2, %rd621;
	and.b16  	%rs3, %rs2, 240;
	shr.u64 	%rd333, %rd621, 8;
	cvt.u32.u64 	%r4358, %rd333;
	shr.u64 	%rd334, %rd621, 16;
	cvt.u32.u64 	%r4359, %rd334;
	shr.u64 	%rd335, %rd621, 24;
	cvt.u32.u64 	%r4360, %rd335;
	shr.u64 	%rd336, %rd621, 32;
	cvt.u32.u64 	%r4361, %rd336;
	shr.u64 	%rd337, %rd621, 40;
	cvt.u32.u64 	%r4362, %rd337;
	shr.u64 	%rd338, %rd621, 48;
	cvt.u32.u64 	%r4363, %rd338;
	shr.u64 	%rd339, %rd621, 56;
	cvt.u32.u64 	%r1188, %rd339;
	shr.u64 	%rd340, %rd616, 8;
	cvt.u32.u64 	%r4364, %rd340;
	shr.u64 	%rd341, %rd616, 16;
	cvt.u32.u64 	%r4365, %rd341;
	shr.u64 	%rd342, %rd616, 24;
	cvt.u32.u64 	%r4366, %rd342;
	shr.u64 	%rd343, %rd616, 32;
	cvt.u32.u64 	%r4367, %rd343;
	shr.u64 	%rd344, %rd616, 40;
	cvt.u32.u64 	%r4368, %rd344;
	shr.u64 	%rd345, %rd616, 48;
	cvt.u32.u64 	%r4369, %rd345;
	shr.u64 	%rd346, %rd616, 56;
	cvt.u32.u64 	%r2244, %rd346;
	shr.u64 	%rd347, %rd611, 8;
	cvt.u32.u64 	%r4370, %rd347;
	shr.u64 	%rd348, %rd611, 16;
	cvt.u32.u64 	%r4371, %rd348;
	shr.u64 	%rd349, %rd611, 24;
	cvt.u32.u64 	%r4372, %rd349;
	shr.u64 	%rd350, %rd611, 32;
	cvt.u32.u64 	%r4373, %rd350;
	shr.u64 	%rd351, %rd611, 40;
	cvt.u32.u64 	%r4374, %rd351;
	shr.u64 	%rd352, %rd611, 48;
	cvt.u32.u64 	%r4375, %rd352;
	shr.u64 	%rd353, %rd611, 56;
	cvt.u32.u64 	%r3300, %rd353;
	shr.u16 	%rs4, %rs3, 4;
	cvt.u32.u64 	%r4376, %rd621;
	shr.u32 	%r4377, %r4376, 12;
	cvt.u32.u16 	%r4378, %rs4;
	and.b32  	%r4379, %r4376, 15;
	prmt.b32 	%r4380, %r4379, %r4378, 30212;
	shl.b32 	%r4381, %r4376, 4;
	and.b32  	%r4382, %r4381, 983040;
	or.b32  	%r4383, %r4380, %r4382;
	shl.b32 	%r4384, %r4358, 24;
	and.b32  	%r4385, %r4384, 251658240;
	or.b32  	%r4291, %r4383, %r4385;
	bfe.u32 	%r4386, %r4376, 20, 4;
	and.b32  	%r4387, %r4359, 15;
	bfi.b32 	%r4388, %r4387, %r4386, 8, 4;
	and.b32  	%r4389, %r4377, 983040;
	or.b32  	%r4390, %r4388, %r4389;
	shl.b32 	%r4391, %r4360, 24;
	and.b32  	%r4392, %r4391, 251658240;
	or.b32  	%r4295, %r4390, %r4392;
	shr.u64 	%rd354, %rd621, 36;
	cvt.u32.u64 	%r4393, %rd354;
	and.b32  	%r4394, %r4393, 15;
	and.b32  	%r4395, %r4361, 15;
	shr.u64 	%rd355, %rd621, 44;
	cvt.u32.u64 	%r4396, %rd355;
	bfi.b32 	%r4397, %r4395, %r4394, 8, 4;
	shl.b32 	%r4398, %r4396, 16;
	and.b32  	%r4399, %r4398, 983040;
	or.b32  	%r4400, %r4397, %r4399;
	shl.b32 	%r4401, %r4362, 24;
	and.b32  	%r4402, %r4401, 251658240;
	or.b32  	%r4299, %r4400, %r4402;
	shr.u64 	%rd356, %rd621, 52;
	cvt.u32.u64 	%r4403, %rd356;
	and.b32  	%r4404, %r4403, 15;
	and.b32  	%r4405, %r4363, 15;
	bfi.b32 	%r4406, %r4405, %r4404, 8, 4;
	and.b32  	%r4407, %r4396, 983040;
	or.b32  	%r4408, %r4406, %r4407;
	shl.b32 	%r4409, %r1188, 24;
	and.b32  	%r4410, %r4409, 251658240;
	or.b32  	%r4303, %r4408, %r4410;
	cvt.u16.u64 	%rs5, %rd616;
	and.b16  	%rs6, %rs5, 240;
	shr.u16 	%rs7, %rs6, 4;
	cvt.u32.u64 	%r4411, %rd616;
	shr.u32 	%r4412, %r4411, 12;
	cvt.u32.u16 	%r4413, %rs7;
	and.b32  	%r4414, %r4411, 15;
	prmt.b32 	%r4415, %r4414, %r4413, 30212;
	shl.b32 	%r4416, %r4411, 4;
	and.b32  	%r4417, %r4416, 983040;
	or.b32  	%r4418, %r4415, %r4417;
	shl.b32 	%r4419, %r4364, 24;
	and.b32  	%r4420, %r4419, 251658240;
	or.b32  	%r4307, %r4418, %r4420;
	bfe.u32 	%r4421, %r4411, 20, 4;
	and.b32  	%r4422, %r4365, 15;
	bfi.b32 	%r4423, %r4422, %r4421, 8, 4;
	and.b32  	%r4424, %r4412, 983040;
	or.b32  	%r4425, %r4423, %r4424;
	shl.b32 	%r4426, %r4366, 24;
	and.b32  	%r4427, %r4426, 251658240;
	or.b32  	%r4311, %r4425, %r4427;
	shr.u64 	%rd357, %rd616, 36;
	cvt.u32.u64 	%r4428, %rd357;
	and.b32  	%r4429, %r4428, 15;
	and.b32  	%r4430, %r4367, 15;
	shr.u64 	%rd358, %rd616, 44;
	cvt.u32.u64 	%r4431, %rd358;
	bfi.b32 	%r4432, %r4430, %r4429, 8, 4;
	shl.b32 	%r4433, %r4431, 16;
	and.b32  	%r4434, %r4433, 983040;
	or.b32  	%r4435, %r4432, %r4434;
	shl.b32 	%r4436, %r4368, 24;
	and.b32  	%r4437, %r4436, 251658240;
	or.b32  	%r4315, %r4435, %r4437;
	shr.u64 	%rd359, %rd616, 52;
	cvt.u32.u64 	%r4438, %rd359;
	and.b32  	%r4439, %r4438, 15;
	and.b32  	%r4440, %r4369, 15;
	bfi.b32 	%r4441, %r4440, %r4439, 8, 4;
	and.b32  	%r4442, %r4431, 983040;
	or.b32  	%r4443, %r4441, %r4442;
	shl.b32 	%r4444, %r2244, 24;
	and.b32  	%r4445, %r4444, 251658240;
	or.b32  	%r4319, %r4443, %r4445;
	cvt.u16.u64 	%rs8, %rd611;
	and.b16  	%rs9, %rs8, 240;
	shr.u16 	%rs10, %rs9, 4;
	cvt.u32.u64 	%r4446, %rd611;
	shr.u32 	%r4447, %r4446, 12;
	cvt.u32.u16 	%r4448, %rs10;
	and.b32  	%r4449, %r4446, 15;
	prmt.b32 	%r4450, %r4449, %r4448, 30212;
	shl.b32 	%r4451, %r4446, 4;
	and.b32  	%r4452, %r4451, 983040;
	or.b32  	%r4453, %r4450, %r4452;
	shl.b32 	%r4454, %r4370, 24;
	and.b32  	%r4455, %r4454, 251658240;
	or.b32  	%r4323, %r4453, %r4455;
	bfe.u32 	%r4456, %r4446, 20, 4;
	and.b32  	%r4457, %r4371, 15;
	bfi.b32 	%r4458, %r4457, %r4456, 8, 4;
	and.b32  	%r4459, %r4447, 983040;
	or.b32  	%r4460, %r4458, %r4459;
	shl.b32 	%r4461, %r4372, 24;
	and.b32  	%r4462, %r4461, 251658240;
	or.b32  	%r4327, %r4460, %r4462;
	shr.u64 	%rd360, %rd611, 36;
	cvt.u32.u64 	%r4463, %rd360;
	and.b32  	%r4464, %r4463, 15;
	and.b32  	%r4465, %r4373, 15;
	shr.u64 	%rd361, %rd611, 44;
	cvt.u32.u64 	%r4466, %rd361;
	bfi.b32 	%r4467, %r4465, %r4464, 8, 4;
	shl.b32 	%r4468, %r4466, 16;
	and.b32  	%r4469, %r4468, 983040;
	or.b32  	%r4470, %r4467, %r4469;
	shl.b32 	%r4471, %r4374, 24;
	and.b32  	%r4472, %r4471, 251658240;
	or.b32  	%r4331, %r4470, %r4472;
	shr.u64 	%rd362, %rd611, 52;
	cvt.u32.u64 	%r4473, %rd362;
	and.b32  	%r4474, %r4473, 15;
	and.b32  	%r4475, %r4375, 15;
	bfi.b32 	%r4476, %r4475, %r4474, 8, 4;
	and.b32  	%r4477, %r4466, 983040;
	or.b32  	%r4478, %r4476, %r4477;
	shl.b32 	%r4479, %r3300, 24;
	and.b32  	%r4480, %r4479, 251658240;
	or.b32  	%r4335, %r4478, %r4480;
	cvt.u16.u64 	%rs11, %rd606;
	and.b16  	%rs12, %rs11, 240;
	shr.u16 	%rs13, %rs12, 4;
	cvt.u32.u64 	%r4481, %rd606;
	shr.u32 	%r4482, %r4481, 12;
	shr.u64 	%rd363, %rd606, 8;
	cvt.u32.u64 	%r4483, %rd363;
	cvt.u32.u16 	%r4484, %rs13;
	and.b32  	%r4485, %r4481, 15;
	prmt.b32 	%r4486, %r4485, %r4484, 30212;
	shl.b32 	%r4487, %r4481, 4;
	and.b32  	%r4488, %r4487, 983040;
	or.b32  	%r4489, %r4486, %r4488;
	shl.b32 	%r4490, %r4483, 24;
	and.b32  	%r4491, %r4490, 251658240;
	or.b32  	%r4339, %r4489, %r4491;
	bfe.u32 	%r4492, %r4481, 20, 4;
	shr.u64 	%rd364, %rd606, 16;
	cvt.u32.u64 	%r4493, %rd364;
	and.b32  	%r4494, %r4493, 15;
	shr.u64 	%rd365, %rd606, 24;
	cvt.u32.u64 	%r4495, %rd365;
	bfi.b32 	%r4496, %r4494, %r4492, 8, 4;
	and.b32  	%r4497, %r4482, 983040;
	or.b32  	%r4498, %r4496, %r4497;
	shl.b32 	%r4499, %r4495, 24;
	and.b32  	%r4500, %r4499, 251658240;
	or.b32  	%r4343, %r4498, %r4500;
	shr.u64 	%rd366, %rd606, 36;
	cvt.u32.u64 	%r4501, %rd366;
	and.b32  	%r4502, %r4501, 15;
	shr.u64 	%rd367, %rd606, 32;
	cvt.u32.u64 	%r4503, %rd367;
	and.b32  	%r4504, %r4503, 15;
	shr.u64 	%rd368, %rd606, 44;
	cvt.u32.u64 	%r4505, %rd368;
	shr.u64 	%rd369, %rd606, 40;
	cvt.u32.u64 	%r4506, %rd369;
	bfi.b32 	%r4507, %r4504, %r4502, 8, 4;
	shl.b32 	%r4508, %r4505, 16;
	and.b32  	%r4509, %r4508, 983040;
	or.b32  	%r4510, %r4507, %r4509;
	shl.b32 	%r4511, %r4506, 24;
	and.b32  	%r4512, %r4511, 251658240;
	or.b32  	%r4347, %r4510, %r4512;
	shr.u64 	%rd370, %rd606, 52;
	cvt.u32.u64 	%r4513, %rd370;
	and.b32  	%r4514, %r4513, 15;
	shr.u64 	%rd371, %rd606, 48;
	cvt.u32.u64 	%r4515, %rd371;
	and.b32  	%r4516, %r4515, 15;
	shr.u64 	%rd372, %rd606, 56;
	cvt.u32.u64 	%r4356, %rd372;
	bfi.b32 	%r4517, %r4516, %r4514, 8, 4;
	and.b32  	%r4518, %r4505, 983040;
	or.b32  	%r4519, %r4517, %r4518;
	shl.b32 	%r4520, %r4356, 24;
	and.b32  	%r4521, %r4520, 251658240;
	or.b32  	%r4351, %r4519, %r4521;
	ld.const.u32 	%r134, [matrix];
	mov.u32 	%r4695, 0;
	// begin inline asm
	dp4a.u32.u32 %r133, %r134, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r138, [matrix+4];
	// begin inline asm
	dp4a.u32.u32 %r137, %r138, %r4295, %r133;
	// end inline asm
	ld.const.u32 	%r142, [matrix+8];
	// begin inline asm
	dp4a.u32.u32 %r141, %r142, %r4299, %r137;
	// end inline asm
	ld.const.u32 	%r146, [matrix+12];
	// begin inline asm
	dp4a.u32.u32 %r145, %r146, %r4303, %r141;
	// end inline asm
	ld.const.u32 	%r150, [matrix+16];
	// begin inline asm
	dp4a.u32.u32 %r149, %r150, %r4307, %r145;
	// end inline asm
	ld.const.u32 	%r154, [matrix+20];
	// begin inline asm
	dp4a.u32.u32 %r153, %r154, %r4311, %r149;
	// end inline asm
	ld.const.u32 	%r158, [matrix+24];
	// begin inline asm
	dp4a.u32.u32 %r157, %r158, %r4315, %r153;
	// end inline asm
	ld.const.u32 	%r162, [matrix+28];
	// begin inline asm
	dp4a.u32.u32 %r161, %r162, %r4319, %r157;
	// end inline asm
	ld.const.u32 	%r166, [matrix+32];
	// begin inline asm
	dp4a.u32.u32 %r165, %r166, %r4323, %r161;
	// end inline asm
	ld.const.u32 	%r170, [matrix+36];
	// begin inline asm
	dp4a.u32.u32 %r169, %r170, %r4327, %r165;
	// end inline asm
	ld.const.u32 	%r174, [matrix+40];
	// begin inline asm
	dp4a.u32.u32 %r173, %r174, %r4331, %r169;
	// end inline asm
	ld.const.u32 	%r178, [matrix+44];
	// begin inline asm
	dp4a.u32.u32 %r177, %r178, %r4335, %r173;
	// end inline asm
	ld.const.u32 	%r182, [matrix+48];
	// begin inline asm
	dp4a.u32.u32 %r181, %r182, %r4339, %r177;
	// end inline asm
	ld.const.u32 	%r186, [matrix+52];
	// begin inline asm
	dp4a.u32.u32 %r185, %r186, %r4343, %r181;
	// end inline asm
	ld.const.u32 	%r190, [matrix+56];
	// begin inline asm
	dp4a.u32.u32 %r189, %r190, %r4347, %r185;
	// end inline asm
	ld.const.u32 	%r194, [matrix+60];
	// begin inline asm
	dp4a.u32.u32 %r193, %r194, %r4351, %r189;
	// end inline asm
	ld.const.u32 	%r198, [matrix+64];
	// begin inline asm
	dp4a.u32.u32 %r197, %r198, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r202, [matrix+68];
	// begin inline asm
	dp4a.u32.u32 %r201, %r202, %r4295, %r197;
	// end inline asm
	ld.const.u32 	%r206, [matrix+72];
	// begin inline asm
	dp4a.u32.u32 %r205, %r206, %r4299, %r201;
	// end inline asm
	ld.const.u32 	%r210, [matrix+76];
	// begin inline asm
	dp4a.u32.u32 %r209, %r210, %r4303, %r205;
	// end inline asm
	ld.const.u32 	%r214, [matrix+80];
	// begin inline asm
	dp4a.u32.u32 %r213, %r214, %r4307, %r209;
	// end inline asm
	ld.const.u32 	%r218, [matrix+84];
	// begin inline asm
	dp4a.u32.u32 %r217, %r218, %r4311, %r213;
	// end inline asm
	ld.const.u32 	%r222, [matrix+88];
	// begin inline asm
	dp4a.u32.u32 %r221, %r222, %r4315, %r217;
	// end inline asm
	ld.const.u32 	%r226, [matrix+92];
	// begin inline asm
	dp4a.u32.u32 %r225, %r226, %r4319, %r221;
	// end inline asm
	ld.const.u32 	%r230, [matrix+96];
	// begin inline asm
	dp4a.u32.u32 %r229, %r230, %r4323, %r225;
	// end inline asm
	ld.const.u32 	%r234, [matrix+100];
	// begin inline asm
	dp4a.u32.u32 %r233, %r234, %r4327, %r229;
	// end inline asm
	ld.const.u32 	%r238, [matrix+104];
	// begin inline asm
	dp4a.u32.u32 %r237, %r238, %r4331, %r233;
	// end inline asm
	ld.const.u32 	%r242, [matrix+108];
	// begin inline asm
	dp4a.u32.u32 %r241, %r242, %r4335, %r237;
	// end inline asm
	ld.const.u32 	%r246, [matrix+112];
	// begin inline asm
	dp4a.u32.u32 %r245, %r246, %r4339, %r241;
	// end inline asm
	ld.const.u32 	%r250, [matrix+116];
	// begin inline asm
	dp4a.u32.u32 %r249, %r250, %r4343, %r245;
	// end inline asm
	ld.const.u32 	%r254, [matrix+120];
	// begin inline asm
	dp4a.u32.u32 %r253, %r254, %r4347, %r249;
	// end inline asm
	ld.const.u32 	%r258, [matrix+124];
	// begin inline asm
	dp4a.u32.u32 %r257, %r258, %r4351, %r253;
	// end inline asm
	shr.u32 	%r4522, %r193, 6;
	and.b32  	%r262, %r4522, 240;
	shr.u32 	%r263, %r257, 10;
	and.b32  	%r264, %r4376, 255;
	// begin inline asm
	lop3.b32 %r261, %r262, %r263, %r264, 0x56;
	// end inline asm
	ld.const.u32 	%r266, [matrix+128];
	// begin inline asm
	dp4a.u32.u32 %r265, %r266, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r270, [matrix+132];
	// begin inline asm
	dp4a.u32.u32 %r269, %r270, %r4295, %r265;
	// end inline asm
	ld.const.u32 	%r274, [matrix+136];
	// begin inline asm
	dp4a.u32.u32 %r273, %r274, %r4299, %r269;
	// end inline asm
	ld.const.u32 	%r278, [matrix+140];
	// begin inline asm
	dp4a.u32.u32 %r277, %r278, %r4303, %r273;
	// end inline asm
	ld.const.u32 	%r282, [matrix+144];
	// begin inline asm
	dp4a.u32.u32 %r281, %r282, %r4307, %r277;
	// end inline asm
	ld.const.u32 	%r286, [matrix+148];
	// begin inline asm
	dp4a.u32.u32 %r285, %r286, %r4311, %r281;
	// end inline asm
	ld.const.u32 	%r290, [matrix+152];
	// begin inline asm
	dp4a.u32.u32 %r289, %r290, %r4315, %r285;
	// end inline asm
	ld.const.u32 	%r294, [matrix+156];
	// begin inline asm
	dp4a.u32.u32 %r293, %r294, %r4319, %r289;
	// end inline asm
	ld.const.u32 	%r298, [matrix+160];
	// begin inline asm
	dp4a.u32.u32 %r297, %r298, %r4323, %r293;
	// end inline asm
	ld.const.u32 	%r302, [matrix+164];
	// begin inline asm
	dp4a.u32.u32 %r301, %r302, %r4327, %r297;
	// end inline asm
	ld.const.u32 	%r306, [matrix+168];
	// begin inline asm
	dp4a.u32.u32 %r305, %r306, %r4331, %r301;
	// end inline asm
	ld.const.u32 	%r310, [matrix+172];
	// begin inline asm
	dp4a.u32.u32 %r309, %r310, %r4335, %r305;
	// end inline asm
	ld.const.u32 	%r314, [matrix+176];
	// begin inline asm
	dp4a.u32.u32 %r313, %r314, %r4339, %r309;
	// end inline asm
	ld.const.u32 	%r318, [matrix+180];
	// begin inline asm
	dp4a.u32.u32 %r317, %r318, %r4343, %r313;
	// end inline asm
	ld.const.u32 	%r322, [matrix+184];
	// begin inline asm
	dp4a.u32.u32 %r321, %r322, %r4347, %r317;
	// end inline asm
	ld.const.u32 	%r326, [matrix+188];
	// begin inline asm
	dp4a.u32.u32 %r325, %r326, %r4351, %r321;
	// end inline asm
	ld.const.u32 	%r330, [matrix+192];
	// begin inline asm
	dp4a.u32.u32 %r329, %r330, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r334, [matrix+196];
	// begin inline asm
	dp4a.u32.u32 %r333, %r334, %r4295, %r329;
	// end inline asm
	ld.const.u32 	%r338, [matrix+200];
	// begin inline asm
	dp4a.u32.u32 %r337, %r338, %r4299, %r333;
	// end inline asm
	ld.const.u32 	%r342, [matrix+204];
	// begin inline asm
	dp4a.u32.u32 %r341, %r342, %r4303, %r337;
	// end inline asm
	ld.const.u32 	%r346, [matrix+208];
	// begin inline asm
	dp4a.u32.u32 %r345, %r346, %r4307, %r341;
	// end inline asm
	ld.const.u32 	%r350, [matrix+212];
	// begin inline asm
	dp4a.u32.u32 %r349, %r350, %r4311, %r345;
	// end inline asm
	ld.const.u32 	%r354, [matrix+216];
	// begin inline asm
	dp4a.u32.u32 %r353, %r354, %r4315, %r349;
	// end inline asm
	ld.const.u32 	%r358, [matrix+220];
	// begin inline asm
	dp4a.u32.u32 %r357, %r358, %r4319, %r353;
	// end inline asm
	ld.const.u32 	%r362, [matrix+224];
	// begin inline asm
	dp4a.u32.u32 %r361, %r362, %r4323, %r357;
	// end inline asm
	ld.const.u32 	%r366, [matrix+228];
	// begin inline asm
	dp4a.u32.u32 %r365, %r366, %r4327, %r361;
	// end inline asm
	ld.const.u32 	%r370, [matrix+232];
	// begin inline asm
	dp4a.u32.u32 %r369, %r370, %r4331, %r365;
	// end inline asm
	ld.const.u32 	%r374, [matrix+236];
	// begin inline asm
	dp4a.u32.u32 %r373, %r374, %r4335, %r369;
	// end inline asm
	ld.const.u32 	%r378, [matrix+240];
	// begin inline asm
	dp4a.u32.u32 %r377, %r378, %r4339, %r373;
	// end inline asm
	ld.const.u32 	%r382, [matrix+244];
	// begin inline asm
	dp4a.u32.u32 %r381, %r382, %r4343, %r377;
	// end inline asm
	ld.const.u32 	%r386, [matrix+248];
	// begin inline asm
	dp4a.u32.u32 %r385, %r386, %r4347, %r381;
	// end inline asm
	ld.const.u32 	%r390, [matrix+252];
	// begin inline asm
	dp4a.u32.u32 %r389, %r390, %r4351, %r385;
	// end inline asm
	shr.u32 	%r4523, %r325, 6;
	and.b32  	%r394, %r4523, 240;
	shr.u32 	%r395, %r389, 10;
	and.b32  	%r396, %r4358, 255;
	// begin inline asm
	lop3.b32 %r393, %r394, %r395, %r396, 0x56;
	// end inline asm
	ld.const.u32 	%r398, [matrix+256];
	// begin inline asm
	dp4a.u32.u32 %r397, %r398, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r402, [matrix+260];
	// begin inline asm
	dp4a.u32.u32 %r401, %r402, %r4295, %r397;
	// end inline asm
	ld.const.u32 	%r406, [matrix+264];
	// begin inline asm
	dp4a.u32.u32 %r405, %r406, %r4299, %r401;
	// end inline asm
	ld.const.u32 	%r410, [matrix+268];
	// begin inline asm
	dp4a.u32.u32 %r409, %r410, %r4303, %r405;
	// end inline asm
	ld.const.u32 	%r414, [matrix+272];
	// begin inline asm
	dp4a.u32.u32 %r413, %r414, %r4307, %r409;
	// end inline asm
	ld.const.u32 	%r418, [matrix+276];
	// begin inline asm
	dp4a.u32.u32 %r417, %r418, %r4311, %r413;
	// end inline asm
	ld.const.u32 	%r422, [matrix+280];
	// begin inline asm
	dp4a.u32.u32 %r421, %r422, %r4315, %r417;
	// end inline asm
	ld.const.u32 	%r426, [matrix+284];
	// begin inline asm
	dp4a.u32.u32 %r425, %r426, %r4319, %r421;
	// end inline asm
	ld.const.u32 	%r430, [matrix+288];
	// begin inline asm
	dp4a.u32.u32 %r429, %r430, %r4323, %r425;
	// end inline asm
	ld.const.u32 	%r434, [matrix+292];
	// begin inline asm
	dp4a.u32.u32 %r433, %r434, %r4327, %r429;
	// end inline asm
	ld.const.u32 	%r438, [matrix+296];
	// begin inline asm
	dp4a.u32.u32 %r437, %r438, %r4331, %r433;
	// end inline asm
	ld.const.u32 	%r442, [matrix+300];
	// begin inline asm
	dp4a.u32.u32 %r441, %r442, %r4335, %r437;
	// end inline asm
	ld.const.u32 	%r446, [matrix+304];
	// begin inline asm
	dp4a.u32.u32 %r445, %r446, %r4339, %r441;
	// end inline asm
	ld.const.u32 	%r450, [matrix+308];
	// begin inline asm
	dp4a.u32.u32 %r449, %r450, %r4343, %r445;
	// end inline asm
	ld.const.u32 	%r454, [matrix+312];
	// begin inline asm
	dp4a.u32.u32 %r453, %r454, %r4347, %r449;
	// end inline asm
	ld.const.u32 	%r458, [matrix+316];
	// begin inline asm
	dp4a.u32.u32 %r457, %r458, %r4351, %r453;
	// end inline asm
	ld.const.u32 	%r462, [matrix+320];
	// begin inline asm
	dp4a.u32.u32 %r461, %r462, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r466, [matrix+324];
	// begin inline asm
	dp4a.u32.u32 %r465, %r466, %r4295, %r461;
	// end inline asm
	ld.const.u32 	%r470, [matrix+328];
	// begin inline asm
	dp4a.u32.u32 %r469, %r470, %r4299, %r465;
	// end inline asm
	ld.const.u32 	%r474, [matrix+332];
	// begin inline asm
	dp4a.u32.u32 %r473, %r474, %r4303, %r469;
	// end inline asm
	ld.const.u32 	%r478, [matrix+336];
	// begin inline asm
	dp4a.u32.u32 %r477, %r478, %r4307, %r473;
	// end inline asm
	ld.const.u32 	%r482, [matrix+340];
	// begin inline asm
	dp4a.u32.u32 %r481, %r482, %r4311, %r477;
	// end inline asm
	ld.const.u32 	%r486, [matrix+344];
	// begin inline asm
	dp4a.u32.u32 %r485, %r486, %r4315, %r481;
	// end inline asm
	ld.const.u32 	%r490, [matrix+348];
	// begin inline asm
	dp4a.u32.u32 %r489, %r490, %r4319, %r485;
	// end inline asm
	ld.const.u32 	%r494, [matrix+352];
	// begin inline asm
	dp4a.u32.u32 %r493, %r494, %r4323, %r489;
	// end inline asm
	ld.const.u32 	%r498, [matrix+356];
	// begin inline asm
	dp4a.u32.u32 %r497, %r498, %r4327, %r493;
	// end inline asm
	ld.const.u32 	%r502, [matrix+360];
	// begin inline asm
	dp4a.u32.u32 %r501, %r502, %r4331, %r497;
	// end inline asm
	ld.const.u32 	%r506, [matrix+364];
	// begin inline asm
	dp4a.u32.u32 %r505, %r506, %r4335, %r501;
	// end inline asm
	ld.const.u32 	%r510, [matrix+368];
	// begin inline asm
	dp4a.u32.u32 %r509, %r510, %r4339, %r505;
	// end inline asm
	ld.const.u32 	%r514, [matrix+372];
	// begin inline asm
	dp4a.u32.u32 %r513, %r514, %r4343, %r509;
	// end inline asm
	ld.const.u32 	%r518, [matrix+376];
	// begin inline asm
	dp4a.u32.u32 %r517, %r518, %r4347, %r513;
	// end inline asm
	ld.const.u32 	%r522, [matrix+380];
	// begin inline asm
	dp4a.u32.u32 %r521, %r522, %r4351, %r517;
	// end inline asm
	shr.u32 	%r4524, %r457, 6;
	and.b32  	%r526, %r4524, 240;
	shr.u32 	%r527, %r521, 10;
	and.b32  	%r528, %r4359, 255;
	// begin inline asm
	lop3.b32 %r525, %r526, %r527, %r528, 0x56;
	// end inline asm
	ld.const.u32 	%r530, [matrix+384];
	// begin inline asm
	dp4a.u32.u32 %r529, %r530, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r534, [matrix+388];
	// begin inline asm
	dp4a.u32.u32 %r533, %r534, %r4295, %r529;
	// end inline asm
	ld.const.u32 	%r538, [matrix+392];
	// begin inline asm
	dp4a.u32.u32 %r537, %r538, %r4299, %r533;
	// end inline asm
	ld.const.u32 	%r542, [matrix+396];
	// begin inline asm
	dp4a.u32.u32 %r541, %r542, %r4303, %r537;
	// end inline asm
	ld.const.u32 	%r546, [matrix+400];
	// begin inline asm
	dp4a.u32.u32 %r545, %r546, %r4307, %r541;
	// end inline asm
	ld.const.u32 	%r550, [matrix+404];
	// begin inline asm
	dp4a.u32.u32 %r549, %r550, %r4311, %r545;
	// end inline asm
	ld.const.u32 	%r554, [matrix+408];
	// begin inline asm
	dp4a.u32.u32 %r553, %r554, %r4315, %r549;
	// end inline asm
	ld.const.u32 	%r558, [matrix+412];
	// begin inline asm
	dp4a.u32.u32 %r557, %r558, %r4319, %r553;
	// end inline asm
	ld.const.u32 	%r562, [matrix+416];
	// begin inline asm
	dp4a.u32.u32 %r561, %r562, %r4323, %r557;
	// end inline asm
	ld.const.u32 	%r566, [matrix+420];
	// begin inline asm
	dp4a.u32.u32 %r565, %r566, %r4327, %r561;
	// end inline asm
	ld.const.u32 	%r570, [matrix+424];
	// begin inline asm
	dp4a.u32.u32 %r569, %r570, %r4331, %r565;
	// end inline asm
	ld.const.u32 	%r574, [matrix+428];
	// begin inline asm
	dp4a.u32.u32 %r573, %r574, %r4335, %r569;
	// end inline asm
	ld.const.u32 	%r578, [matrix+432];
	// begin inline asm
	dp4a.u32.u32 %r577, %r578, %r4339, %r573;
	// end inline asm
	ld.const.u32 	%r582, [matrix+436];
	// begin inline asm
	dp4a.u32.u32 %r581, %r582, %r4343, %r577;
	// end inline asm
	ld.const.u32 	%r586, [matrix+440];
	// begin inline asm
	dp4a.u32.u32 %r585, %r586, %r4347, %r581;
	// end inline asm
	ld.const.u32 	%r590, [matrix+444];
	// begin inline asm
	dp4a.u32.u32 %r589, %r590, %r4351, %r585;
	// end inline asm
	ld.const.u32 	%r594, [matrix+448];
	// begin inline asm
	dp4a.u32.u32 %r593, %r594, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r598, [matrix+452];
	// begin inline asm
	dp4a.u32.u32 %r597, %r598, %r4295, %r593;
	// end inline asm
	ld.const.u32 	%r602, [matrix+456];
	// begin inline asm
	dp4a.u32.u32 %r601, %r602, %r4299, %r597;
	// end inline asm
	ld.const.u32 	%r606, [matrix+460];
	// begin inline asm
	dp4a.u32.u32 %r605, %r606, %r4303, %r601;
	// end inline asm
	ld.const.u32 	%r610, [matrix+464];
	// begin inline asm
	dp4a.u32.u32 %r609, %r610, %r4307, %r605;
	// end inline asm
	ld.const.u32 	%r614, [matrix+468];
	// begin inline asm
	dp4a.u32.u32 %r613, %r614, %r4311, %r609;
	// end inline asm
	ld.const.u32 	%r618, [matrix+472];
	// begin inline asm
	dp4a.u32.u32 %r617, %r618, %r4315, %r613;
	// end inline asm
	ld.const.u32 	%r622, [matrix+476];
	// begin inline asm
	dp4a.u32.u32 %r621, %r622, %r4319, %r617;
	// end inline asm
	ld.const.u32 	%r626, [matrix+480];
	// begin inline asm
	dp4a.u32.u32 %r625, %r626, %r4323, %r621;
	// end inline asm
	ld.const.u32 	%r630, [matrix+484];
	// begin inline asm
	dp4a.u32.u32 %r629, %r630, %r4327, %r625;
	// end inline asm
	ld.const.u32 	%r634, [matrix+488];
	// begin inline asm
	dp4a.u32.u32 %r633, %r634, %r4331, %r629;
	// end inline asm
	ld.const.u32 	%r638, [matrix+492];
	// begin inline asm
	dp4a.u32.u32 %r637, %r638, %r4335, %r633;
	// end inline asm
	ld.const.u32 	%r642, [matrix+496];
	// begin inline asm
	dp4a.u32.u32 %r641, %r642, %r4339, %r637;
	// end inline asm
	ld.const.u32 	%r646, [matrix+500];
	// begin inline asm
	dp4a.u32.u32 %r645, %r646, %r4343, %r641;
	// end inline asm
	ld.const.u32 	%r650, [matrix+504];
	// begin inline asm
	dp4a.u32.u32 %r649, %r650, %r4347, %r645;
	// end inline asm
	ld.const.u32 	%r654, [matrix+508];
	// begin inline asm
	dp4a.u32.u32 %r653, %r654, %r4351, %r649;
	// end inline asm
	shr.u32 	%r4525, %r589, 6;
	and.b32  	%r658, %r4525, 240;
	shr.u32 	%r659, %r653, 10;
	and.b32  	%r660, %r4360, 255;
	// begin inline asm
	lop3.b32 %r657, %r658, %r659, %r660, 0x56;
	// end inline asm
	ld.const.u32 	%r662, [matrix+512];
	// begin inline asm
	dp4a.u32.u32 %r661, %r662, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r666, [matrix+516];
	// begin inline asm
	dp4a.u32.u32 %r665, %r666, %r4295, %r661;
	// end inline asm
	ld.const.u32 	%r670, [matrix+520];
	// begin inline asm
	dp4a.u32.u32 %r669, %r670, %r4299, %r665;
	// end inline asm
	ld.const.u32 	%r674, [matrix+524];
	// begin inline asm
	dp4a.u32.u32 %r673, %r674, %r4303, %r669;
	// end inline asm
	ld.const.u32 	%r678, [matrix+528];
	// begin inline asm
	dp4a.u32.u32 %r677, %r678, %r4307, %r673;
	// end inline asm
	ld.const.u32 	%r682, [matrix+532];
	// begin inline asm
	dp4a.u32.u32 %r681, %r682, %r4311, %r677;
	// end inline asm
	ld.const.u32 	%r686, [matrix+536];
	// begin inline asm
	dp4a.u32.u32 %r685, %r686, %r4315, %r681;
	// end inline asm
	ld.const.u32 	%r690, [matrix+540];
	// begin inline asm
	dp4a.u32.u32 %r689, %r690, %r4319, %r685;
	// end inline asm
	ld.const.u32 	%r694, [matrix+544];
	// begin inline asm
	dp4a.u32.u32 %r693, %r694, %r4323, %r689;
	// end inline asm
	ld.const.u32 	%r698, [matrix+548];
	// begin inline asm
	dp4a.u32.u32 %r697, %r698, %r4327, %r693;
	// end inline asm
	ld.const.u32 	%r702, [matrix+552];
	// begin inline asm
	dp4a.u32.u32 %r701, %r702, %r4331, %r697;
	// end inline asm
	ld.const.u32 	%r706, [matrix+556];
	// begin inline asm
	dp4a.u32.u32 %r705, %r706, %r4335, %r701;
	// end inline asm
	ld.const.u32 	%r710, [matrix+560];
	// begin inline asm
	dp4a.u32.u32 %r709, %r710, %r4339, %r705;
	// end inline asm
	ld.const.u32 	%r714, [matrix+564];
	// begin inline asm
	dp4a.u32.u32 %r713, %r714, %r4343, %r709;
	// end inline asm
	ld.const.u32 	%r718, [matrix+568];
	// begin inline asm
	dp4a.u32.u32 %r717, %r718, %r4347, %r713;
	// end inline asm
	ld.const.u32 	%r722, [matrix+572];
	// begin inline asm
	dp4a.u32.u32 %r721, %r722, %r4351, %r717;
	// end inline asm
	ld.const.u32 	%r726, [matrix+576];
	// begin inline asm
	dp4a.u32.u32 %r725, %r726, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r730, [matrix+580];
	// begin inline asm
	dp4a.u32.u32 %r729, %r730, %r4295, %r725;
	// end inline asm
	ld.const.u32 	%r734, [matrix+584];
	// begin inline asm
	dp4a.u32.u32 %r733, %r734, %r4299, %r729;
	// end inline asm
	ld.const.u32 	%r738, [matrix+588];
	// begin inline asm
	dp4a.u32.u32 %r737, %r738, %r4303, %r733;
	// end inline asm
	ld.const.u32 	%r742, [matrix+592];
	// begin inline asm
	dp4a.u32.u32 %r741, %r742, %r4307, %r737;
	// end inline asm
	ld.const.u32 	%r746, [matrix+596];
	// begin inline asm
	dp4a.u32.u32 %r745, %r746, %r4311, %r741;
	// end inline asm
	ld.const.u32 	%r750, [matrix+600];
	// begin inline asm
	dp4a.u32.u32 %r749, %r750, %r4315, %r745;
	// end inline asm
	ld.const.u32 	%r754, [matrix+604];
	// begin inline asm
	dp4a.u32.u32 %r753, %r754, %r4319, %r749;
	// end inline asm
	ld.const.u32 	%r758, [matrix+608];
	// begin inline asm
	dp4a.u32.u32 %r757, %r758, %r4323, %r753;
	// end inline asm
	ld.const.u32 	%r762, [matrix+612];
	// begin inline asm
	dp4a.u32.u32 %r761, %r762, %r4327, %r757;
	// end inline asm
	ld.const.u32 	%r766, [matrix+616];
	// begin inline asm
	dp4a.u32.u32 %r765, %r766, %r4331, %r761;
	// end inline asm
	ld.const.u32 	%r770, [matrix+620];
	// begin inline asm
	dp4a.u32.u32 %r769, %r770, %r4335, %r765;
	// end inline asm
	ld.const.u32 	%r774, [matrix+624];
	// begin inline asm
	dp4a.u32.u32 %r773, %r774, %r4339, %r769;
	// end inline asm
	ld.const.u32 	%r778, [matrix+628];
	// begin inline asm
	dp4a.u32.u32 %r777, %r778, %r4343, %r773;
	// end inline asm
	ld.const.u32 	%r782, [matrix+632];
	// begin inline asm
	dp4a.u32.u32 %r781, %r782, %r4347, %r777;
	// end inline asm
	ld.const.u32 	%r786, [matrix+636];
	// begin inline asm
	dp4a.u32.u32 %r785, %r786, %r4351, %r781;
	// end inline asm
	shr.u32 	%r4526, %r721, 6;
	and.b32  	%r790, %r4526, 240;
	shr.u32 	%r791, %r785, 10;
	and.b32  	%r792, %r4361, 255;
	// begin inline asm
	lop3.b32 %r789, %r790, %r791, %r792, 0x56;
	// end inline asm
	ld.const.u32 	%r794, [matrix+640];
	// begin inline asm
	dp4a.u32.u32 %r793, %r794, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r798, [matrix+644];
	// begin inline asm
	dp4a.u32.u32 %r797, %r798, %r4295, %r793;
	// end inline asm
	ld.const.u32 	%r802, [matrix+648];
	// begin inline asm
	dp4a.u32.u32 %r801, %r802, %r4299, %r797;
	// end inline asm
	ld.const.u32 	%r806, [matrix+652];
	// begin inline asm
	dp4a.u32.u32 %r805, %r806, %r4303, %r801;
	// end inline asm
	ld.const.u32 	%r810, [matrix+656];
	// begin inline asm
	dp4a.u32.u32 %r809, %r810, %r4307, %r805;
	// end inline asm
	ld.const.u32 	%r814, [matrix+660];
	// begin inline asm
	dp4a.u32.u32 %r813, %r814, %r4311, %r809;
	// end inline asm
	ld.const.u32 	%r818, [matrix+664];
	// begin inline asm
	dp4a.u32.u32 %r817, %r818, %r4315, %r813;
	// end inline asm
	ld.const.u32 	%r822, [matrix+668];
	// begin inline asm
	dp4a.u32.u32 %r821, %r822, %r4319, %r817;
	// end inline asm
	ld.const.u32 	%r826, [matrix+672];
	// begin inline asm
	dp4a.u32.u32 %r825, %r826, %r4323, %r821;
	// end inline asm
	ld.const.u32 	%r830, [matrix+676];
	// begin inline asm
	dp4a.u32.u32 %r829, %r830, %r4327, %r825;
	// end inline asm
	ld.const.u32 	%r834, [matrix+680];
	// begin inline asm
	dp4a.u32.u32 %r833, %r834, %r4331, %r829;
	// end inline asm
	ld.const.u32 	%r838, [matrix+684];
	// begin inline asm
	dp4a.u32.u32 %r837, %r838, %r4335, %r833;
	// end inline asm
	ld.const.u32 	%r842, [matrix+688];
	// begin inline asm
	dp4a.u32.u32 %r841, %r842, %r4339, %r837;
	// end inline asm
	ld.const.u32 	%r846, [matrix+692];
	// begin inline asm
	dp4a.u32.u32 %r845, %r846, %r4343, %r841;
	// end inline asm
	ld.const.u32 	%r850, [matrix+696];
	// begin inline asm
	dp4a.u32.u32 %r849, %r850, %r4347, %r845;
	// end inline asm
	ld.const.u32 	%r854, [matrix+700];
	// begin inline asm
	dp4a.u32.u32 %r853, %r854, %r4351, %r849;
	// end inline asm
	ld.const.u32 	%r858, [matrix+704];
	// begin inline asm
	dp4a.u32.u32 %r857, %r858, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r862, [matrix+708];
	// begin inline asm
	dp4a.u32.u32 %r861, %r862, %r4295, %r857;
	// end inline asm
	ld.const.u32 	%r866, [matrix+712];
	// begin inline asm
	dp4a.u32.u32 %r865, %r866, %r4299, %r861;
	// end inline asm
	ld.const.u32 	%r870, [matrix+716];
	// begin inline asm
	dp4a.u32.u32 %r869, %r870, %r4303, %r865;
	// end inline asm
	ld.const.u32 	%r874, [matrix+720];
	// begin inline asm
	dp4a.u32.u32 %r873, %r874, %r4307, %r869;
	// end inline asm
	ld.const.u32 	%r878, [matrix+724];
	// begin inline asm
	dp4a.u32.u32 %r877, %r878, %r4311, %r873;
	// end inline asm
	ld.const.u32 	%r882, [matrix+728];
	// begin inline asm
	dp4a.u32.u32 %r881, %r882, %r4315, %r877;
	// end inline asm
	ld.const.u32 	%r886, [matrix+732];
	// begin inline asm
	dp4a.u32.u32 %r885, %r886, %r4319, %r881;
	// end inline asm
	ld.const.u32 	%r890, [matrix+736];
	// begin inline asm
	dp4a.u32.u32 %r889, %r890, %r4323, %r885;
	// end inline asm
	ld.const.u32 	%r894, [matrix+740];
	// begin inline asm
	dp4a.u32.u32 %r893, %r894, %r4327, %r889;
	// end inline asm
	ld.const.u32 	%r898, [matrix+744];
	// begin inline asm
	dp4a.u32.u32 %r897, %r898, %r4331, %r893;
	// end inline asm
	ld.const.u32 	%r902, [matrix+748];
	// begin inline asm
	dp4a.u32.u32 %r901, %r902, %r4335, %r897;
	// end inline asm
	ld.const.u32 	%r906, [matrix+752];
	// begin inline asm
	dp4a.u32.u32 %r905, %r906, %r4339, %r901;
	// end inline asm
	ld.const.u32 	%r910, [matrix+756];
	// begin inline asm
	dp4a.u32.u32 %r909, %r910, %r4343, %r905;
	// end inline asm
	ld.const.u32 	%r914, [matrix+760];
	// begin inline asm
	dp4a.u32.u32 %r913, %r914, %r4347, %r909;
	// end inline asm
	ld.const.u32 	%r918, [matrix+764];
	// begin inline asm
	dp4a.u32.u32 %r917, %r918, %r4351, %r913;
	// end inline asm
	shr.u32 	%r4527, %r853, 6;
	and.b32  	%r922, %r4527, 240;
	shr.u32 	%r923, %r917, 10;
	and.b32  	%r924, %r4362, 255;
	// begin inline asm
	lop3.b32 %r921, %r922, %r923, %r924, 0x56;
	// end inline asm
	ld.const.u32 	%r926, [matrix+768];
	// begin inline asm
	dp4a.u32.u32 %r925, %r926, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r930, [matrix+772];
	// begin inline asm
	dp4a.u32.u32 %r929, %r930, %r4295, %r925;
	// end inline asm
	ld.const.u32 	%r934, [matrix+776];
	// begin inline asm
	dp4a.u32.u32 %r933, %r934, %r4299, %r929;
	// end inline asm
	ld.const.u32 	%r938, [matrix+780];
	// begin inline asm
	dp4a.u32.u32 %r937, %r938, %r4303, %r933;
	// end inline asm
	ld.const.u32 	%r942, [matrix+784];
	// begin inline asm
	dp4a.u32.u32 %r941, %r942, %r4307, %r937;
	// end inline asm
	ld.const.u32 	%r946, [matrix+788];
	// begin inline asm
	dp4a.u32.u32 %r945, %r946, %r4311, %r941;
	// end inline asm
	ld.const.u32 	%r950, [matrix+792];
	// begin inline asm
	dp4a.u32.u32 %r949, %r950, %r4315, %r945;
	// end inline asm
	ld.const.u32 	%r954, [matrix+796];
	// begin inline asm
	dp4a.u32.u32 %r953, %r954, %r4319, %r949;
	// end inline asm
	ld.const.u32 	%r958, [matrix+800];
	// begin inline asm
	dp4a.u32.u32 %r957, %r958, %r4323, %r953;
	// end inline asm
	ld.const.u32 	%r962, [matrix+804];
	// begin inline asm
	dp4a.u32.u32 %r961, %r962, %r4327, %r957;
	// end inline asm
	ld.const.u32 	%r966, [matrix+808];
	// begin inline asm
	dp4a.u32.u32 %r965, %r966, %r4331, %r961;
	// end inline asm
	ld.const.u32 	%r970, [matrix+812];
	// begin inline asm
	dp4a.u32.u32 %r969, %r970, %r4335, %r965;
	// end inline asm
	ld.const.u32 	%r974, [matrix+816];
	// begin inline asm
	dp4a.u32.u32 %r973, %r974, %r4339, %r969;
	// end inline asm
	ld.const.u32 	%r978, [matrix+820];
	// begin inline asm
	dp4a.u32.u32 %r977, %r978, %r4343, %r973;
	// end inline asm
	ld.const.u32 	%r982, [matrix+824];
	// begin inline asm
	dp4a.u32.u32 %r981, %r982, %r4347, %r977;
	// end inline asm
	ld.const.u32 	%r986, [matrix+828];
	// begin inline asm
	dp4a.u32.u32 %r985, %r986, %r4351, %r981;
	// end inline asm
	ld.const.u32 	%r990, [matrix+832];
	// begin inline asm
	dp4a.u32.u32 %r989, %r990, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r994, [matrix+836];
	// begin inline asm
	dp4a.u32.u32 %r993, %r994, %r4295, %r989;
	// end inline asm
	ld.const.u32 	%r998, [matrix+840];
	// begin inline asm
	dp4a.u32.u32 %r997, %r998, %r4299, %r993;
	// end inline asm
	ld.const.u32 	%r1002, [matrix+844];
	// begin inline asm
	dp4a.u32.u32 %r1001, %r1002, %r4303, %r997;
	// end inline asm
	ld.const.u32 	%r1006, [matrix+848];
	// begin inline asm
	dp4a.u32.u32 %r1005, %r1006, %r4307, %r1001;
	// end inline asm
	ld.const.u32 	%r1010, [matrix+852];
	// begin inline asm
	dp4a.u32.u32 %r1009, %r1010, %r4311, %r1005;
	// end inline asm
	ld.const.u32 	%r1014, [matrix+856];
	// begin inline asm
	dp4a.u32.u32 %r1013, %r1014, %r4315, %r1009;
	// end inline asm
	ld.const.u32 	%r1018, [matrix+860];
	// begin inline asm
	dp4a.u32.u32 %r1017, %r1018, %r4319, %r1013;
	// end inline asm
	ld.const.u32 	%r1022, [matrix+864];
	// begin inline asm
	dp4a.u32.u32 %r1021, %r1022, %r4323, %r1017;
	// end inline asm
	ld.const.u32 	%r1026, [matrix+868];
	// begin inline asm
	dp4a.u32.u32 %r1025, %r1026, %r4327, %r1021;
	// end inline asm
	ld.const.u32 	%r1030, [matrix+872];
	// begin inline asm
	dp4a.u32.u32 %r1029, %r1030, %r4331, %r1025;
	// end inline asm
	ld.const.u32 	%r1034, [matrix+876];
	// begin inline asm
	dp4a.u32.u32 %r1033, %r1034, %r4335, %r1029;
	// end inline asm
	ld.const.u32 	%r1038, [matrix+880];
	// begin inline asm
	dp4a.u32.u32 %r1037, %r1038, %r4339, %r1033;
	// end inline asm
	ld.const.u32 	%r1042, [matrix+884];
	// begin inline asm
	dp4a.u32.u32 %r1041, %r1042, %r4343, %r1037;
	// end inline asm
	ld.const.u32 	%r1046, [matrix+888];
	// begin inline asm
	dp4a.u32.u32 %r1045, %r1046, %r4347, %r1041;
	// end inline asm
	ld.const.u32 	%r1050, [matrix+892];
	// begin inline asm
	dp4a.u32.u32 %r1049, %r1050, %r4351, %r1045;
	// end inline asm
	shr.u32 	%r4528, %r985, 6;
	and.b32  	%r1054, %r4528, 240;
	shr.u32 	%r1055, %r1049, 10;
	and.b32  	%r1056, %r4363, 255;
	// begin inline asm
	lop3.b32 %r1053, %r1054, %r1055, %r1056, 0x56;
	// end inline asm
	ld.const.u32 	%r1058, [matrix+896];
	// begin inline asm
	dp4a.u32.u32 %r1057, %r1058, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1062, [matrix+900];
	// begin inline asm
	dp4a.u32.u32 %r1061, %r1062, %r4295, %r1057;
	// end inline asm
	ld.const.u32 	%r1066, [matrix+904];
	// begin inline asm
	dp4a.u32.u32 %r1065, %r1066, %r4299, %r1061;
	// end inline asm
	ld.const.u32 	%r1070, [matrix+908];
	// begin inline asm
	dp4a.u32.u32 %r1069, %r1070, %r4303, %r1065;
	// end inline asm
	ld.const.u32 	%r1074, [matrix+912];
	// begin inline asm
	dp4a.u32.u32 %r1073, %r1074, %r4307, %r1069;
	// end inline asm
	ld.const.u32 	%r1078, [matrix+916];
	// begin inline asm
	dp4a.u32.u32 %r1077, %r1078, %r4311, %r1073;
	// end inline asm
	ld.const.u32 	%r1082, [matrix+920];
	// begin inline asm
	dp4a.u32.u32 %r1081, %r1082, %r4315, %r1077;
	// end inline asm
	ld.const.u32 	%r1086, [matrix+924];
	// begin inline asm
	dp4a.u32.u32 %r1085, %r1086, %r4319, %r1081;
	// end inline asm
	ld.const.u32 	%r1090, [matrix+928];
	// begin inline asm
	dp4a.u32.u32 %r1089, %r1090, %r4323, %r1085;
	// end inline asm
	ld.const.u32 	%r1094, [matrix+932];
	// begin inline asm
	dp4a.u32.u32 %r1093, %r1094, %r4327, %r1089;
	// end inline asm
	ld.const.u32 	%r1098, [matrix+936];
	// begin inline asm
	dp4a.u32.u32 %r1097, %r1098, %r4331, %r1093;
	// end inline asm
	ld.const.u32 	%r1102, [matrix+940];
	// begin inline asm
	dp4a.u32.u32 %r1101, %r1102, %r4335, %r1097;
	// end inline asm
	ld.const.u32 	%r1106, [matrix+944];
	// begin inline asm
	dp4a.u32.u32 %r1105, %r1106, %r4339, %r1101;
	// end inline asm
	ld.const.u32 	%r1110, [matrix+948];
	// begin inline asm
	dp4a.u32.u32 %r1109, %r1110, %r4343, %r1105;
	// end inline asm
	ld.const.u32 	%r1114, [matrix+952];
	// begin inline asm
	dp4a.u32.u32 %r1113, %r1114, %r4347, %r1109;
	// end inline asm
	ld.const.u32 	%r1118, [matrix+956];
	// begin inline asm
	dp4a.u32.u32 %r1117, %r1118, %r4351, %r1113;
	// end inline asm
	ld.const.u32 	%r1122, [matrix+960];
	// begin inline asm
	dp4a.u32.u32 %r1121, %r1122, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1126, [matrix+964];
	// begin inline asm
	dp4a.u32.u32 %r1125, %r1126, %r4295, %r1121;
	// end inline asm
	ld.const.u32 	%r1130, [matrix+968];
	// begin inline asm
	dp4a.u32.u32 %r1129, %r1130, %r4299, %r1125;
	// end inline asm
	ld.const.u32 	%r1134, [matrix+972];
	// begin inline asm
	dp4a.u32.u32 %r1133, %r1134, %r4303, %r1129;
	// end inline asm
	ld.const.u32 	%r1138, [matrix+976];
	// begin inline asm
	dp4a.u32.u32 %r1137, %r1138, %r4307, %r1133;
	// end inline asm
	ld.const.u32 	%r1142, [matrix+980];
	// begin inline asm
	dp4a.u32.u32 %r1141, %r1142, %r4311, %r1137;
	// end inline asm
	ld.const.u32 	%r1146, [matrix+984];
	// begin inline asm
	dp4a.u32.u32 %r1145, %r1146, %r4315, %r1141;
	// end inline asm
	ld.const.u32 	%r1150, [matrix+988];
	// begin inline asm
	dp4a.u32.u32 %r1149, %r1150, %r4319, %r1145;
	// end inline asm
	ld.const.u32 	%r1154, [matrix+992];
	// begin inline asm
	dp4a.u32.u32 %r1153, %r1154, %r4323, %r1149;
	// end inline asm
	ld.const.u32 	%r1158, [matrix+996];
	// begin inline asm
	dp4a.u32.u32 %r1157, %r1158, %r4327, %r1153;
	// end inline asm
	ld.const.u32 	%r1162, [matrix+1000];
	// begin inline asm
	dp4a.u32.u32 %r1161, %r1162, %r4331, %r1157;
	// end inline asm
	ld.const.u32 	%r1166, [matrix+1004];
	// begin inline asm
	dp4a.u32.u32 %r1165, %r1166, %r4335, %r1161;
	// end inline asm
	ld.const.u32 	%r1170, [matrix+1008];
	// begin inline asm
	dp4a.u32.u32 %r1169, %r1170, %r4339, %r1165;
	// end inline asm
	ld.const.u32 	%r1174, [matrix+1012];
	// begin inline asm
	dp4a.u32.u32 %r1173, %r1174, %r4343, %r1169;
	// end inline asm
	ld.const.u32 	%r1178, [matrix+1016];
	// begin inline asm
	dp4a.u32.u32 %r1177, %r1178, %r4347, %r1173;
	// end inline asm
	ld.const.u32 	%r1182, [matrix+1020];
	// begin inline asm
	dp4a.u32.u32 %r1181, %r1182, %r4351, %r1177;
	// end inline asm
	shr.u32 	%r4529, %r1117, 6;
	and.b32  	%r1186, %r4529, 240;
	shr.u32 	%r1187, %r1181, 10;
	// begin inline asm
	lop3.b32 %r1185, %r1186, %r1187, %r1188, 0x56;
	// end inline asm
	ld.const.u32 	%r1190, [matrix+1024];
	// begin inline asm
	dp4a.u32.u32 %r1189, %r1190, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1194, [matrix+1028];
	// begin inline asm
	dp4a.u32.u32 %r1193, %r1194, %r4295, %r1189;
	// end inline asm
	ld.const.u32 	%r1198, [matrix+1032];
	// begin inline asm
	dp4a.u32.u32 %r1197, %r1198, %r4299, %r1193;
	// end inline asm
	ld.const.u32 	%r1202, [matrix+1036];
	// begin inline asm
	dp4a.u32.u32 %r1201, %r1202, %r4303, %r1197;
	// end inline asm
	ld.const.u32 	%r1206, [matrix+1040];
	// begin inline asm
	dp4a.u32.u32 %r1205, %r1206, %r4307, %r1201;
	// end inline asm
	ld.const.u32 	%r1210, [matrix+1044];
	// begin inline asm
	dp4a.u32.u32 %r1209, %r1210, %r4311, %r1205;
	// end inline asm
	ld.const.u32 	%r1214, [matrix+1048];
	// begin inline asm
	dp4a.u32.u32 %r1213, %r1214, %r4315, %r1209;
	// end inline asm
	ld.const.u32 	%r1218, [matrix+1052];
	// begin inline asm
	dp4a.u32.u32 %r1217, %r1218, %r4319, %r1213;
	// end inline asm
	ld.const.u32 	%r1222, [matrix+1056];
	// begin inline asm
	dp4a.u32.u32 %r1221, %r1222, %r4323, %r1217;
	// end inline asm
	ld.const.u32 	%r1226, [matrix+1060];
	// begin inline asm
	dp4a.u32.u32 %r1225, %r1226, %r4327, %r1221;
	// end inline asm
	ld.const.u32 	%r1230, [matrix+1064];
	// begin inline asm
	dp4a.u32.u32 %r1229, %r1230, %r4331, %r1225;
	// end inline asm
	ld.const.u32 	%r1234, [matrix+1068];
	// begin inline asm
	dp4a.u32.u32 %r1233, %r1234, %r4335, %r1229;
	// end inline asm
	ld.const.u32 	%r1238, [matrix+1072];
	// begin inline asm
	dp4a.u32.u32 %r1237, %r1238, %r4339, %r1233;
	// end inline asm
	ld.const.u32 	%r1242, [matrix+1076];
	// begin inline asm
	dp4a.u32.u32 %r1241, %r1242, %r4343, %r1237;
	// end inline asm
	ld.const.u32 	%r1246, [matrix+1080];
	// begin inline asm
	dp4a.u32.u32 %r1245, %r1246, %r4347, %r1241;
	// end inline asm
	ld.const.u32 	%r1250, [matrix+1084];
	// begin inline asm
	dp4a.u32.u32 %r1249, %r1250, %r4351, %r1245;
	// end inline asm
	ld.const.u32 	%r1254, [matrix+1088];
	// begin inline asm
	dp4a.u32.u32 %r1253, %r1254, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1258, [matrix+1092];
	// begin inline asm
	dp4a.u32.u32 %r1257, %r1258, %r4295, %r1253;
	// end inline asm
	ld.const.u32 	%r1262, [matrix+1096];
	// begin inline asm
	dp4a.u32.u32 %r1261, %r1262, %r4299, %r1257;
	// end inline asm
	ld.const.u32 	%r1266, [matrix+1100];
	// begin inline asm
	dp4a.u32.u32 %r1265, %r1266, %r4303, %r1261;
	// end inline asm
	ld.const.u32 	%r1270, [matrix+1104];
	// begin inline asm
	dp4a.u32.u32 %r1269, %r1270, %r4307, %r1265;
	// end inline asm
	ld.const.u32 	%r1274, [matrix+1108];
	// begin inline asm
	dp4a.u32.u32 %r1273, %r1274, %r4311, %r1269;
	// end inline asm
	ld.const.u32 	%r1278, [matrix+1112];
	// begin inline asm
	dp4a.u32.u32 %r1277, %r1278, %r4315, %r1273;
	// end inline asm
	ld.const.u32 	%r1282, [matrix+1116];
	// begin inline asm
	dp4a.u32.u32 %r1281, %r1282, %r4319, %r1277;
	// end inline asm
	ld.const.u32 	%r1286, [matrix+1120];
	// begin inline asm
	dp4a.u32.u32 %r1285, %r1286, %r4323, %r1281;
	// end inline asm
	ld.const.u32 	%r1290, [matrix+1124];
	// begin inline asm
	dp4a.u32.u32 %r1289, %r1290, %r4327, %r1285;
	// end inline asm
	ld.const.u32 	%r1294, [matrix+1128];
	// begin inline asm
	dp4a.u32.u32 %r1293, %r1294, %r4331, %r1289;
	// end inline asm
	ld.const.u32 	%r1298, [matrix+1132];
	// begin inline asm
	dp4a.u32.u32 %r1297, %r1298, %r4335, %r1293;
	// end inline asm
	ld.const.u32 	%r1302, [matrix+1136];
	// begin inline asm
	dp4a.u32.u32 %r1301, %r1302, %r4339, %r1297;
	// end inline asm
	ld.const.u32 	%r1306, [matrix+1140];
	// begin inline asm
	dp4a.u32.u32 %r1305, %r1306, %r4343, %r1301;
	// end inline asm
	ld.const.u32 	%r1310, [matrix+1144];
	// begin inline asm
	dp4a.u32.u32 %r1309, %r1310, %r4347, %r1305;
	// end inline asm
	ld.const.u32 	%r1314, [matrix+1148];
	// begin inline asm
	dp4a.u32.u32 %r1313, %r1314, %r4351, %r1309;
	// end inline asm
	shr.u32 	%r4530, %r1249, 6;
	and.b32  	%r1318, %r4530, 240;
	shr.u32 	%r1319, %r1313, 10;
	and.b32  	%r1320, %r4411, 255;
	// begin inline asm
	lop3.b32 %r1317, %r1318, %r1319, %r1320, 0x56;
	// end inline asm
	ld.const.u32 	%r1322, [matrix+1152];
	// begin inline asm
	dp4a.u32.u32 %r1321, %r1322, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1326, [matrix+1156];
	// begin inline asm
	dp4a.u32.u32 %r1325, %r1326, %r4295, %r1321;
	// end inline asm
	ld.const.u32 	%r1330, [matrix+1160];
	// begin inline asm
	dp4a.u32.u32 %r1329, %r1330, %r4299, %r1325;
	// end inline asm
	ld.const.u32 	%r1334, [matrix+1164];
	// begin inline asm
	dp4a.u32.u32 %r1333, %r1334, %r4303, %r1329;
	// end inline asm
	ld.const.u32 	%r1338, [matrix+1168];
	// begin inline asm
	dp4a.u32.u32 %r1337, %r1338, %r4307, %r1333;
	// end inline asm
	ld.const.u32 	%r1342, [matrix+1172];
	// begin inline asm
	dp4a.u32.u32 %r1341, %r1342, %r4311, %r1337;
	// end inline asm
	ld.const.u32 	%r1346, [matrix+1176];
	// begin inline asm
	dp4a.u32.u32 %r1345, %r1346, %r4315, %r1341;
	// end inline asm
	ld.const.u32 	%r1350, [matrix+1180];
	// begin inline asm
	dp4a.u32.u32 %r1349, %r1350, %r4319, %r1345;
	// end inline asm
	ld.const.u32 	%r1354, [matrix+1184];
	// begin inline asm
	dp4a.u32.u32 %r1353, %r1354, %r4323, %r1349;
	// end inline asm
	ld.const.u32 	%r1358, [matrix+1188];
	// begin inline asm
	dp4a.u32.u32 %r1357, %r1358, %r4327, %r1353;
	// end inline asm
	ld.const.u32 	%r1362, [matrix+1192];
	// begin inline asm
	dp4a.u32.u32 %r1361, %r1362, %r4331, %r1357;
	// end inline asm
	ld.const.u32 	%r1366, [matrix+1196];
	// begin inline asm
	dp4a.u32.u32 %r1365, %r1366, %r4335, %r1361;
	// end inline asm
	ld.const.u32 	%r1370, [matrix+1200];
	// begin inline asm
	dp4a.u32.u32 %r1369, %r1370, %r4339, %r1365;
	// end inline asm
	ld.const.u32 	%r1374, [matrix+1204];
	// begin inline asm
	dp4a.u32.u32 %r1373, %r1374, %r4343, %r1369;
	// end inline asm
	ld.const.u32 	%r1378, [matrix+1208];
	// begin inline asm
	dp4a.u32.u32 %r1377, %r1378, %r4347, %r1373;
	// end inline asm
	ld.const.u32 	%r1382, [matrix+1212];
	// begin inline asm
	dp4a.u32.u32 %r1381, %r1382, %r4351, %r1377;
	// end inline asm
	ld.const.u32 	%r1386, [matrix+1216];
	// begin inline asm
	dp4a.u32.u32 %r1385, %r1386, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1390, [matrix+1220];
	// begin inline asm
	dp4a.u32.u32 %r1389, %r1390, %r4295, %r1385;
	// end inline asm
	ld.const.u32 	%r1394, [matrix+1224];
	// begin inline asm
	dp4a.u32.u32 %r1393, %r1394, %r4299, %r1389;
	// end inline asm
	ld.const.u32 	%r1398, [matrix+1228];
	// begin inline asm
	dp4a.u32.u32 %r1397, %r1398, %r4303, %r1393;
	// end inline asm
	ld.const.u32 	%r1402, [matrix+1232];
	// begin inline asm
	dp4a.u32.u32 %r1401, %r1402, %r4307, %r1397;
	// end inline asm
	ld.const.u32 	%r1406, [matrix+1236];
	// begin inline asm
	dp4a.u32.u32 %r1405, %r1406, %r4311, %r1401;
	// end inline asm
	ld.const.u32 	%r1410, [matrix+1240];
	// begin inline asm
	dp4a.u32.u32 %r1409, %r1410, %r4315, %r1405;
	// end inline asm
	ld.const.u32 	%r1414, [matrix+1244];
	// begin inline asm
	dp4a.u32.u32 %r1413, %r1414, %r4319, %r1409;
	// end inline asm
	ld.const.u32 	%r1418, [matrix+1248];
	// begin inline asm
	dp4a.u32.u32 %r1417, %r1418, %r4323, %r1413;
	// end inline asm
	ld.const.u32 	%r1422, [matrix+1252];
	// begin inline asm
	dp4a.u32.u32 %r1421, %r1422, %r4327, %r1417;
	// end inline asm
	ld.const.u32 	%r1426, [matrix+1256];
	// begin inline asm
	dp4a.u32.u32 %r1425, %r1426, %r4331, %r1421;
	// end inline asm
	ld.const.u32 	%r1430, [matrix+1260];
	// begin inline asm
	dp4a.u32.u32 %r1429, %r1430, %r4335, %r1425;
	// end inline asm
	ld.const.u32 	%r1434, [matrix+1264];
	// begin inline asm
	dp4a.u32.u32 %r1433, %r1434, %r4339, %r1429;
	// end inline asm
	ld.const.u32 	%r1438, [matrix+1268];
	// begin inline asm
	dp4a.u32.u32 %r1437, %r1438, %r4343, %r1433;
	// end inline asm
	ld.const.u32 	%r1442, [matrix+1272];
	// begin inline asm
	dp4a.u32.u32 %r1441, %r1442, %r4347, %r1437;
	// end inline asm
	ld.const.u32 	%r1446, [matrix+1276];
	// begin inline asm
	dp4a.u32.u32 %r1445, %r1446, %r4351, %r1441;
	// end inline asm
	shr.u32 	%r4531, %r1381, 6;
	and.b32  	%r1450, %r4531, 240;
	shr.u32 	%r1451, %r1445, 10;
	and.b32  	%r1452, %r4364, 255;
	// begin inline asm
	lop3.b32 %r1449, %r1450, %r1451, %r1452, 0x56;
	// end inline asm
	ld.const.u32 	%r1454, [matrix+1280];
	// begin inline asm
	dp4a.u32.u32 %r1453, %r1454, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1458, [matrix+1284];
	// begin inline asm
	dp4a.u32.u32 %r1457, %r1458, %r4295, %r1453;
	// end inline asm
	ld.const.u32 	%r1462, [matrix+1288];
	// begin inline asm
	dp4a.u32.u32 %r1461, %r1462, %r4299, %r1457;
	// end inline asm
	ld.const.u32 	%r1466, [matrix+1292];
	// begin inline asm
	dp4a.u32.u32 %r1465, %r1466, %r4303, %r1461;
	// end inline asm
	ld.const.u32 	%r1470, [matrix+1296];
	// begin inline asm
	dp4a.u32.u32 %r1469, %r1470, %r4307, %r1465;
	// end inline asm
	ld.const.u32 	%r1474, [matrix+1300];
	// begin inline asm
	dp4a.u32.u32 %r1473, %r1474, %r4311, %r1469;
	// end inline asm
	ld.const.u32 	%r1478, [matrix+1304];
	// begin inline asm
	dp4a.u32.u32 %r1477, %r1478, %r4315, %r1473;
	// end inline asm
	ld.const.u32 	%r1482, [matrix+1308];
	// begin inline asm
	dp4a.u32.u32 %r1481, %r1482, %r4319, %r1477;
	// end inline asm
	ld.const.u32 	%r1486, [matrix+1312];
	// begin inline asm
	dp4a.u32.u32 %r1485, %r1486, %r4323, %r1481;
	// end inline asm
	ld.const.u32 	%r1490, [matrix+1316];
	// begin inline asm
	dp4a.u32.u32 %r1489, %r1490, %r4327, %r1485;
	// end inline asm
	ld.const.u32 	%r1494, [matrix+1320];
	// begin inline asm
	dp4a.u32.u32 %r1493, %r1494, %r4331, %r1489;
	// end inline asm
	ld.const.u32 	%r1498, [matrix+1324];
	// begin inline asm
	dp4a.u32.u32 %r1497, %r1498, %r4335, %r1493;
	// end inline asm
	ld.const.u32 	%r1502, [matrix+1328];
	// begin inline asm
	dp4a.u32.u32 %r1501, %r1502, %r4339, %r1497;
	// end inline asm
	ld.const.u32 	%r1506, [matrix+1332];
	// begin inline asm
	dp4a.u32.u32 %r1505, %r1506, %r4343, %r1501;
	// end inline asm
	ld.const.u32 	%r1510, [matrix+1336];
	// begin inline asm
	dp4a.u32.u32 %r1509, %r1510, %r4347, %r1505;
	// end inline asm
	ld.const.u32 	%r1514, [matrix+1340];
	// begin inline asm
	dp4a.u32.u32 %r1513, %r1514, %r4351, %r1509;
	// end inline asm
	ld.const.u32 	%r1518, [matrix+1344];
	// begin inline asm
	dp4a.u32.u32 %r1517, %r1518, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1522, [matrix+1348];
	// begin inline asm
	dp4a.u32.u32 %r1521, %r1522, %r4295, %r1517;
	// end inline asm
	ld.const.u32 	%r1526, [matrix+1352];
	// begin inline asm
	dp4a.u32.u32 %r1525, %r1526, %r4299, %r1521;
	// end inline asm
	ld.const.u32 	%r1530, [matrix+1356];
	// begin inline asm
	dp4a.u32.u32 %r1529, %r1530, %r4303, %r1525;
	// end inline asm
	ld.const.u32 	%r1534, [matrix+1360];
	// begin inline asm
	dp4a.u32.u32 %r1533, %r1534, %r4307, %r1529;
	// end inline asm
	ld.const.u32 	%r1538, [matrix+1364];
	// begin inline asm
	dp4a.u32.u32 %r1537, %r1538, %r4311, %r1533;
	// end inline asm
	ld.const.u32 	%r1542, [matrix+1368];
	// begin inline asm
	dp4a.u32.u32 %r1541, %r1542, %r4315, %r1537;
	// end inline asm
	ld.const.u32 	%r1546, [matrix+1372];
	// begin inline asm
	dp4a.u32.u32 %r1545, %r1546, %r4319, %r1541;
	// end inline asm
	ld.const.u32 	%r1550, [matrix+1376];
	// begin inline asm
	dp4a.u32.u32 %r1549, %r1550, %r4323, %r1545;
	// end inline asm
	ld.const.u32 	%r1554, [matrix+1380];
	// begin inline asm
	dp4a.u32.u32 %r1553, %r1554, %r4327, %r1549;
	// end inline asm
	ld.const.u32 	%r1558, [matrix+1384];
	// begin inline asm
	dp4a.u32.u32 %r1557, %r1558, %r4331, %r1553;
	// end inline asm
	ld.const.u32 	%r1562, [matrix+1388];
	// begin inline asm
	dp4a.u32.u32 %r1561, %r1562, %r4335, %r1557;
	// end inline asm
	ld.const.u32 	%r1566, [matrix+1392];
	// begin inline asm
	dp4a.u32.u32 %r1565, %r1566, %r4339, %r1561;
	// end inline asm
	ld.const.u32 	%r1570, [matrix+1396];
	// begin inline asm
	dp4a.u32.u32 %r1569, %r1570, %r4343, %r1565;
	// end inline asm
	ld.const.u32 	%r1574, [matrix+1400];
	// begin inline asm
	dp4a.u32.u32 %r1573, %r1574, %r4347, %r1569;
	// end inline asm
	ld.const.u32 	%r1578, [matrix+1404];
	// begin inline asm
	dp4a.u32.u32 %r1577, %r1578, %r4351, %r1573;
	// end inline asm
	shr.u32 	%r4532, %r1513, 6;
	and.b32  	%r1582, %r4532, 240;
	shr.u32 	%r1583, %r1577, 10;
	and.b32  	%r1584, %r4365, 255;
	// begin inline asm
	lop3.b32 %r1581, %r1582, %r1583, %r1584, 0x56;
	// end inline asm
	ld.const.u32 	%r1586, [matrix+1408];
	// begin inline asm
	dp4a.u32.u32 %r1585, %r1586, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1590, [matrix+1412];
	// begin inline asm
	dp4a.u32.u32 %r1589, %r1590, %r4295, %r1585;
	// end inline asm
	ld.const.u32 	%r1594, [matrix+1416];
	// begin inline asm
	dp4a.u32.u32 %r1593, %r1594, %r4299, %r1589;
	// end inline asm
	ld.const.u32 	%r1598, [matrix+1420];
	// begin inline asm
	dp4a.u32.u32 %r1597, %r1598, %r4303, %r1593;
	// end inline asm
	ld.const.u32 	%r1602, [matrix+1424];
	// begin inline asm
	dp4a.u32.u32 %r1601, %r1602, %r4307, %r1597;
	// end inline asm
	ld.const.u32 	%r1606, [matrix+1428];
	// begin inline asm
	dp4a.u32.u32 %r1605, %r1606, %r4311, %r1601;
	// end inline asm
	ld.const.u32 	%r1610, [matrix+1432];
	// begin inline asm
	dp4a.u32.u32 %r1609, %r1610, %r4315, %r1605;
	// end inline asm
	ld.const.u32 	%r1614, [matrix+1436];
	// begin inline asm
	dp4a.u32.u32 %r1613, %r1614, %r4319, %r1609;
	// end inline asm
	ld.const.u32 	%r1618, [matrix+1440];
	// begin inline asm
	dp4a.u32.u32 %r1617, %r1618, %r4323, %r1613;
	// end inline asm
	ld.const.u32 	%r1622, [matrix+1444];
	// begin inline asm
	dp4a.u32.u32 %r1621, %r1622, %r4327, %r1617;
	// end inline asm
	ld.const.u32 	%r1626, [matrix+1448];
	// begin inline asm
	dp4a.u32.u32 %r1625, %r1626, %r4331, %r1621;
	// end inline asm
	ld.const.u32 	%r1630, [matrix+1452];
	// begin inline asm
	dp4a.u32.u32 %r1629, %r1630, %r4335, %r1625;
	// end inline asm
	ld.const.u32 	%r1634, [matrix+1456];
	// begin inline asm
	dp4a.u32.u32 %r1633, %r1634, %r4339, %r1629;
	// end inline asm
	ld.const.u32 	%r1638, [matrix+1460];
	// begin inline asm
	dp4a.u32.u32 %r1637, %r1638, %r4343, %r1633;
	// end inline asm
	ld.const.u32 	%r1642, [matrix+1464];
	// begin inline asm
	dp4a.u32.u32 %r1641, %r1642, %r4347, %r1637;
	// end inline asm
	ld.const.u32 	%r1646, [matrix+1468];
	// begin inline asm
	dp4a.u32.u32 %r1645, %r1646, %r4351, %r1641;
	// end inline asm
	ld.const.u32 	%r1650, [matrix+1472];
	// begin inline asm
	dp4a.u32.u32 %r1649, %r1650, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1654, [matrix+1476];
	// begin inline asm
	dp4a.u32.u32 %r1653, %r1654, %r4295, %r1649;
	// end inline asm
	ld.const.u32 	%r1658, [matrix+1480];
	// begin inline asm
	dp4a.u32.u32 %r1657, %r1658, %r4299, %r1653;
	// end inline asm
	ld.const.u32 	%r1662, [matrix+1484];
	// begin inline asm
	dp4a.u32.u32 %r1661, %r1662, %r4303, %r1657;
	// end inline asm
	ld.const.u32 	%r1666, [matrix+1488];
	// begin inline asm
	dp4a.u32.u32 %r1665, %r1666, %r4307, %r1661;
	// end inline asm
	ld.const.u32 	%r1670, [matrix+1492];
	// begin inline asm
	dp4a.u32.u32 %r1669, %r1670, %r4311, %r1665;
	// end inline asm
	ld.const.u32 	%r1674, [matrix+1496];
	// begin inline asm
	dp4a.u32.u32 %r1673, %r1674, %r4315, %r1669;
	// end inline asm
	ld.const.u32 	%r1678, [matrix+1500];
	// begin inline asm
	dp4a.u32.u32 %r1677, %r1678, %r4319, %r1673;
	// end inline asm
	ld.const.u32 	%r1682, [matrix+1504];
	// begin inline asm
	dp4a.u32.u32 %r1681, %r1682, %r4323, %r1677;
	// end inline asm
	ld.const.u32 	%r1686, [matrix+1508];
	// begin inline asm
	dp4a.u32.u32 %r1685, %r1686, %r4327, %r1681;
	// end inline asm
	ld.const.u32 	%r1690, [matrix+1512];
	// begin inline asm
	dp4a.u32.u32 %r1689, %r1690, %r4331, %r1685;
	// end inline asm
	ld.const.u32 	%r1694, [matrix+1516];
	// begin inline asm
	dp4a.u32.u32 %r1693, %r1694, %r4335, %r1689;
	// end inline asm
	ld.const.u32 	%r1698, [matrix+1520];
	// begin inline asm
	dp4a.u32.u32 %r1697, %r1698, %r4339, %r1693;
	// end inline asm
	ld.const.u32 	%r1702, [matrix+1524];
	// begin inline asm
	dp4a.u32.u32 %r1701, %r1702, %r4343, %r1697;
	// end inline asm
	ld.const.u32 	%r1706, [matrix+1528];
	// begin inline asm
	dp4a.u32.u32 %r1705, %r1706, %r4347, %r1701;
	// end inline asm
	ld.const.u32 	%r1710, [matrix+1532];
	// begin inline asm
	dp4a.u32.u32 %r1709, %r1710, %r4351, %r1705;
	// end inline asm
	shr.u32 	%r4533, %r1645, 6;
	and.b32  	%r1714, %r4533, 240;
	shr.u32 	%r1715, %r1709, 10;
	and.b32  	%r1716, %r4366, 255;
	// begin inline asm
	lop3.b32 %r1713, %r1714, %r1715, %r1716, 0x56;
	// end inline asm
	ld.const.u32 	%r1718, [matrix+1536];
	// begin inline asm
	dp4a.u32.u32 %r1717, %r1718, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1722, [matrix+1540];
	// begin inline asm
	dp4a.u32.u32 %r1721, %r1722, %r4295, %r1717;
	// end inline asm
	ld.const.u32 	%r1726, [matrix+1544];
	// begin inline asm
	dp4a.u32.u32 %r1725, %r1726, %r4299, %r1721;
	// end inline asm
	ld.const.u32 	%r1730, [matrix+1548];
	// begin inline asm
	dp4a.u32.u32 %r1729, %r1730, %r4303, %r1725;
	// end inline asm
	ld.const.u32 	%r1734, [matrix+1552];
	// begin inline asm
	dp4a.u32.u32 %r1733, %r1734, %r4307, %r1729;
	// end inline asm
	ld.const.u32 	%r1738, [matrix+1556];
	// begin inline asm
	dp4a.u32.u32 %r1737, %r1738, %r4311, %r1733;
	// end inline asm
	ld.const.u32 	%r1742, [matrix+1560];
	// begin inline asm
	dp4a.u32.u32 %r1741, %r1742, %r4315, %r1737;
	// end inline asm
	ld.const.u32 	%r1746, [matrix+1564];
	// begin inline asm
	dp4a.u32.u32 %r1745, %r1746, %r4319, %r1741;
	// end inline asm
	ld.const.u32 	%r1750, [matrix+1568];
	// begin inline asm
	dp4a.u32.u32 %r1749, %r1750, %r4323, %r1745;
	// end inline asm
	ld.const.u32 	%r1754, [matrix+1572];
	// begin inline asm
	dp4a.u32.u32 %r1753, %r1754, %r4327, %r1749;
	// end inline asm
	ld.const.u32 	%r1758, [matrix+1576];
	// begin inline asm
	dp4a.u32.u32 %r1757, %r1758, %r4331, %r1753;
	// end inline asm
	ld.const.u32 	%r1762, [matrix+1580];
	// begin inline asm
	dp4a.u32.u32 %r1761, %r1762, %r4335, %r1757;
	// end inline asm
	ld.const.u32 	%r1766, [matrix+1584];
	// begin inline asm
	dp4a.u32.u32 %r1765, %r1766, %r4339, %r1761;
	// end inline asm
	ld.const.u32 	%r1770, [matrix+1588];
	// begin inline asm
	dp4a.u32.u32 %r1769, %r1770, %r4343, %r1765;
	// end inline asm
	ld.const.u32 	%r1774, [matrix+1592];
	// begin inline asm
	dp4a.u32.u32 %r1773, %r1774, %r4347, %r1769;
	// end inline asm
	ld.const.u32 	%r1778, [matrix+1596];
	// begin inline asm
	dp4a.u32.u32 %r1777, %r1778, %r4351, %r1773;
	// end inline asm
	ld.const.u32 	%r1782, [matrix+1600];
	// begin inline asm
	dp4a.u32.u32 %r1781, %r1782, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1786, [matrix+1604];
	// begin inline asm
	dp4a.u32.u32 %r1785, %r1786, %r4295, %r1781;
	// end inline asm
	ld.const.u32 	%r1790, [matrix+1608];
	// begin inline asm
	dp4a.u32.u32 %r1789, %r1790, %r4299, %r1785;
	// end inline asm
	ld.const.u32 	%r1794, [matrix+1612];
	// begin inline asm
	dp4a.u32.u32 %r1793, %r1794, %r4303, %r1789;
	// end inline asm
	ld.const.u32 	%r1798, [matrix+1616];
	// begin inline asm
	dp4a.u32.u32 %r1797, %r1798, %r4307, %r1793;
	// end inline asm
	ld.const.u32 	%r1802, [matrix+1620];
	// begin inline asm
	dp4a.u32.u32 %r1801, %r1802, %r4311, %r1797;
	// end inline asm
	ld.const.u32 	%r1806, [matrix+1624];
	// begin inline asm
	dp4a.u32.u32 %r1805, %r1806, %r4315, %r1801;
	// end inline asm
	ld.const.u32 	%r1810, [matrix+1628];
	// begin inline asm
	dp4a.u32.u32 %r1809, %r1810, %r4319, %r1805;
	// end inline asm
	ld.const.u32 	%r1814, [matrix+1632];
	// begin inline asm
	dp4a.u32.u32 %r1813, %r1814, %r4323, %r1809;
	// end inline asm
	ld.const.u32 	%r1818, [matrix+1636];
	// begin inline asm
	dp4a.u32.u32 %r1817, %r1818, %r4327, %r1813;
	// end inline asm
	ld.const.u32 	%r1822, [matrix+1640];
	// begin inline asm
	dp4a.u32.u32 %r1821, %r1822, %r4331, %r1817;
	// end inline asm
	ld.const.u32 	%r1826, [matrix+1644];
	// begin inline asm
	dp4a.u32.u32 %r1825, %r1826, %r4335, %r1821;
	// end inline asm
	ld.const.u32 	%r1830, [matrix+1648];
	// begin inline asm
	dp4a.u32.u32 %r1829, %r1830, %r4339, %r1825;
	// end inline asm
	ld.const.u32 	%r1834, [matrix+1652];
	// begin inline asm
	dp4a.u32.u32 %r1833, %r1834, %r4343, %r1829;
	// end inline asm
	ld.const.u32 	%r1838, [matrix+1656];
	// begin inline asm
	dp4a.u32.u32 %r1837, %r1838, %r4347, %r1833;
	// end inline asm
	ld.const.u32 	%r1842, [matrix+1660];
	// begin inline asm
	dp4a.u32.u32 %r1841, %r1842, %r4351, %r1837;
	// end inline asm
	shr.u32 	%r4534, %r1777, 6;
	and.b32  	%r1846, %r4534, 240;
	shr.u32 	%r1847, %r1841, 10;
	and.b32  	%r1848, %r4367, 255;
	// begin inline asm
	lop3.b32 %r1845, %r1846, %r1847, %r1848, 0x56;
	// end inline asm
	ld.const.u32 	%r1850, [matrix+1664];
	// begin inline asm
	dp4a.u32.u32 %r1849, %r1850, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1854, [matrix+1668];
	// begin inline asm
	dp4a.u32.u32 %r1853, %r1854, %r4295, %r1849;
	// end inline asm
	ld.const.u32 	%r1858, [matrix+1672];
	// begin inline asm
	dp4a.u32.u32 %r1857, %r1858, %r4299, %r1853;
	// end inline asm
	ld.const.u32 	%r1862, [matrix+1676];
	// begin inline asm
	dp4a.u32.u32 %r1861, %r1862, %r4303, %r1857;
	// end inline asm
	ld.const.u32 	%r1866, [matrix+1680];
	// begin inline asm
	dp4a.u32.u32 %r1865, %r1866, %r4307, %r1861;
	// end inline asm
	ld.const.u32 	%r1870, [matrix+1684];
	// begin inline asm
	dp4a.u32.u32 %r1869, %r1870, %r4311, %r1865;
	// end inline asm
	ld.const.u32 	%r1874, [matrix+1688];
	// begin inline asm
	dp4a.u32.u32 %r1873, %r1874, %r4315, %r1869;
	// end inline asm
	ld.const.u32 	%r1878, [matrix+1692];
	// begin inline asm
	dp4a.u32.u32 %r1877, %r1878, %r4319, %r1873;
	// end inline asm
	ld.const.u32 	%r1882, [matrix+1696];
	// begin inline asm
	dp4a.u32.u32 %r1881, %r1882, %r4323, %r1877;
	// end inline asm
	ld.const.u32 	%r1886, [matrix+1700];
	// begin inline asm
	dp4a.u32.u32 %r1885, %r1886, %r4327, %r1881;
	// end inline asm
	ld.const.u32 	%r1890, [matrix+1704];
	// begin inline asm
	dp4a.u32.u32 %r1889, %r1890, %r4331, %r1885;
	// end inline asm
	ld.const.u32 	%r1894, [matrix+1708];
	// begin inline asm
	dp4a.u32.u32 %r1893, %r1894, %r4335, %r1889;
	// end inline asm
	ld.const.u32 	%r1898, [matrix+1712];
	// begin inline asm
	dp4a.u32.u32 %r1897, %r1898, %r4339, %r1893;
	// end inline asm
	ld.const.u32 	%r1902, [matrix+1716];
	// begin inline asm
	dp4a.u32.u32 %r1901, %r1902, %r4343, %r1897;
	// end inline asm
	ld.const.u32 	%r1906, [matrix+1720];
	// begin inline asm
	dp4a.u32.u32 %r1905, %r1906, %r4347, %r1901;
	// end inline asm
	ld.const.u32 	%r1910, [matrix+1724];
	// begin inline asm
	dp4a.u32.u32 %r1909, %r1910, %r4351, %r1905;
	// end inline asm
	ld.const.u32 	%r1914, [matrix+1728];
	// begin inline asm
	dp4a.u32.u32 %r1913, %r1914, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1918, [matrix+1732];
	// begin inline asm
	dp4a.u32.u32 %r1917, %r1918, %r4295, %r1913;
	// end inline asm
	ld.const.u32 	%r1922, [matrix+1736];
	// begin inline asm
	dp4a.u32.u32 %r1921, %r1922, %r4299, %r1917;
	// end inline asm
	ld.const.u32 	%r1926, [matrix+1740];
	// begin inline asm
	dp4a.u32.u32 %r1925, %r1926, %r4303, %r1921;
	// end inline asm
	ld.const.u32 	%r1930, [matrix+1744];
	// begin inline asm
	dp4a.u32.u32 %r1929, %r1930, %r4307, %r1925;
	// end inline asm
	ld.const.u32 	%r1934, [matrix+1748];
	// begin inline asm
	dp4a.u32.u32 %r1933, %r1934, %r4311, %r1929;
	// end inline asm
	ld.const.u32 	%r1938, [matrix+1752];
	// begin inline asm
	dp4a.u32.u32 %r1937, %r1938, %r4315, %r1933;
	// end inline asm
	ld.const.u32 	%r1942, [matrix+1756];
	// begin inline asm
	dp4a.u32.u32 %r1941, %r1942, %r4319, %r1937;
	// end inline asm
	ld.const.u32 	%r1946, [matrix+1760];
	// begin inline asm
	dp4a.u32.u32 %r1945, %r1946, %r4323, %r1941;
	// end inline asm
	ld.const.u32 	%r1950, [matrix+1764];
	// begin inline asm
	dp4a.u32.u32 %r1949, %r1950, %r4327, %r1945;
	// end inline asm
	ld.const.u32 	%r1954, [matrix+1768];
	// begin inline asm
	dp4a.u32.u32 %r1953, %r1954, %r4331, %r1949;
	// end inline asm
	ld.const.u32 	%r1958, [matrix+1772];
	// begin inline asm
	dp4a.u32.u32 %r1957, %r1958, %r4335, %r1953;
	// end inline asm
	ld.const.u32 	%r1962, [matrix+1776];
	// begin inline asm
	dp4a.u32.u32 %r1961, %r1962, %r4339, %r1957;
	// end inline asm
	ld.const.u32 	%r1966, [matrix+1780];
	// begin inline asm
	dp4a.u32.u32 %r1965, %r1966, %r4343, %r1961;
	// end inline asm
	ld.const.u32 	%r1970, [matrix+1784];
	// begin inline asm
	dp4a.u32.u32 %r1969, %r1970, %r4347, %r1965;
	// end inline asm
	ld.const.u32 	%r1974, [matrix+1788];
	// begin inline asm
	dp4a.u32.u32 %r1973, %r1974, %r4351, %r1969;
	// end inline asm
	shr.u32 	%r4535, %r1909, 6;
	and.b32  	%r1978, %r4535, 240;
	shr.u32 	%r1979, %r1973, 10;
	and.b32  	%r1980, %r4368, 255;
	// begin inline asm
	lop3.b32 %r1977, %r1978, %r1979, %r1980, 0x56;
	// end inline asm
	ld.const.u32 	%r1982, [matrix+1792];
	// begin inline asm
	dp4a.u32.u32 %r1981, %r1982, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r1986, [matrix+1796];
	// begin inline asm
	dp4a.u32.u32 %r1985, %r1986, %r4295, %r1981;
	// end inline asm
	ld.const.u32 	%r1990, [matrix+1800];
	// begin inline asm
	dp4a.u32.u32 %r1989, %r1990, %r4299, %r1985;
	// end inline asm
	ld.const.u32 	%r1994, [matrix+1804];
	// begin inline asm
	dp4a.u32.u32 %r1993, %r1994, %r4303, %r1989;
	// end inline asm
	ld.const.u32 	%r1998, [matrix+1808];
	// begin inline asm
	dp4a.u32.u32 %r1997, %r1998, %r4307, %r1993;
	// end inline asm
	ld.const.u32 	%r2002, [matrix+1812];
	// begin inline asm
	dp4a.u32.u32 %r2001, %r2002, %r4311, %r1997;
	// end inline asm
	ld.const.u32 	%r2006, [matrix+1816];
	// begin inline asm
	dp4a.u32.u32 %r2005, %r2006, %r4315, %r2001;
	// end inline asm
	ld.const.u32 	%r2010, [matrix+1820];
	// begin inline asm
	dp4a.u32.u32 %r2009, %r2010, %r4319, %r2005;
	// end inline asm
	ld.const.u32 	%r2014, [matrix+1824];
	// begin inline asm
	dp4a.u32.u32 %r2013, %r2014, %r4323, %r2009;
	// end inline asm
	ld.const.u32 	%r2018, [matrix+1828];
	// begin inline asm
	dp4a.u32.u32 %r2017, %r2018, %r4327, %r2013;
	// end inline asm
	ld.const.u32 	%r2022, [matrix+1832];
	// begin inline asm
	dp4a.u32.u32 %r2021, %r2022, %r4331, %r2017;
	// end inline asm
	ld.const.u32 	%r2026, [matrix+1836];
	// begin inline asm
	dp4a.u32.u32 %r2025, %r2026, %r4335, %r2021;
	// end inline asm
	ld.const.u32 	%r2030, [matrix+1840];
	// begin inline asm
	dp4a.u32.u32 %r2029, %r2030, %r4339, %r2025;
	// end inline asm
	ld.const.u32 	%r2034, [matrix+1844];
	// begin inline asm
	dp4a.u32.u32 %r2033, %r2034, %r4343, %r2029;
	// end inline asm
	ld.const.u32 	%r2038, [matrix+1848];
	// begin inline asm
	dp4a.u32.u32 %r2037, %r2038, %r4347, %r2033;
	// end inline asm
	ld.const.u32 	%r2042, [matrix+1852];
	// begin inline asm
	dp4a.u32.u32 %r2041, %r2042, %r4351, %r2037;
	// end inline asm
	ld.const.u32 	%r2046, [matrix+1856];
	// begin inline asm
	dp4a.u32.u32 %r2045, %r2046, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2050, [matrix+1860];
	// begin inline asm
	dp4a.u32.u32 %r2049, %r2050, %r4295, %r2045;
	// end inline asm
	ld.const.u32 	%r2054, [matrix+1864];
	// begin inline asm
	dp4a.u32.u32 %r2053, %r2054, %r4299, %r2049;
	// end inline asm
	ld.const.u32 	%r2058, [matrix+1868];
	// begin inline asm
	dp4a.u32.u32 %r2057, %r2058, %r4303, %r2053;
	// end inline asm
	ld.const.u32 	%r2062, [matrix+1872];
	// begin inline asm
	dp4a.u32.u32 %r2061, %r2062, %r4307, %r2057;
	// end inline asm
	ld.const.u32 	%r2066, [matrix+1876];
	// begin inline asm
	dp4a.u32.u32 %r2065, %r2066, %r4311, %r2061;
	// end inline asm
	ld.const.u32 	%r2070, [matrix+1880];
	// begin inline asm
	dp4a.u32.u32 %r2069, %r2070, %r4315, %r2065;
	// end inline asm
	ld.const.u32 	%r2074, [matrix+1884];
	// begin inline asm
	dp4a.u32.u32 %r2073, %r2074, %r4319, %r2069;
	// end inline asm
	ld.const.u32 	%r2078, [matrix+1888];
	// begin inline asm
	dp4a.u32.u32 %r2077, %r2078, %r4323, %r2073;
	// end inline asm
	ld.const.u32 	%r2082, [matrix+1892];
	// begin inline asm
	dp4a.u32.u32 %r2081, %r2082, %r4327, %r2077;
	// end inline asm
	ld.const.u32 	%r2086, [matrix+1896];
	// begin inline asm
	dp4a.u32.u32 %r2085, %r2086, %r4331, %r2081;
	// end inline asm
	ld.const.u32 	%r2090, [matrix+1900];
	// begin inline asm
	dp4a.u32.u32 %r2089, %r2090, %r4335, %r2085;
	// end inline asm
	ld.const.u32 	%r2094, [matrix+1904];
	// begin inline asm
	dp4a.u32.u32 %r2093, %r2094, %r4339, %r2089;
	// end inline asm
	ld.const.u32 	%r2098, [matrix+1908];
	// begin inline asm
	dp4a.u32.u32 %r2097, %r2098, %r4343, %r2093;
	// end inline asm
	ld.const.u32 	%r2102, [matrix+1912];
	// begin inline asm
	dp4a.u32.u32 %r2101, %r2102, %r4347, %r2097;
	// end inline asm
	ld.const.u32 	%r2106, [matrix+1916];
	// begin inline asm
	dp4a.u32.u32 %r2105, %r2106, %r4351, %r2101;
	// end inline asm
	shr.u32 	%r4536, %r2041, 6;
	and.b32  	%r2110, %r4536, 240;
	shr.u32 	%r2111, %r2105, 10;
	and.b32  	%r2112, %r4369, 255;
	// begin inline asm
	lop3.b32 %r2109, %r2110, %r2111, %r2112, 0x56;
	// end inline asm
	ld.const.u32 	%r2114, [matrix+1920];
	// begin inline asm
	dp4a.u32.u32 %r2113, %r2114, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2118, [matrix+1924];
	// begin inline asm
	dp4a.u32.u32 %r2117, %r2118, %r4295, %r2113;
	// end inline asm
	ld.const.u32 	%r2122, [matrix+1928];
	// begin inline asm
	dp4a.u32.u32 %r2121, %r2122, %r4299, %r2117;
	// end inline asm
	ld.const.u32 	%r2126, [matrix+1932];
	// begin inline asm
	dp4a.u32.u32 %r2125, %r2126, %r4303, %r2121;
	// end inline asm
	ld.const.u32 	%r2130, [matrix+1936];
	// begin inline asm
	dp4a.u32.u32 %r2129, %r2130, %r4307, %r2125;
	// end inline asm
	ld.const.u32 	%r2134, [matrix+1940];
	// begin inline asm
	dp4a.u32.u32 %r2133, %r2134, %r4311, %r2129;
	// end inline asm
	ld.const.u32 	%r2138, [matrix+1944];
	// begin inline asm
	dp4a.u32.u32 %r2137, %r2138, %r4315, %r2133;
	// end inline asm
	ld.const.u32 	%r2142, [matrix+1948];
	// begin inline asm
	dp4a.u32.u32 %r2141, %r2142, %r4319, %r2137;
	// end inline asm
	ld.const.u32 	%r2146, [matrix+1952];
	// begin inline asm
	dp4a.u32.u32 %r2145, %r2146, %r4323, %r2141;
	// end inline asm
	ld.const.u32 	%r2150, [matrix+1956];
	// begin inline asm
	dp4a.u32.u32 %r2149, %r2150, %r4327, %r2145;
	// end inline asm
	ld.const.u32 	%r2154, [matrix+1960];
	// begin inline asm
	dp4a.u32.u32 %r2153, %r2154, %r4331, %r2149;
	// end inline asm
	ld.const.u32 	%r2158, [matrix+1964];
	// begin inline asm
	dp4a.u32.u32 %r2157, %r2158, %r4335, %r2153;
	// end inline asm
	ld.const.u32 	%r2162, [matrix+1968];
	// begin inline asm
	dp4a.u32.u32 %r2161, %r2162, %r4339, %r2157;
	// end inline asm
	ld.const.u32 	%r2166, [matrix+1972];
	// begin inline asm
	dp4a.u32.u32 %r2165, %r2166, %r4343, %r2161;
	// end inline asm
	ld.const.u32 	%r2170, [matrix+1976];
	// begin inline asm
	dp4a.u32.u32 %r2169, %r2170, %r4347, %r2165;
	// end inline asm
	ld.const.u32 	%r2174, [matrix+1980];
	// begin inline asm
	dp4a.u32.u32 %r2173, %r2174, %r4351, %r2169;
	// end inline asm
	ld.const.u32 	%r2178, [matrix+1984];
	// begin inline asm
	dp4a.u32.u32 %r2177, %r2178, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2182, [matrix+1988];
	// begin inline asm
	dp4a.u32.u32 %r2181, %r2182, %r4295, %r2177;
	// end inline asm
	ld.const.u32 	%r2186, [matrix+1992];
	// begin inline asm
	dp4a.u32.u32 %r2185, %r2186, %r4299, %r2181;
	// end inline asm
	ld.const.u32 	%r2190, [matrix+1996];
	// begin inline asm
	dp4a.u32.u32 %r2189, %r2190, %r4303, %r2185;
	// end inline asm
	ld.const.u32 	%r2194, [matrix+2000];
	// begin inline asm
	dp4a.u32.u32 %r2193, %r2194, %r4307, %r2189;
	// end inline asm
	ld.const.u32 	%r2198, [matrix+2004];
	// begin inline asm
	dp4a.u32.u32 %r2197, %r2198, %r4311, %r2193;
	// end inline asm
	ld.const.u32 	%r2202, [matrix+2008];
	// begin inline asm
	dp4a.u32.u32 %r2201, %r2202, %r4315, %r2197;
	// end inline asm
	ld.const.u32 	%r2206, [matrix+2012];
	// begin inline asm
	dp4a.u32.u32 %r2205, %r2206, %r4319, %r2201;
	// end inline asm
	ld.const.u32 	%r2210, [matrix+2016];
	// begin inline asm
	dp4a.u32.u32 %r2209, %r2210, %r4323, %r2205;
	// end inline asm
	ld.const.u32 	%r2214, [matrix+2020];
	// begin inline asm
	dp4a.u32.u32 %r2213, %r2214, %r4327, %r2209;
	// end inline asm
	ld.const.u32 	%r2218, [matrix+2024];
	// begin inline asm
	dp4a.u32.u32 %r2217, %r2218, %r4331, %r2213;
	// end inline asm
	ld.const.u32 	%r2222, [matrix+2028];
	// begin inline asm
	dp4a.u32.u32 %r2221, %r2222, %r4335, %r2217;
	// end inline asm
	ld.const.u32 	%r2226, [matrix+2032];
	// begin inline asm
	dp4a.u32.u32 %r2225, %r2226, %r4339, %r2221;
	// end inline asm
	ld.const.u32 	%r2230, [matrix+2036];
	// begin inline asm
	dp4a.u32.u32 %r2229, %r2230, %r4343, %r2225;
	// end inline asm
	ld.const.u32 	%r2234, [matrix+2040];
	// begin inline asm
	dp4a.u32.u32 %r2233, %r2234, %r4347, %r2229;
	// end inline asm
	ld.const.u32 	%r2238, [matrix+2044];
	// begin inline asm
	dp4a.u32.u32 %r2237, %r2238, %r4351, %r2233;
	// end inline asm
	shr.u32 	%r4537, %r2173, 6;
	and.b32  	%r2242, %r4537, 240;
	shr.u32 	%r2243, %r2237, 10;
	// begin inline asm
	lop3.b32 %r2241, %r2242, %r2243, %r2244, 0x56;
	// end inline asm
	ld.const.u32 	%r2246, [matrix+2048];
	// begin inline asm
	dp4a.u32.u32 %r2245, %r2246, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2250, [matrix+2052];
	// begin inline asm
	dp4a.u32.u32 %r2249, %r2250, %r4295, %r2245;
	// end inline asm
	ld.const.u32 	%r2254, [matrix+2056];
	// begin inline asm
	dp4a.u32.u32 %r2253, %r2254, %r4299, %r2249;
	// end inline asm
	ld.const.u32 	%r2258, [matrix+2060];
	// begin inline asm
	dp4a.u32.u32 %r2257, %r2258, %r4303, %r2253;
	// end inline asm
	ld.const.u32 	%r2262, [matrix+2064];
	// begin inline asm
	dp4a.u32.u32 %r2261, %r2262, %r4307, %r2257;
	// end inline asm
	ld.const.u32 	%r2266, [matrix+2068];
	// begin inline asm
	dp4a.u32.u32 %r2265, %r2266, %r4311, %r2261;
	// end inline asm
	ld.const.u32 	%r2270, [matrix+2072];
	// begin inline asm
	dp4a.u32.u32 %r2269, %r2270, %r4315, %r2265;
	// end inline asm
	ld.const.u32 	%r2274, [matrix+2076];
	// begin inline asm
	dp4a.u32.u32 %r2273, %r2274, %r4319, %r2269;
	// end inline asm
	ld.const.u32 	%r2278, [matrix+2080];
	// begin inline asm
	dp4a.u32.u32 %r2277, %r2278, %r4323, %r2273;
	// end inline asm
	ld.const.u32 	%r2282, [matrix+2084];
	// begin inline asm
	dp4a.u32.u32 %r2281, %r2282, %r4327, %r2277;
	// end inline asm
	ld.const.u32 	%r2286, [matrix+2088];
	// begin inline asm
	dp4a.u32.u32 %r2285, %r2286, %r4331, %r2281;
	// end inline asm
	ld.const.u32 	%r2290, [matrix+2092];
	// begin inline asm
	dp4a.u32.u32 %r2289, %r2290, %r4335, %r2285;
	// end inline asm
	ld.const.u32 	%r2294, [matrix+2096];
	// begin inline asm
	dp4a.u32.u32 %r2293, %r2294, %r4339, %r2289;
	// end inline asm
	ld.const.u32 	%r2298, [matrix+2100];
	// begin inline asm
	dp4a.u32.u32 %r2297, %r2298, %r4343, %r2293;
	// end inline asm
	ld.const.u32 	%r2302, [matrix+2104];
	// begin inline asm
	dp4a.u32.u32 %r2301, %r2302, %r4347, %r2297;
	// end inline asm
	ld.const.u32 	%r2306, [matrix+2108];
	// begin inline asm
	dp4a.u32.u32 %r2305, %r2306, %r4351, %r2301;
	// end inline asm
	ld.const.u32 	%r2310, [matrix+2112];
	// begin inline asm
	dp4a.u32.u32 %r2309, %r2310, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2314, [matrix+2116];
	// begin inline asm
	dp4a.u32.u32 %r2313, %r2314, %r4295, %r2309;
	// end inline asm
	ld.const.u32 	%r2318, [matrix+2120];
	// begin inline asm
	dp4a.u32.u32 %r2317, %r2318, %r4299, %r2313;
	// end inline asm
	ld.const.u32 	%r2322, [matrix+2124];
	// begin inline asm
	dp4a.u32.u32 %r2321, %r2322, %r4303, %r2317;
	// end inline asm
	ld.const.u32 	%r2326, [matrix+2128];
	// begin inline asm
	dp4a.u32.u32 %r2325, %r2326, %r4307, %r2321;
	// end inline asm
	ld.const.u32 	%r2330, [matrix+2132];
	// begin inline asm
	dp4a.u32.u32 %r2329, %r2330, %r4311, %r2325;
	// end inline asm
	ld.const.u32 	%r2334, [matrix+2136];
	// begin inline asm
	dp4a.u32.u32 %r2333, %r2334, %r4315, %r2329;
	// end inline asm
	ld.const.u32 	%r2338, [matrix+2140];
	// begin inline asm
	dp4a.u32.u32 %r2337, %r2338, %r4319, %r2333;
	// end inline asm
	ld.const.u32 	%r2342, [matrix+2144];
	// begin inline asm
	dp4a.u32.u32 %r2341, %r2342, %r4323, %r2337;
	// end inline asm
	ld.const.u32 	%r2346, [matrix+2148];
	// begin inline asm
	dp4a.u32.u32 %r2345, %r2346, %r4327, %r2341;
	// end inline asm
	ld.const.u32 	%r2350, [matrix+2152];
	// begin inline asm
	dp4a.u32.u32 %r2349, %r2350, %r4331, %r2345;
	// end inline asm
	ld.const.u32 	%r2354, [matrix+2156];
	// begin inline asm
	dp4a.u32.u32 %r2353, %r2354, %r4335, %r2349;
	// end inline asm
	ld.const.u32 	%r2358, [matrix+2160];
	// begin inline asm
	dp4a.u32.u32 %r2357, %r2358, %r4339, %r2353;
	// end inline asm
	ld.const.u32 	%r2362, [matrix+2164];
	// begin inline asm
	dp4a.u32.u32 %r2361, %r2362, %r4343, %r2357;
	// end inline asm
	ld.const.u32 	%r2366, [matrix+2168];
	// begin inline asm
	dp4a.u32.u32 %r2365, %r2366, %r4347, %r2361;
	// end inline asm
	ld.const.u32 	%r2370, [matrix+2172];
	// begin inline asm
	dp4a.u32.u32 %r2369, %r2370, %r4351, %r2365;
	// end inline asm
	shr.u32 	%r4538, %r2305, 6;
	and.b32  	%r2374, %r4538, 240;
	shr.u32 	%r2375, %r2369, 10;
	and.b32  	%r2376, %r4446, 255;
	// begin inline asm
	lop3.b32 %r2373, %r2374, %r2375, %r2376, 0x56;
	// end inline asm
	ld.const.u32 	%r2378, [matrix+2176];
	// begin inline asm
	dp4a.u32.u32 %r2377, %r2378, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2382, [matrix+2180];
	// begin inline asm
	dp4a.u32.u32 %r2381, %r2382, %r4295, %r2377;
	// end inline asm
	ld.const.u32 	%r2386, [matrix+2184];
	// begin inline asm
	dp4a.u32.u32 %r2385, %r2386, %r4299, %r2381;
	// end inline asm
	ld.const.u32 	%r2390, [matrix+2188];
	// begin inline asm
	dp4a.u32.u32 %r2389, %r2390, %r4303, %r2385;
	// end inline asm
	ld.const.u32 	%r2394, [matrix+2192];
	// begin inline asm
	dp4a.u32.u32 %r2393, %r2394, %r4307, %r2389;
	// end inline asm
	ld.const.u32 	%r2398, [matrix+2196];
	// begin inline asm
	dp4a.u32.u32 %r2397, %r2398, %r4311, %r2393;
	// end inline asm
	ld.const.u32 	%r2402, [matrix+2200];
	// begin inline asm
	dp4a.u32.u32 %r2401, %r2402, %r4315, %r2397;
	// end inline asm
	ld.const.u32 	%r2406, [matrix+2204];
	// begin inline asm
	dp4a.u32.u32 %r2405, %r2406, %r4319, %r2401;
	// end inline asm
	ld.const.u32 	%r2410, [matrix+2208];
	// begin inline asm
	dp4a.u32.u32 %r2409, %r2410, %r4323, %r2405;
	// end inline asm
	ld.const.u32 	%r2414, [matrix+2212];
	// begin inline asm
	dp4a.u32.u32 %r2413, %r2414, %r4327, %r2409;
	// end inline asm
	ld.const.u32 	%r2418, [matrix+2216];
	// begin inline asm
	dp4a.u32.u32 %r2417, %r2418, %r4331, %r2413;
	// end inline asm
	ld.const.u32 	%r2422, [matrix+2220];
	// begin inline asm
	dp4a.u32.u32 %r2421, %r2422, %r4335, %r2417;
	// end inline asm
	ld.const.u32 	%r2426, [matrix+2224];
	// begin inline asm
	dp4a.u32.u32 %r2425, %r2426, %r4339, %r2421;
	// end inline asm
	ld.const.u32 	%r2430, [matrix+2228];
	// begin inline asm
	dp4a.u32.u32 %r2429, %r2430, %r4343, %r2425;
	// end inline asm
	ld.const.u32 	%r2434, [matrix+2232];
	// begin inline asm
	dp4a.u32.u32 %r2433, %r2434, %r4347, %r2429;
	// end inline asm
	ld.const.u32 	%r2438, [matrix+2236];
	// begin inline asm
	dp4a.u32.u32 %r2437, %r2438, %r4351, %r2433;
	// end inline asm
	ld.const.u32 	%r2442, [matrix+2240];
	// begin inline asm
	dp4a.u32.u32 %r2441, %r2442, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2446, [matrix+2244];
	// begin inline asm
	dp4a.u32.u32 %r2445, %r2446, %r4295, %r2441;
	// end inline asm
	ld.const.u32 	%r2450, [matrix+2248];
	// begin inline asm
	dp4a.u32.u32 %r2449, %r2450, %r4299, %r2445;
	// end inline asm
	ld.const.u32 	%r2454, [matrix+2252];
	// begin inline asm
	dp4a.u32.u32 %r2453, %r2454, %r4303, %r2449;
	// end inline asm
	ld.const.u32 	%r2458, [matrix+2256];
	// begin inline asm
	dp4a.u32.u32 %r2457, %r2458, %r4307, %r2453;
	// end inline asm
	ld.const.u32 	%r2462, [matrix+2260];
	// begin inline asm
	dp4a.u32.u32 %r2461, %r2462, %r4311, %r2457;
	// end inline asm
	ld.const.u32 	%r2466, [matrix+2264];
	// begin inline asm
	dp4a.u32.u32 %r2465, %r2466, %r4315, %r2461;
	// end inline asm
	ld.const.u32 	%r2470, [matrix+2268];
	// begin inline asm
	dp4a.u32.u32 %r2469, %r2470, %r4319, %r2465;
	// end inline asm
	ld.const.u32 	%r2474, [matrix+2272];
	// begin inline asm
	dp4a.u32.u32 %r2473, %r2474, %r4323, %r2469;
	// end inline asm
	ld.const.u32 	%r2478, [matrix+2276];
	// begin inline asm
	dp4a.u32.u32 %r2477, %r2478, %r4327, %r2473;
	// end inline asm
	ld.const.u32 	%r2482, [matrix+2280];
	// begin inline asm
	dp4a.u32.u32 %r2481, %r2482, %r4331, %r2477;
	// end inline asm
	ld.const.u32 	%r2486, [matrix+2284];
	// begin inline asm
	dp4a.u32.u32 %r2485, %r2486, %r4335, %r2481;
	// end inline asm
	ld.const.u32 	%r2490, [matrix+2288];
	// begin inline asm
	dp4a.u32.u32 %r2489, %r2490, %r4339, %r2485;
	// end inline asm
	ld.const.u32 	%r2494, [matrix+2292];
	// begin inline asm
	dp4a.u32.u32 %r2493, %r2494, %r4343, %r2489;
	// end inline asm
	ld.const.u32 	%r2498, [matrix+2296];
	// begin inline asm
	dp4a.u32.u32 %r2497, %r2498, %r4347, %r2493;
	// end inline asm
	ld.const.u32 	%r2502, [matrix+2300];
	// begin inline asm
	dp4a.u32.u32 %r2501, %r2502, %r4351, %r2497;
	// end inline asm
	shr.u32 	%r4539, %r2437, 6;
	and.b32  	%r2506, %r4539, 240;
	shr.u32 	%r2507, %r2501, 10;
	and.b32  	%r2508, %r4370, 255;
	// begin inline asm
	lop3.b32 %r2505, %r2506, %r2507, %r2508, 0x56;
	// end inline asm
	ld.const.u32 	%r2510, [matrix+2304];
	// begin inline asm
	dp4a.u32.u32 %r2509, %r2510, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2514, [matrix+2308];
	// begin inline asm
	dp4a.u32.u32 %r2513, %r2514, %r4295, %r2509;
	// end inline asm
	ld.const.u32 	%r2518, [matrix+2312];
	// begin inline asm
	dp4a.u32.u32 %r2517, %r2518, %r4299, %r2513;
	// end inline asm
	ld.const.u32 	%r2522, [matrix+2316];
	// begin inline asm
	dp4a.u32.u32 %r2521, %r2522, %r4303, %r2517;
	// end inline asm
	ld.const.u32 	%r2526, [matrix+2320];
	// begin inline asm
	dp4a.u32.u32 %r2525, %r2526, %r4307, %r2521;
	// end inline asm
	ld.const.u32 	%r2530, [matrix+2324];
	// begin inline asm
	dp4a.u32.u32 %r2529, %r2530, %r4311, %r2525;
	// end inline asm
	ld.const.u32 	%r2534, [matrix+2328];
	// begin inline asm
	dp4a.u32.u32 %r2533, %r2534, %r4315, %r2529;
	// end inline asm
	ld.const.u32 	%r2538, [matrix+2332];
	// begin inline asm
	dp4a.u32.u32 %r2537, %r2538, %r4319, %r2533;
	// end inline asm
	ld.const.u32 	%r2542, [matrix+2336];
	// begin inline asm
	dp4a.u32.u32 %r2541, %r2542, %r4323, %r2537;
	// end inline asm
	ld.const.u32 	%r2546, [matrix+2340];
	// begin inline asm
	dp4a.u32.u32 %r2545, %r2546, %r4327, %r2541;
	// end inline asm
	ld.const.u32 	%r2550, [matrix+2344];
	// begin inline asm
	dp4a.u32.u32 %r2549, %r2550, %r4331, %r2545;
	// end inline asm
	ld.const.u32 	%r2554, [matrix+2348];
	// begin inline asm
	dp4a.u32.u32 %r2553, %r2554, %r4335, %r2549;
	// end inline asm
	ld.const.u32 	%r2558, [matrix+2352];
	// begin inline asm
	dp4a.u32.u32 %r2557, %r2558, %r4339, %r2553;
	// end inline asm
	ld.const.u32 	%r2562, [matrix+2356];
	// begin inline asm
	dp4a.u32.u32 %r2561, %r2562, %r4343, %r2557;
	// end inline asm
	ld.const.u32 	%r2566, [matrix+2360];
	// begin inline asm
	dp4a.u32.u32 %r2565, %r2566, %r4347, %r2561;
	// end inline asm
	ld.const.u32 	%r2570, [matrix+2364];
	// begin inline asm
	dp4a.u32.u32 %r2569, %r2570, %r4351, %r2565;
	// end inline asm
	ld.const.u32 	%r2574, [matrix+2368];
	// begin inline asm
	dp4a.u32.u32 %r2573, %r2574, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2578, [matrix+2372];
	// begin inline asm
	dp4a.u32.u32 %r2577, %r2578, %r4295, %r2573;
	// end inline asm
	ld.const.u32 	%r2582, [matrix+2376];
	// begin inline asm
	dp4a.u32.u32 %r2581, %r2582, %r4299, %r2577;
	// end inline asm
	ld.const.u32 	%r2586, [matrix+2380];
	// begin inline asm
	dp4a.u32.u32 %r2585, %r2586, %r4303, %r2581;
	// end inline asm
	ld.const.u32 	%r2590, [matrix+2384];
	// begin inline asm
	dp4a.u32.u32 %r2589, %r2590, %r4307, %r2585;
	// end inline asm
	ld.const.u32 	%r2594, [matrix+2388];
	// begin inline asm
	dp4a.u32.u32 %r2593, %r2594, %r4311, %r2589;
	// end inline asm
	ld.const.u32 	%r2598, [matrix+2392];
	// begin inline asm
	dp4a.u32.u32 %r2597, %r2598, %r4315, %r2593;
	// end inline asm
	ld.const.u32 	%r2602, [matrix+2396];
	// begin inline asm
	dp4a.u32.u32 %r2601, %r2602, %r4319, %r2597;
	// end inline asm
	ld.const.u32 	%r2606, [matrix+2400];
	// begin inline asm
	dp4a.u32.u32 %r2605, %r2606, %r4323, %r2601;
	// end inline asm
	ld.const.u32 	%r2610, [matrix+2404];
	// begin inline asm
	dp4a.u32.u32 %r2609, %r2610, %r4327, %r2605;
	// end inline asm
	ld.const.u32 	%r2614, [matrix+2408];
	// begin inline asm
	dp4a.u32.u32 %r2613, %r2614, %r4331, %r2609;
	// end inline asm
	ld.const.u32 	%r2618, [matrix+2412];
	// begin inline asm
	dp4a.u32.u32 %r2617, %r2618, %r4335, %r2613;
	// end inline asm
	ld.const.u32 	%r2622, [matrix+2416];
	// begin inline asm
	dp4a.u32.u32 %r2621, %r2622, %r4339, %r2617;
	// end inline asm
	ld.const.u32 	%r2626, [matrix+2420];
	// begin inline asm
	dp4a.u32.u32 %r2625, %r2626, %r4343, %r2621;
	// end inline asm
	ld.const.u32 	%r2630, [matrix+2424];
	// begin inline asm
	dp4a.u32.u32 %r2629, %r2630, %r4347, %r2625;
	// end inline asm
	ld.const.u32 	%r2634, [matrix+2428];
	// begin inline asm
	dp4a.u32.u32 %r2633, %r2634, %r4351, %r2629;
	// end inline asm
	shr.u32 	%r4540, %r2569, 6;
	and.b32  	%r2638, %r4540, 240;
	shr.u32 	%r2639, %r2633, 10;
	and.b32  	%r2640, %r4371, 255;
	// begin inline asm
	lop3.b32 %r2637, %r2638, %r2639, %r2640, 0x56;
	// end inline asm
	ld.const.u32 	%r2642, [matrix+2432];
	// begin inline asm
	dp4a.u32.u32 %r2641, %r2642, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2646, [matrix+2436];
	// begin inline asm
	dp4a.u32.u32 %r2645, %r2646, %r4295, %r2641;
	// end inline asm
	ld.const.u32 	%r2650, [matrix+2440];
	// begin inline asm
	dp4a.u32.u32 %r2649, %r2650, %r4299, %r2645;
	// end inline asm
	ld.const.u32 	%r2654, [matrix+2444];
	// begin inline asm
	dp4a.u32.u32 %r2653, %r2654, %r4303, %r2649;
	// end inline asm
	ld.const.u32 	%r2658, [matrix+2448];
	// begin inline asm
	dp4a.u32.u32 %r2657, %r2658, %r4307, %r2653;
	// end inline asm
	ld.const.u32 	%r2662, [matrix+2452];
	// begin inline asm
	dp4a.u32.u32 %r2661, %r2662, %r4311, %r2657;
	// end inline asm
	ld.const.u32 	%r2666, [matrix+2456];
	// begin inline asm
	dp4a.u32.u32 %r2665, %r2666, %r4315, %r2661;
	// end inline asm
	ld.const.u32 	%r2670, [matrix+2460];
	// begin inline asm
	dp4a.u32.u32 %r2669, %r2670, %r4319, %r2665;
	// end inline asm
	ld.const.u32 	%r2674, [matrix+2464];
	// begin inline asm
	dp4a.u32.u32 %r2673, %r2674, %r4323, %r2669;
	// end inline asm
	ld.const.u32 	%r2678, [matrix+2468];
	// begin inline asm
	dp4a.u32.u32 %r2677, %r2678, %r4327, %r2673;
	// end inline asm
	ld.const.u32 	%r2682, [matrix+2472];
	// begin inline asm
	dp4a.u32.u32 %r2681, %r2682, %r4331, %r2677;
	// end inline asm
	ld.const.u32 	%r2686, [matrix+2476];
	// begin inline asm
	dp4a.u32.u32 %r2685, %r2686, %r4335, %r2681;
	// end inline asm
	ld.const.u32 	%r2690, [matrix+2480];
	// begin inline asm
	dp4a.u32.u32 %r2689, %r2690, %r4339, %r2685;
	// end inline asm
	ld.const.u32 	%r2694, [matrix+2484];
	// begin inline asm
	dp4a.u32.u32 %r2693, %r2694, %r4343, %r2689;
	// end inline asm
	ld.const.u32 	%r2698, [matrix+2488];
	// begin inline asm
	dp4a.u32.u32 %r2697, %r2698, %r4347, %r2693;
	// end inline asm
	ld.const.u32 	%r2702, [matrix+2492];
	// begin inline asm
	dp4a.u32.u32 %r2701, %r2702, %r4351, %r2697;
	// end inline asm
	ld.const.u32 	%r2706, [matrix+2496];
	// begin inline asm
	dp4a.u32.u32 %r2705, %r2706, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2710, [matrix+2500];
	// begin inline asm
	dp4a.u32.u32 %r2709, %r2710, %r4295, %r2705;
	// end inline asm
	ld.const.u32 	%r2714, [matrix+2504];
	// begin inline asm
	dp4a.u32.u32 %r2713, %r2714, %r4299, %r2709;
	// end inline asm
	ld.const.u32 	%r2718, [matrix+2508];
	// begin inline asm
	dp4a.u32.u32 %r2717, %r2718, %r4303, %r2713;
	// end inline asm
	ld.const.u32 	%r2722, [matrix+2512];
	// begin inline asm
	dp4a.u32.u32 %r2721, %r2722, %r4307, %r2717;
	// end inline asm
	ld.const.u32 	%r2726, [matrix+2516];
	// begin inline asm
	dp4a.u32.u32 %r2725, %r2726, %r4311, %r2721;
	// end inline asm
	ld.const.u32 	%r2730, [matrix+2520];
	// begin inline asm
	dp4a.u32.u32 %r2729, %r2730, %r4315, %r2725;
	// end inline asm
	ld.const.u32 	%r2734, [matrix+2524];
	// begin inline asm
	dp4a.u32.u32 %r2733, %r2734, %r4319, %r2729;
	// end inline asm
	ld.const.u32 	%r2738, [matrix+2528];
	// begin inline asm
	dp4a.u32.u32 %r2737, %r2738, %r4323, %r2733;
	// end inline asm
	ld.const.u32 	%r2742, [matrix+2532];
	// begin inline asm
	dp4a.u32.u32 %r2741, %r2742, %r4327, %r2737;
	// end inline asm
	ld.const.u32 	%r2746, [matrix+2536];
	// begin inline asm
	dp4a.u32.u32 %r2745, %r2746, %r4331, %r2741;
	// end inline asm
	ld.const.u32 	%r2750, [matrix+2540];
	// begin inline asm
	dp4a.u32.u32 %r2749, %r2750, %r4335, %r2745;
	// end inline asm
	ld.const.u32 	%r2754, [matrix+2544];
	// begin inline asm
	dp4a.u32.u32 %r2753, %r2754, %r4339, %r2749;
	// end inline asm
	ld.const.u32 	%r2758, [matrix+2548];
	// begin inline asm
	dp4a.u32.u32 %r2757, %r2758, %r4343, %r2753;
	// end inline asm
	ld.const.u32 	%r2762, [matrix+2552];
	// begin inline asm
	dp4a.u32.u32 %r2761, %r2762, %r4347, %r2757;
	// end inline asm
	ld.const.u32 	%r2766, [matrix+2556];
	// begin inline asm
	dp4a.u32.u32 %r2765, %r2766, %r4351, %r2761;
	// end inline asm
	shr.u32 	%r4541, %r2701, 6;
	and.b32  	%r2770, %r4541, 240;
	shr.u32 	%r2771, %r2765, 10;
	and.b32  	%r2772, %r4372, 255;
	// begin inline asm
	lop3.b32 %r2769, %r2770, %r2771, %r2772, 0x56;
	// end inline asm
	ld.const.u32 	%r2774, [matrix+2560];
	// begin inline asm
	dp4a.u32.u32 %r2773, %r2774, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2778, [matrix+2564];
	// begin inline asm
	dp4a.u32.u32 %r2777, %r2778, %r4295, %r2773;
	// end inline asm
	ld.const.u32 	%r2782, [matrix+2568];
	// begin inline asm
	dp4a.u32.u32 %r2781, %r2782, %r4299, %r2777;
	// end inline asm
	ld.const.u32 	%r2786, [matrix+2572];
	// begin inline asm
	dp4a.u32.u32 %r2785, %r2786, %r4303, %r2781;
	// end inline asm
	ld.const.u32 	%r2790, [matrix+2576];
	// begin inline asm
	dp4a.u32.u32 %r2789, %r2790, %r4307, %r2785;
	// end inline asm
	ld.const.u32 	%r2794, [matrix+2580];
	// begin inline asm
	dp4a.u32.u32 %r2793, %r2794, %r4311, %r2789;
	// end inline asm
	ld.const.u32 	%r2798, [matrix+2584];
	// begin inline asm
	dp4a.u32.u32 %r2797, %r2798, %r4315, %r2793;
	// end inline asm
	ld.const.u32 	%r2802, [matrix+2588];
	// begin inline asm
	dp4a.u32.u32 %r2801, %r2802, %r4319, %r2797;
	// end inline asm
	ld.const.u32 	%r2806, [matrix+2592];
	// begin inline asm
	dp4a.u32.u32 %r2805, %r2806, %r4323, %r2801;
	// end inline asm
	ld.const.u32 	%r2810, [matrix+2596];
	// begin inline asm
	dp4a.u32.u32 %r2809, %r2810, %r4327, %r2805;
	// end inline asm
	ld.const.u32 	%r2814, [matrix+2600];
	// begin inline asm
	dp4a.u32.u32 %r2813, %r2814, %r4331, %r2809;
	// end inline asm
	ld.const.u32 	%r2818, [matrix+2604];
	// begin inline asm
	dp4a.u32.u32 %r2817, %r2818, %r4335, %r2813;
	// end inline asm
	ld.const.u32 	%r2822, [matrix+2608];
	// begin inline asm
	dp4a.u32.u32 %r2821, %r2822, %r4339, %r2817;
	// end inline asm
	ld.const.u32 	%r2826, [matrix+2612];
	// begin inline asm
	dp4a.u32.u32 %r2825, %r2826, %r4343, %r2821;
	// end inline asm
	ld.const.u32 	%r2830, [matrix+2616];
	// begin inline asm
	dp4a.u32.u32 %r2829, %r2830, %r4347, %r2825;
	// end inline asm
	ld.const.u32 	%r2834, [matrix+2620];
	// begin inline asm
	dp4a.u32.u32 %r2833, %r2834, %r4351, %r2829;
	// end inline asm
	ld.const.u32 	%r2838, [matrix+2624];
	// begin inline asm
	dp4a.u32.u32 %r2837, %r2838, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2842, [matrix+2628];
	// begin inline asm
	dp4a.u32.u32 %r2841, %r2842, %r4295, %r2837;
	// end inline asm
	ld.const.u32 	%r2846, [matrix+2632];
	// begin inline asm
	dp4a.u32.u32 %r2845, %r2846, %r4299, %r2841;
	// end inline asm
	ld.const.u32 	%r2850, [matrix+2636];
	// begin inline asm
	dp4a.u32.u32 %r2849, %r2850, %r4303, %r2845;
	// end inline asm
	ld.const.u32 	%r2854, [matrix+2640];
	// begin inline asm
	dp4a.u32.u32 %r2853, %r2854, %r4307, %r2849;
	// end inline asm
	ld.const.u32 	%r2858, [matrix+2644];
	// begin inline asm
	dp4a.u32.u32 %r2857, %r2858, %r4311, %r2853;
	// end inline asm
	ld.const.u32 	%r2862, [matrix+2648];
	// begin inline asm
	dp4a.u32.u32 %r2861, %r2862, %r4315, %r2857;
	// end inline asm
	ld.const.u32 	%r2866, [matrix+2652];
	// begin inline asm
	dp4a.u32.u32 %r2865, %r2866, %r4319, %r2861;
	// end inline asm
	ld.const.u32 	%r2870, [matrix+2656];
	// begin inline asm
	dp4a.u32.u32 %r2869, %r2870, %r4323, %r2865;
	// end inline asm
	ld.const.u32 	%r2874, [matrix+2660];
	// begin inline asm
	dp4a.u32.u32 %r2873, %r2874, %r4327, %r2869;
	// end inline asm
	ld.const.u32 	%r2878, [matrix+2664];
	// begin inline asm
	dp4a.u32.u32 %r2877, %r2878, %r4331, %r2873;
	// end inline asm
	ld.const.u32 	%r2882, [matrix+2668];
	// begin inline asm
	dp4a.u32.u32 %r2881, %r2882, %r4335, %r2877;
	// end inline asm
	ld.const.u32 	%r2886, [matrix+2672];
	// begin inline asm
	dp4a.u32.u32 %r2885, %r2886, %r4339, %r2881;
	// end inline asm
	ld.const.u32 	%r2890, [matrix+2676];
	// begin inline asm
	dp4a.u32.u32 %r2889, %r2890, %r4343, %r2885;
	// end inline asm
	ld.const.u32 	%r2894, [matrix+2680];
	// begin inline asm
	dp4a.u32.u32 %r2893, %r2894, %r4347, %r2889;
	// end inline asm
	ld.const.u32 	%r2898, [matrix+2684];
	// begin inline asm
	dp4a.u32.u32 %r2897, %r2898, %r4351, %r2893;
	// end inline asm
	shr.u32 	%r4542, %r2833, 6;
	and.b32  	%r2902, %r4542, 240;
	shr.u32 	%r2903, %r2897, 10;
	and.b32  	%r2904, %r4373, 255;
	// begin inline asm
	lop3.b32 %r2901, %r2902, %r2903, %r2904, 0x56;
	// end inline asm
	ld.const.u32 	%r2906, [matrix+2688];
	// begin inline asm
	dp4a.u32.u32 %r2905, %r2906, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2910, [matrix+2692];
	// begin inline asm
	dp4a.u32.u32 %r2909, %r2910, %r4295, %r2905;
	// end inline asm
	ld.const.u32 	%r2914, [matrix+2696];
	// begin inline asm
	dp4a.u32.u32 %r2913, %r2914, %r4299, %r2909;
	// end inline asm
	ld.const.u32 	%r2918, [matrix+2700];
	// begin inline asm
	dp4a.u32.u32 %r2917, %r2918, %r4303, %r2913;
	// end inline asm
	ld.const.u32 	%r2922, [matrix+2704];
	// begin inline asm
	dp4a.u32.u32 %r2921, %r2922, %r4307, %r2917;
	// end inline asm
	ld.const.u32 	%r2926, [matrix+2708];
	// begin inline asm
	dp4a.u32.u32 %r2925, %r2926, %r4311, %r2921;
	// end inline asm
	ld.const.u32 	%r2930, [matrix+2712];
	// begin inline asm
	dp4a.u32.u32 %r2929, %r2930, %r4315, %r2925;
	// end inline asm
	ld.const.u32 	%r2934, [matrix+2716];
	// begin inline asm
	dp4a.u32.u32 %r2933, %r2934, %r4319, %r2929;
	// end inline asm
	ld.const.u32 	%r2938, [matrix+2720];
	// begin inline asm
	dp4a.u32.u32 %r2937, %r2938, %r4323, %r2933;
	// end inline asm
	ld.const.u32 	%r2942, [matrix+2724];
	// begin inline asm
	dp4a.u32.u32 %r2941, %r2942, %r4327, %r2937;
	// end inline asm
	ld.const.u32 	%r2946, [matrix+2728];
	// begin inline asm
	dp4a.u32.u32 %r2945, %r2946, %r4331, %r2941;
	// end inline asm
	ld.const.u32 	%r2950, [matrix+2732];
	// begin inline asm
	dp4a.u32.u32 %r2949, %r2950, %r4335, %r2945;
	// end inline asm
	ld.const.u32 	%r2954, [matrix+2736];
	// begin inline asm
	dp4a.u32.u32 %r2953, %r2954, %r4339, %r2949;
	// end inline asm
	ld.const.u32 	%r2958, [matrix+2740];
	// begin inline asm
	dp4a.u32.u32 %r2957, %r2958, %r4343, %r2953;
	// end inline asm
	ld.const.u32 	%r2962, [matrix+2744];
	// begin inline asm
	dp4a.u32.u32 %r2961, %r2962, %r4347, %r2957;
	// end inline asm
	ld.const.u32 	%r2966, [matrix+2748];
	// begin inline asm
	dp4a.u32.u32 %r2965, %r2966, %r4351, %r2961;
	// end inline asm
	ld.const.u32 	%r2970, [matrix+2752];
	// begin inline asm
	dp4a.u32.u32 %r2969, %r2970, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r2974, [matrix+2756];
	// begin inline asm
	dp4a.u32.u32 %r2973, %r2974, %r4295, %r2969;
	// end inline asm
	ld.const.u32 	%r2978, [matrix+2760];
	// begin inline asm
	dp4a.u32.u32 %r2977, %r2978, %r4299, %r2973;
	// end inline asm
	ld.const.u32 	%r2982, [matrix+2764];
	// begin inline asm
	dp4a.u32.u32 %r2981, %r2982, %r4303, %r2977;
	// end inline asm
	ld.const.u32 	%r2986, [matrix+2768];
	// begin inline asm
	dp4a.u32.u32 %r2985, %r2986, %r4307, %r2981;
	// end inline asm
	ld.const.u32 	%r2990, [matrix+2772];
	// begin inline asm
	dp4a.u32.u32 %r2989, %r2990, %r4311, %r2985;
	// end inline asm
	ld.const.u32 	%r2994, [matrix+2776];
	// begin inline asm
	dp4a.u32.u32 %r2993, %r2994, %r4315, %r2989;
	// end inline asm
	ld.const.u32 	%r2998, [matrix+2780];
	// begin inline asm
	dp4a.u32.u32 %r2997, %r2998, %r4319, %r2993;
	// end inline asm
	ld.const.u32 	%r3002, [matrix+2784];
	// begin inline asm
	dp4a.u32.u32 %r3001, %r3002, %r4323, %r2997;
	// end inline asm
	ld.const.u32 	%r3006, [matrix+2788];
	// begin inline asm
	dp4a.u32.u32 %r3005, %r3006, %r4327, %r3001;
	// end inline asm
	ld.const.u32 	%r3010, [matrix+2792];
	// begin inline asm
	dp4a.u32.u32 %r3009, %r3010, %r4331, %r3005;
	// end inline asm
	ld.const.u32 	%r3014, [matrix+2796];
	// begin inline asm
	dp4a.u32.u32 %r3013, %r3014, %r4335, %r3009;
	// end inline asm
	ld.const.u32 	%r3018, [matrix+2800];
	// begin inline asm
	dp4a.u32.u32 %r3017, %r3018, %r4339, %r3013;
	// end inline asm
	ld.const.u32 	%r3022, [matrix+2804];
	// begin inline asm
	dp4a.u32.u32 %r3021, %r3022, %r4343, %r3017;
	// end inline asm
	ld.const.u32 	%r3026, [matrix+2808];
	// begin inline asm
	dp4a.u32.u32 %r3025, %r3026, %r4347, %r3021;
	// end inline asm
	ld.const.u32 	%r3030, [matrix+2812];
	// begin inline asm
	dp4a.u32.u32 %r3029, %r3030, %r4351, %r3025;
	// end inline asm
	shr.u32 	%r4543, %r2965, 6;
	and.b32  	%r3034, %r4543, 240;
	shr.u32 	%r3035, %r3029, 10;
	and.b32  	%r3036, %r4374, 255;
	// begin inline asm
	lop3.b32 %r3033, %r3034, %r3035, %r3036, 0x56;
	// end inline asm
	ld.const.u32 	%r3038, [matrix+2816];
	// begin inline asm
	dp4a.u32.u32 %r3037, %r3038, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3042, [matrix+2820];
	// begin inline asm
	dp4a.u32.u32 %r3041, %r3042, %r4295, %r3037;
	// end inline asm
	ld.const.u32 	%r3046, [matrix+2824];
	// begin inline asm
	dp4a.u32.u32 %r3045, %r3046, %r4299, %r3041;
	// end inline asm
	ld.const.u32 	%r3050, [matrix+2828];
	// begin inline asm
	dp4a.u32.u32 %r3049, %r3050, %r4303, %r3045;
	// end inline asm
	ld.const.u32 	%r3054, [matrix+2832];
	// begin inline asm
	dp4a.u32.u32 %r3053, %r3054, %r4307, %r3049;
	// end inline asm
	ld.const.u32 	%r3058, [matrix+2836];
	// begin inline asm
	dp4a.u32.u32 %r3057, %r3058, %r4311, %r3053;
	// end inline asm
	ld.const.u32 	%r3062, [matrix+2840];
	// begin inline asm
	dp4a.u32.u32 %r3061, %r3062, %r4315, %r3057;
	// end inline asm
	ld.const.u32 	%r3066, [matrix+2844];
	// begin inline asm
	dp4a.u32.u32 %r3065, %r3066, %r4319, %r3061;
	// end inline asm
	ld.const.u32 	%r3070, [matrix+2848];
	// begin inline asm
	dp4a.u32.u32 %r3069, %r3070, %r4323, %r3065;
	// end inline asm
	ld.const.u32 	%r3074, [matrix+2852];
	// begin inline asm
	dp4a.u32.u32 %r3073, %r3074, %r4327, %r3069;
	// end inline asm
	ld.const.u32 	%r3078, [matrix+2856];
	// begin inline asm
	dp4a.u32.u32 %r3077, %r3078, %r4331, %r3073;
	// end inline asm
	ld.const.u32 	%r3082, [matrix+2860];
	// begin inline asm
	dp4a.u32.u32 %r3081, %r3082, %r4335, %r3077;
	// end inline asm
	ld.const.u32 	%r3086, [matrix+2864];
	// begin inline asm
	dp4a.u32.u32 %r3085, %r3086, %r4339, %r3081;
	// end inline asm
	ld.const.u32 	%r3090, [matrix+2868];
	// begin inline asm
	dp4a.u32.u32 %r3089, %r3090, %r4343, %r3085;
	// end inline asm
	ld.const.u32 	%r3094, [matrix+2872];
	// begin inline asm
	dp4a.u32.u32 %r3093, %r3094, %r4347, %r3089;
	// end inline asm
	ld.const.u32 	%r3098, [matrix+2876];
	// begin inline asm
	dp4a.u32.u32 %r3097, %r3098, %r4351, %r3093;
	// end inline asm
	ld.const.u32 	%r3102, [matrix+2880];
	// begin inline asm
	dp4a.u32.u32 %r3101, %r3102, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3106, [matrix+2884];
	// begin inline asm
	dp4a.u32.u32 %r3105, %r3106, %r4295, %r3101;
	// end inline asm
	ld.const.u32 	%r3110, [matrix+2888];
	// begin inline asm
	dp4a.u32.u32 %r3109, %r3110, %r4299, %r3105;
	// end inline asm
	ld.const.u32 	%r3114, [matrix+2892];
	// begin inline asm
	dp4a.u32.u32 %r3113, %r3114, %r4303, %r3109;
	// end inline asm
	ld.const.u32 	%r3118, [matrix+2896];
	// begin inline asm
	dp4a.u32.u32 %r3117, %r3118, %r4307, %r3113;
	// end inline asm
	ld.const.u32 	%r3122, [matrix+2900];
	// begin inline asm
	dp4a.u32.u32 %r3121, %r3122, %r4311, %r3117;
	// end inline asm
	ld.const.u32 	%r3126, [matrix+2904];
	// begin inline asm
	dp4a.u32.u32 %r3125, %r3126, %r4315, %r3121;
	// end inline asm
	ld.const.u32 	%r3130, [matrix+2908];
	// begin inline asm
	dp4a.u32.u32 %r3129, %r3130, %r4319, %r3125;
	// end inline asm
	ld.const.u32 	%r3134, [matrix+2912];
	// begin inline asm
	dp4a.u32.u32 %r3133, %r3134, %r4323, %r3129;
	// end inline asm
	ld.const.u32 	%r3138, [matrix+2916];
	// begin inline asm
	dp4a.u32.u32 %r3137, %r3138, %r4327, %r3133;
	// end inline asm
	ld.const.u32 	%r3142, [matrix+2920];
	// begin inline asm
	dp4a.u32.u32 %r3141, %r3142, %r4331, %r3137;
	// end inline asm
	ld.const.u32 	%r3146, [matrix+2924];
	// begin inline asm
	dp4a.u32.u32 %r3145, %r3146, %r4335, %r3141;
	// end inline asm
	ld.const.u32 	%r3150, [matrix+2928];
	// begin inline asm
	dp4a.u32.u32 %r3149, %r3150, %r4339, %r3145;
	// end inline asm
	ld.const.u32 	%r3154, [matrix+2932];
	// begin inline asm
	dp4a.u32.u32 %r3153, %r3154, %r4343, %r3149;
	// end inline asm
	ld.const.u32 	%r3158, [matrix+2936];
	// begin inline asm
	dp4a.u32.u32 %r3157, %r3158, %r4347, %r3153;
	// end inline asm
	ld.const.u32 	%r3162, [matrix+2940];
	// begin inline asm
	dp4a.u32.u32 %r3161, %r3162, %r4351, %r3157;
	// end inline asm
	shr.u32 	%r4544, %r3097, 6;
	and.b32  	%r3166, %r4544, 240;
	shr.u32 	%r3167, %r3161, 10;
	and.b32  	%r3168, %r4375, 255;
	// begin inline asm
	lop3.b32 %r3165, %r3166, %r3167, %r3168, 0x56;
	// end inline asm
	ld.const.u32 	%r3170, [matrix+2944];
	// begin inline asm
	dp4a.u32.u32 %r3169, %r3170, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3174, [matrix+2948];
	// begin inline asm
	dp4a.u32.u32 %r3173, %r3174, %r4295, %r3169;
	// end inline asm
	ld.const.u32 	%r3178, [matrix+2952];
	// begin inline asm
	dp4a.u32.u32 %r3177, %r3178, %r4299, %r3173;
	// end inline asm
	ld.const.u32 	%r3182, [matrix+2956];
	// begin inline asm
	dp4a.u32.u32 %r3181, %r3182, %r4303, %r3177;
	// end inline asm
	ld.const.u32 	%r3186, [matrix+2960];
	// begin inline asm
	dp4a.u32.u32 %r3185, %r3186, %r4307, %r3181;
	// end inline asm
	ld.const.u32 	%r3190, [matrix+2964];
	// begin inline asm
	dp4a.u32.u32 %r3189, %r3190, %r4311, %r3185;
	// end inline asm
	ld.const.u32 	%r3194, [matrix+2968];
	// begin inline asm
	dp4a.u32.u32 %r3193, %r3194, %r4315, %r3189;
	// end inline asm
	ld.const.u32 	%r3198, [matrix+2972];
	// begin inline asm
	dp4a.u32.u32 %r3197, %r3198, %r4319, %r3193;
	// end inline asm
	ld.const.u32 	%r3202, [matrix+2976];
	// begin inline asm
	dp4a.u32.u32 %r3201, %r3202, %r4323, %r3197;
	// end inline asm
	ld.const.u32 	%r3206, [matrix+2980];
	// begin inline asm
	dp4a.u32.u32 %r3205, %r3206, %r4327, %r3201;
	// end inline asm
	ld.const.u32 	%r3210, [matrix+2984];
	// begin inline asm
	dp4a.u32.u32 %r3209, %r3210, %r4331, %r3205;
	// end inline asm
	ld.const.u32 	%r3214, [matrix+2988];
	// begin inline asm
	dp4a.u32.u32 %r3213, %r3214, %r4335, %r3209;
	// end inline asm
	ld.const.u32 	%r3218, [matrix+2992];
	// begin inline asm
	dp4a.u32.u32 %r3217, %r3218, %r4339, %r3213;
	// end inline asm
	ld.const.u32 	%r3222, [matrix+2996];
	// begin inline asm
	dp4a.u32.u32 %r3221, %r3222, %r4343, %r3217;
	// end inline asm
	ld.const.u32 	%r3226, [matrix+3000];
	// begin inline asm
	dp4a.u32.u32 %r3225, %r3226, %r4347, %r3221;
	// end inline asm
	ld.const.u32 	%r3230, [matrix+3004];
	// begin inline asm
	dp4a.u32.u32 %r3229, %r3230, %r4351, %r3225;
	// end inline asm
	ld.const.u32 	%r3234, [matrix+3008];
	// begin inline asm
	dp4a.u32.u32 %r3233, %r3234, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3238, [matrix+3012];
	// begin inline asm
	dp4a.u32.u32 %r3237, %r3238, %r4295, %r3233;
	// end inline asm
	ld.const.u32 	%r3242, [matrix+3016];
	// begin inline asm
	dp4a.u32.u32 %r3241, %r3242, %r4299, %r3237;
	// end inline asm
	ld.const.u32 	%r3246, [matrix+3020];
	// begin inline asm
	dp4a.u32.u32 %r3245, %r3246, %r4303, %r3241;
	// end inline asm
	ld.const.u32 	%r3250, [matrix+3024];
	// begin inline asm
	dp4a.u32.u32 %r3249, %r3250, %r4307, %r3245;
	// end inline asm
	ld.const.u32 	%r3254, [matrix+3028];
	// begin inline asm
	dp4a.u32.u32 %r3253, %r3254, %r4311, %r3249;
	// end inline asm
	ld.const.u32 	%r3258, [matrix+3032];
	// begin inline asm
	dp4a.u32.u32 %r3257, %r3258, %r4315, %r3253;
	// end inline asm
	ld.const.u32 	%r3262, [matrix+3036];
	// begin inline asm
	dp4a.u32.u32 %r3261, %r3262, %r4319, %r3257;
	// end inline asm
	ld.const.u32 	%r3266, [matrix+3040];
	// begin inline asm
	dp4a.u32.u32 %r3265, %r3266, %r4323, %r3261;
	// end inline asm
	ld.const.u32 	%r3270, [matrix+3044];
	// begin inline asm
	dp4a.u32.u32 %r3269, %r3270, %r4327, %r3265;
	// end inline asm
	ld.const.u32 	%r3274, [matrix+3048];
	// begin inline asm
	dp4a.u32.u32 %r3273, %r3274, %r4331, %r3269;
	// end inline asm
	ld.const.u32 	%r3278, [matrix+3052];
	// begin inline asm
	dp4a.u32.u32 %r3277, %r3278, %r4335, %r3273;
	// end inline asm
	ld.const.u32 	%r3282, [matrix+3056];
	// begin inline asm
	dp4a.u32.u32 %r3281, %r3282, %r4339, %r3277;
	// end inline asm
	ld.const.u32 	%r3286, [matrix+3060];
	// begin inline asm
	dp4a.u32.u32 %r3285, %r3286, %r4343, %r3281;
	// end inline asm
	ld.const.u32 	%r3290, [matrix+3064];
	// begin inline asm
	dp4a.u32.u32 %r3289, %r3290, %r4347, %r3285;
	// end inline asm
	ld.const.u32 	%r3294, [matrix+3068];
	// begin inline asm
	dp4a.u32.u32 %r3293, %r3294, %r4351, %r3289;
	// end inline asm
	shr.u32 	%r4545, %r3229, 6;
	and.b32  	%r3298, %r4545, 240;
	shr.u32 	%r3299, %r3293, 10;
	// begin inline asm
	lop3.b32 %r3297, %r3298, %r3299, %r3300, 0x56;
	// end inline asm
	ld.const.u32 	%r3302, [matrix+3072];
	// begin inline asm
	dp4a.u32.u32 %r3301, %r3302, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3306, [matrix+3076];
	// begin inline asm
	dp4a.u32.u32 %r3305, %r3306, %r4295, %r3301;
	// end inline asm
	ld.const.u32 	%r3310, [matrix+3080];
	// begin inline asm
	dp4a.u32.u32 %r3309, %r3310, %r4299, %r3305;
	// end inline asm
	ld.const.u32 	%r3314, [matrix+3084];
	// begin inline asm
	dp4a.u32.u32 %r3313, %r3314, %r4303, %r3309;
	// end inline asm
	ld.const.u32 	%r3318, [matrix+3088];
	// begin inline asm
	dp4a.u32.u32 %r3317, %r3318, %r4307, %r3313;
	// end inline asm
	ld.const.u32 	%r3322, [matrix+3092];
	// begin inline asm
	dp4a.u32.u32 %r3321, %r3322, %r4311, %r3317;
	// end inline asm
	ld.const.u32 	%r3326, [matrix+3096];
	// begin inline asm
	dp4a.u32.u32 %r3325, %r3326, %r4315, %r3321;
	// end inline asm
	ld.const.u32 	%r3330, [matrix+3100];
	// begin inline asm
	dp4a.u32.u32 %r3329, %r3330, %r4319, %r3325;
	// end inline asm
	ld.const.u32 	%r3334, [matrix+3104];
	// begin inline asm
	dp4a.u32.u32 %r3333, %r3334, %r4323, %r3329;
	// end inline asm
	ld.const.u32 	%r3338, [matrix+3108];
	// begin inline asm
	dp4a.u32.u32 %r3337, %r3338, %r4327, %r3333;
	// end inline asm
	ld.const.u32 	%r3342, [matrix+3112];
	// begin inline asm
	dp4a.u32.u32 %r3341, %r3342, %r4331, %r3337;
	// end inline asm
	ld.const.u32 	%r3346, [matrix+3116];
	// begin inline asm
	dp4a.u32.u32 %r3345, %r3346, %r4335, %r3341;
	// end inline asm
	ld.const.u32 	%r3350, [matrix+3120];
	// begin inline asm
	dp4a.u32.u32 %r3349, %r3350, %r4339, %r3345;
	// end inline asm
	ld.const.u32 	%r3354, [matrix+3124];
	// begin inline asm
	dp4a.u32.u32 %r3353, %r3354, %r4343, %r3349;
	// end inline asm
	ld.const.u32 	%r3358, [matrix+3128];
	// begin inline asm
	dp4a.u32.u32 %r3357, %r3358, %r4347, %r3353;
	// end inline asm
	ld.const.u32 	%r3362, [matrix+3132];
	// begin inline asm
	dp4a.u32.u32 %r3361, %r3362, %r4351, %r3357;
	// end inline asm
	ld.const.u32 	%r3366, [matrix+3136];
	// begin inline asm
	dp4a.u32.u32 %r3365, %r3366, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3370, [matrix+3140];
	// begin inline asm
	dp4a.u32.u32 %r3369, %r3370, %r4295, %r3365;
	// end inline asm
	ld.const.u32 	%r3374, [matrix+3144];
	// begin inline asm
	dp4a.u32.u32 %r3373, %r3374, %r4299, %r3369;
	// end inline asm
	ld.const.u32 	%r3378, [matrix+3148];
	// begin inline asm
	dp4a.u32.u32 %r3377, %r3378, %r4303, %r3373;
	// end inline asm
	ld.const.u32 	%r3382, [matrix+3152];
	// begin inline asm
	dp4a.u32.u32 %r3381, %r3382, %r4307, %r3377;
	// end inline asm
	ld.const.u32 	%r3386, [matrix+3156];
	// begin inline asm
	dp4a.u32.u32 %r3385, %r3386, %r4311, %r3381;
	// end inline asm
	ld.const.u32 	%r3390, [matrix+3160];
	// begin inline asm
	dp4a.u32.u32 %r3389, %r3390, %r4315, %r3385;
	// end inline asm
	ld.const.u32 	%r3394, [matrix+3164];
	// begin inline asm
	dp4a.u32.u32 %r3393, %r3394, %r4319, %r3389;
	// end inline asm
	ld.const.u32 	%r3398, [matrix+3168];
	// begin inline asm
	dp4a.u32.u32 %r3397, %r3398, %r4323, %r3393;
	// end inline asm
	ld.const.u32 	%r3402, [matrix+3172];
	// begin inline asm
	dp4a.u32.u32 %r3401, %r3402, %r4327, %r3397;
	// end inline asm
	ld.const.u32 	%r3406, [matrix+3176];
	// begin inline asm
	dp4a.u32.u32 %r3405, %r3406, %r4331, %r3401;
	// end inline asm
	ld.const.u32 	%r3410, [matrix+3180];
	// begin inline asm
	dp4a.u32.u32 %r3409, %r3410, %r4335, %r3405;
	// end inline asm
	ld.const.u32 	%r3414, [matrix+3184];
	// begin inline asm
	dp4a.u32.u32 %r3413, %r3414, %r4339, %r3409;
	// end inline asm
	ld.const.u32 	%r3418, [matrix+3188];
	// begin inline asm
	dp4a.u32.u32 %r3417, %r3418, %r4343, %r3413;
	// end inline asm
	ld.const.u32 	%r3422, [matrix+3192];
	// begin inline asm
	dp4a.u32.u32 %r3421, %r3422, %r4347, %r3417;
	// end inline asm
	ld.const.u32 	%r3426, [matrix+3196];
	// begin inline asm
	dp4a.u32.u32 %r3425, %r3426, %r4351, %r3421;
	// end inline asm
	shr.u32 	%r4546, %r3361, 6;
	and.b32  	%r3430, %r4546, 240;
	shr.u32 	%r3431, %r3425, 10;
	and.b32  	%r3432, %r4481, 255;
	// begin inline asm
	lop3.b32 %r3429, %r3430, %r3431, %r3432, 0x56;
	// end inline asm
	ld.const.u32 	%r3434, [matrix+3200];
	// begin inline asm
	dp4a.u32.u32 %r3433, %r3434, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3438, [matrix+3204];
	// begin inline asm
	dp4a.u32.u32 %r3437, %r3438, %r4295, %r3433;
	// end inline asm
	ld.const.u32 	%r3442, [matrix+3208];
	// begin inline asm
	dp4a.u32.u32 %r3441, %r3442, %r4299, %r3437;
	// end inline asm
	ld.const.u32 	%r3446, [matrix+3212];
	// begin inline asm
	dp4a.u32.u32 %r3445, %r3446, %r4303, %r3441;
	// end inline asm
	ld.const.u32 	%r3450, [matrix+3216];
	// begin inline asm
	dp4a.u32.u32 %r3449, %r3450, %r4307, %r3445;
	// end inline asm
	ld.const.u32 	%r3454, [matrix+3220];
	// begin inline asm
	dp4a.u32.u32 %r3453, %r3454, %r4311, %r3449;
	// end inline asm
	ld.const.u32 	%r3458, [matrix+3224];
	// begin inline asm
	dp4a.u32.u32 %r3457, %r3458, %r4315, %r3453;
	// end inline asm
	ld.const.u32 	%r3462, [matrix+3228];
	// begin inline asm
	dp4a.u32.u32 %r3461, %r3462, %r4319, %r3457;
	// end inline asm
	ld.const.u32 	%r3466, [matrix+3232];
	// begin inline asm
	dp4a.u32.u32 %r3465, %r3466, %r4323, %r3461;
	// end inline asm
	ld.const.u32 	%r3470, [matrix+3236];
	// begin inline asm
	dp4a.u32.u32 %r3469, %r3470, %r4327, %r3465;
	// end inline asm
	ld.const.u32 	%r3474, [matrix+3240];
	// begin inline asm
	dp4a.u32.u32 %r3473, %r3474, %r4331, %r3469;
	// end inline asm
	ld.const.u32 	%r3478, [matrix+3244];
	// begin inline asm
	dp4a.u32.u32 %r3477, %r3478, %r4335, %r3473;
	// end inline asm
	ld.const.u32 	%r3482, [matrix+3248];
	// begin inline asm
	dp4a.u32.u32 %r3481, %r3482, %r4339, %r3477;
	// end inline asm
	ld.const.u32 	%r3486, [matrix+3252];
	// begin inline asm
	dp4a.u32.u32 %r3485, %r3486, %r4343, %r3481;
	// end inline asm
	ld.const.u32 	%r3490, [matrix+3256];
	// begin inline asm
	dp4a.u32.u32 %r3489, %r3490, %r4347, %r3485;
	// end inline asm
	ld.const.u32 	%r3494, [matrix+3260];
	// begin inline asm
	dp4a.u32.u32 %r3493, %r3494, %r4351, %r3489;
	// end inline asm
	ld.const.u32 	%r3498, [matrix+3264];
	// begin inline asm
	dp4a.u32.u32 %r3497, %r3498, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3502, [matrix+3268];
	// begin inline asm
	dp4a.u32.u32 %r3501, %r3502, %r4295, %r3497;
	// end inline asm
	ld.const.u32 	%r3506, [matrix+3272];
	// begin inline asm
	dp4a.u32.u32 %r3505, %r3506, %r4299, %r3501;
	// end inline asm
	ld.const.u32 	%r3510, [matrix+3276];
	// begin inline asm
	dp4a.u32.u32 %r3509, %r3510, %r4303, %r3505;
	// end inline asm
	ld.const.u32 	%r3514, [matrix+3280];
	// begin inline asm
	dp4a.u32.u32 %r3513, %r3514, %r4307, %r3509;
	// end inline asm
	ld.const.u32 	%r3518, [matrix+3284];
	// begin inline asm
	dp4a.u32.u32 %r3517, %r3518, %r4311, %r3513;
	// end inline asm
	ld.const.u32 	%r3522, [matrix+3288];
	// begin inline asm
	dp4a.u32.u32 %r3521, %r3522, %r4315, %r3517;
	// end inline asm
	ld.const.u32 	%r3526, [matrix+3292];
	// begin inline asm
	dp4a.u32.u32 %r3525, %r3526, %r4319, %r3521;
	// end inline asm
	ld.const.u32 	%r3530, [matrix+3296];
	// begin inline asm
	dp4a.u32.u32 %r3529, %r3530, %r4323, %r3525;
	// end inline asm
	ld.const.u32 	%r3534, [matrix+3300];
	// begin inline asm
	dp4a.u32.u32 %r3533, %r3534, %r4327, %r3529;
	// end inline asm
	ld.const.u32 	%r3538, [matrix+3304];
	// begin inline asm
	dp4a.u32.u32 %r3537, %r3538, %r4331, %r3533;
	// end inline asm
	ld.const.u32 	%r3542, [matrix+3308];
	// begin inline asm
	dp4a.u32.u32 %r3541, %r3542, %r4335, %r3537;
	// end inline asm
	ld.const.u32 	%r3546, [matrix+3312];
	// begin inline asm
	dp4a.u32.u32 %r3545, %r3546, %r4339, %r3541;
	// end inline asm
	ld.const.u32 	%r3550, [matrix+3316];
	// begin inline asm
	dp4a.u32.u32 %r3549, %r3550, %r4343, %r3545;
	// end inline asm
	ld.const.u32 	%r3554, [matrix+3320];
	// begin inline asm
	dp4a.u32.u32 %r3553, %r3554, %r4347, %r3549;
	// end inline asm
	ld.const.u32 	%r3558, [matrix+3324];
	// begin inline asm
	dp4a.u32.u32 %r3557, %r3558, %r4351, %r3553;
	// end inline asm
	shr.u32 	%r4547, %r3493, 6;
	and.b32  	%r3562, %r4547, 240;
	shr.u32 	%r3563, %r3557, 10;
	and.b32  	%r3564, %r4483, 255;
	// begin inline asm
	lop3.b32 %r3561, %r3562, %r3563, %r3564, 0x56;
	// end inline asm
	ld.const.u32 	%r3566, [matrix+3328];
	// begin inline asm
	dp4a.u32.u32 %r3565, %r3566, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3570, [matrix+3332];
	// begin inline asm
	dp4a.u32.u32 %r3569, %r3570, %r4295, %r3565;
	// end inline asm
	ld.const.u32 	%r3574, [matrix+3336];
	// begin inline asm
	dp4a.u32.u32 %r3573, %r3574, %r4299, %r3569;
	// end inline asm
	ld.const.u32 	%r3578, [matrix+3340];
	// begin inline asm
	dp4a.u32.u32 %r3577, %r3578, %r4303, %r3573;
	// end inline asm
	ld.const.u32 	%r3582, [matrix+3344];
	// begin inline asm
	dp4a.u32.u32 %r3581, %r3582, %r4307, %r3577;
	// end inline asm
	ld.const.u32 	%r3586, [matrix+3348];
	// begin inline asm
	dp4a.u32.u32 %r3585, %r3586, %r4311, %r3581;
	// end inline asm
	ld.const.u32 	%r3590, [matrix+3352];
	// begin inline asm
	dp4a.u32.u32 %r3589, %r3590, %r4315, %r3585;
	// end inline asm
	ld.const.u32 	%r3594, [matrix+3356];
	// begin inline asm
	dp4a.u32.u32 %r3593, %r3594, %r4319, %r3589;
	// end inline asm
	ld.const.u32 	%r3598, [matrix+3360];
	// begin inline asm
	dp4a.u32.u32 %r3597, %r3598, %r4323, %r3593;
	// end inline asm
	ld.const.u32 	%r3602, [matrix+3364];
	// begin inline asm
	dp4a.u32.u32 %r3601, %r3602, %r4327, %r3597;
	// end inline asm
	ld.const.u32 	%r3606, [matrix+3368];
	// begin inline asm
	dp4a.u32.u32 %r3605, %r3606, %r4331, %r3601;
	// end inline asm
	ld.const.u32 	%r3610, [matrix+3372];
	// begin inline asm
	dp4a.u32.u32 %r3609, %r3610, %r4335, %r3605;
	// end inline asm
	ld.const.u32 	%r3614, [matrix+3376];
	// begin inline asm
	dp4a.u32.u32 %r3613, %r3614, %r4339, %r3609;
	// end inline asm
	ld.const.u32 	%r3618, [matrix+3380];
	// begin inline asm
	dp4a.u32.u32 %r3617, %r3618, %r4343, %r3613;
	// end inline asm
	ld.const.u32 	%r3622, [matrix+3384];
	// begin inline asm
	dp4a.u32.u32 %r3621, %r3622, %r4347, %r3617;
	// end inline asm
	ld.const.u32 	%r3626, [matrix+3388];
	// begin inline asm
	dp4a.u32.u32 %r3625, %r3626, %r4351, %r3621;
	// end inline asm
	ld.const.u32 	%r3630, [matrix+3392];
	// begin inline asm
	dp4a.u32.u32 %r3629, %r3630, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3634, [matrix+3396];
	// begin inline asm
	dp4a.u32.u32 %r3633, %r3634, %r4295, %r3629;
	// end inline asm
	ld.const.u32 	%r3638, [matrix+3400];
	// begin inline asm
	dp4a.u32.u32 %r3637, %r3638, %r4299, %r3633;
	// end inline asm
	ld.const.u32 	%r3642, [matrix+3404];
	// begin inline asm
	dp4a.u32.u32 %r3641, %r3642, %r4303, %r3637;
	// end inline asm
	ld.const.u32 	%r3646, [matrix+3408];
	// begin inline asm
	dp4a.u32.u32 %r3645, %r3646, %r4307, %r3641;
	// end inline asm
	ld.const.u32 	%r3650, [matrix+3412];
	// begin inline asm
	dp4a.u32.u32 %r3649, %r3650, %r4311, %r3645;
	// end inline asm
	ld.const.u32 	%r3654, [matrix+3416];
	// begin inline asm
	dp4a.u32.u32 %r3653, %r3654, %r4315, %r3649;
	// end inline asm
	ld.const.u32 	%r3658, [matrix+3420];
	// begin inline asm
	dp4a.u32.u32 %r3657, %r3658, %r4319, %r3653;
	// end inline asm
	ld.const.u32 	%r3662, [matrix+3424];
	// begin inline asm
	dp4a.u32.u32 %r3661, %r3662, %r4323, %r3657;
	// end inline asm
	ld.const.u32 	%r3666, [matrix+3428];
	// begin inline asm
	dp4a.u32.u32 %r3665, %r3666, %r4327, %r3661;
	// end inline asm
	ld.const.u32 	%r3670, [matrix+3432];
	// begin inline asm
	dp4a.u32.u32 %r3669, %r3670, %r4331, %r3665;
	// end inline asm
	ld.const.u32 	%r3674, [matrix+3436];
	// begin inline asm
	dp4a.u32.u32 %r3673, %r3674, %r4335, %r3669;
	// end inline asm
	ld.const.u32 	%r3678, [matrix+3440];
	// begin inline asm
	dp4a.u32.u32 %r3677, %r3678, %r4339, %r3673;
	// end inline asm
	ld.const.u32 	%r3682, [matrix+3444];
	// begin inline asm
	dp4a.u32.u32 %r3681, %r3682, %r4343, %r3677;
	// end inline asm
	ld.const.u32 	%r3686, [matrix+3448];
	// begin inline asm
	dp4a.u32.u32 %r3685, %r3686, %r4347, %r3681;
	// end inline asm
	ld.const.u32 	%r3690, [matrix+3452];
	// begin inline asm
	dp4a.u32.u32 %r3689, %r3690, %r4351, %r3685;
	// end inline asm
	shr.u32 	%r4548, %r3625, 6;
	and.b32  	%r3694, %r4548, 240;
	shr.u32 	%r3695, %r3689, 10;
	and.b32  	%r3696, %r4493, 255;
	// begin inline asm
	lop3.b32 %r3693, %r3694, %r3695, %r3696, 0x56;
	// end inline asm
	shl.b32 	%r4549, %r3693, 16;
	and.b32  	%r4550, %r4549, 16711680;
	cvt.u64.u32 	%rd373, %r4550;
	ld.const.u32 	%r3698, [matrix+3456];
	// begin inline asm
	dp4a.u32.u32 %r3697, %r3698, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3702, [matrix+3460];
	// begin inline asm
	dp4a.u32.u32 %r3701, %r3702, %r4295, %r3697;
	// end inline asm
	ld.const.u32 	%r3706, [matrix+3464];
	// begin inline asm
	dp4a.u32.u32 %r3705, %r3706, %r4299, %r3701;
	// end inline asm
	ld.const.u32 	%r3710, [matrix+3468];
	// begin inline asm
	dp4a.u32.u32 %r3709, %r3710, %r4303, %r3705;
	// end inline asm
	ld.const.u32 	%r3714, [matrix+3472];
	// begin inline asm
	dp4a.u32.u32 %r3713, %r3714, %r4307, %r3709;
	// end inline asm
	ld.const.u32 	%r3718, [matrix+3476];
	// begin inline asm
	dp4a.u32.u32 %r3717, %r3718, %r4311, %r3713;
	// end inline asm
	ld.const.u32 	%r3722, [matrix+3480];
	// begin inline asm
	dp4a.u32.u32 %r3721, %r3722, %r4315, %r3717;
	// end inline asm
	ld.const.u32 	%r3726, [matrix+3484];
	// begin inline asm
	dp4a.u32.u32 %r3725, %r3726, %r4319, %r3721;
	// end inline asm
	ld.const.u32 	%r3730, [matrix+3488];
	// begin inline asm
	dp4a.u32.u32 %r3729, %r3730, %r4323, %r3725;
	// end inline asm
	ld.const.u32 	%r3734, [matrix+3492];
	// begin inline asm
	dp4a.u32.u32 %r3733, %r3734, %r4327, %r3729;
	// end inline asm
	ld.const.u32 	%r3738, [matrix+3496];
	// begin inline asm
	dp4a.u32.u32 %r3737, %r3738, %r4331, %r3733;
	// end inline asm
	ld.const.u32 	%r3742, [matrix+3500];
	// begin inline asm
	dp4a.u32.u32 %r3741, %r3742, %r4335, %r3737;
	// end inline asm
	ld.const.u32 	%r3746, [matrix+3504];
	// begin inline asm
	dp4a.u32.u32 %r3745, %r3746, %r4339, %r3741;
	// end inline asm
	ld.const.u32 	%r3750, [matrix+3508];
	// begin inline asm
	dp4a.u32.u32 %r3749, %r3750, %r4343, %r3745;
	// end inline asm
	ld.const.u32 	%r3754, [matrix+3512];
	// begin inline asm
	dp4a.u32.u32 %r3753, %r3754, %r4347, %r3749;
	// end inline asm
	ld.const.u32 	%r3758, [matrix+3516];
	// begin inline asm
	dp4a.u32.u32 %r3757, %r3758, %r4351, %r3753;
	// end inline asm
	ld.const.u32 	%r3762, [matrix+3520];
	// begin inline asm
	dp4a.u32.u32 %r3761, %r3762, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3766, [matrix+3524];
	// begin inline asm
	dp4a.u32.u32 %r3765, %r3766, %r4295, %r3761;
	// end inline asm
	ld.const.u32 	%r3770, [matrix+3528];
	// begin inline asm
	dp4a.u32.u32 %r3769, %r3770, %r4299, %r3765;
	// end inline asm
	ld.const.u32 	%r3774, [matrix+3532];
	// begin inline asm
	dp4a.u32.u32 %r3773, %r3774, %r4303, %r3769;
	// end inline asm
	ld.const.u32 	%r3778, [matrix+3536];
	// begin inline asm
	dp4a.u32.u32 %r3777, %r3778, %r4307, %r3773;
	// end inline asm
	ld.const.u32 	%r3782, [matrix+3540];
	// begin inline asm
	dp4a.u32.u32 %r3781, %r3782, %r4311, %r3777;
	// end inline asm
	ld.const.u32 	%r3786, [matrix+3544];
	// begin inline asm
	dp4a.u32.u32 %r3785, %r3786, %r4315, %r3781;
	// end inline asm
	ld.const.u32 	%r3790, [matrix+3548];
	// begin inline asm
	dp4a.u32.u32 %r3789, %r3790, %r4319, %r3785;
	// end inline asm
	ld.const.u32 	%r3794, [matrix+3552];
	// begin inline asm
	dp4a.u32.u32 %r3793, %r3794, %r4323, %r3789;
	// end inline asm
	ld.const.u32 	%r3798, [matrix+3556];
	// begin inline asm
	dp4a.u32.u32 %r3797, %r3798, %r4327, %r3793;
	// end inline asm
	ld.const.u32 	%r3802, [matrix+3560];
	// begin inline asm
	dp4a.u32.u32 %r3801, %r3802, %r4331, %r3797;
	// end inline asm
	ld.const.u32 	%r3806, [matrix+3564];
	// begin inline asm
	dp4a.u32.u32 %r3805, %r3806, %r4335, %r3801;
	// end inline asm
	ld.const.u32 	%r3810, [matrix+3568];
	// begin inline asm
	dp4a.u32.u32 %r3809, %r3810, %r4339, %r3805;
	// end inline asm
	ld.const.u32 	%r3814, [matrix+3572];
	// begin inline asm
	dp4a.u32.u32 %r3813, %r3814, %r4343, %r3809;
	// end inline asm
	ld.const.u32 	%r3818, [matrix+3576];
	// begin inline asm
	dp4a.u32.u32 %r3817, %r3818, %r4347, %r3813;
	// end inline asm
	ld.const.u32 	%r3822, [matrix+3580];
	// begin inline asm
	dp4a.u32.u32 %r3821, %r3822, %r4351, %r3817;
	// end inline asm
	shr.u32 	%r4551, %r3757, 6;
	and.b32  	%r3826, %r4551, 240;
	shr.u32 	%r3827, %r3821, 10;
	and.b32  	%r3828, %r4495, 255;
	// begin inline asm
	lop3.b32 %r3825, %r3826, %r3827, %r3828, 0x56;
	// end inline asm
	shl.b32 	%r4552, %r3825, 24;
	cvt.u64.u32 	%rd374, %r4552;
	ld.const.u32 	%r3830, [matrix+3584];
	// begin inline asm
	dp4a.u32.u32 %r3829, %r3830, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3834, [matrix+3588];
	// begin inline asm
	dp4a.u32.u32 %r3833, %r3834, %r4295, %r3829;
	// end inline asm
	ld.const.u32 	%r3838, [matrix+3592];
	// begin inline asm
	dp4a.u32.u32 %r3837, %r3838, %r4299, %r3833;
	// end inline asm
	ld.const.u32 	%r3842, [matrix+3596];
	// begin inline asm
	dp4a.u32.u32 %r3841, %r3842, %r4303, %r3837;
	// end inline asm
	ld.const.u32 	%r3846, [matrix+3600];
	// begin inline asm
	dp4a.u32.u32 %r3845, %r3846, %r4307, %r3841;
	// end inline asm
	ld.const.u32 	%r3850, [matrix+3604];
	// begin inline asm
	dp4a.u32.u32 %r3849, %r3850, %r4311, %r3845;
	// end inline asm
	ld.const.u32 	%r3854, [matrix+3608];
	// begin inline asm
	dp4a.u32.u32 %r3853, %r3854, %r4315, %r3849;
	// end inline asm
	ld.const.u32 	%r3858, [matrix+3612];
	// begin inline asm
	dp4a.u32.u32 %r3857, %r3858, %r4319, %r3853;
	// end inline asm
	ld.const.u32 	%r3862, [matrix+3616];
	// begin inline asm
	dp4a.u32.u32 %r3861, %r3862, %r4323, %r3857;
	// end inline asm
	ld.const.u32 	%r3866, [matrix+3620];
	// begin inline asm
	dp4a.u32.u32 %r3865, %r3866, %r4327, %r3861;
	// end inline asm
	ld.const.u32 	%r3870, [matrix+3624];
	// begin inline asm
	dp4a.u32.u32 %r3869, %r3870, %r4331, %r3865;
	// end inline asm
	ld.const.u32 	%r3874, [matrix+3628];
	// begin inline asm
	dp4a.u32.u32 %r3873, %r3874, %r4335, %r3869;
	// end inline asm
	ld.const.u32 	%r3878, [matrix+3632];
	// begin inline asm
	dp4a.u32.u32 %r3877, %r3878, %r4339, %r3873;
	// end inline asm
	ld.const.u32 	%r3882, [matrix+3636];
	// begin inline asm
	dp4a.u32.u32 %r3881, %r3882, %r4343, %r3877;
	// end inline asm
	ld.const.u32 	%r3886, [matrix+3640];
	// begin inline asm
	dp4a.u32.u32 %r3885, %r3886, %r4347, %r3881;
	// end inline asm
	ld.const.u32 	%r3890, [matrix+3644];
	// begin inline asm
	dp4a.u32.u32 %r3889, %r3890, %r4351, %r3885;
	// end inline asm
	ld.const.u32 	%r3894, [matrix+3648];
	// begin inline asm
	dp4a.u32.u32 %r3893, %r3894, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3898, [matrix+3652];
	// begin inline asm
	dp4a.u32.u32 %r3897, %r3898, %r4295, %r3893;
	// end inline asm
	ld.const.u32 	%r3902, [matrix+3656];
	// begin inline asm
	dp4a.u32.u32 %r3901, %r3902, %r4299, %r3897;
	// end inline asm
	ld.const.u32 	%r3906, [matrix+3660];
	// begin inline asm
	dp4a.u32.u32 %r3905, %r3906, %r4303, %r3901;
	// end inline asm
	ld.const.u32 	%r3910, [matrix+3664];
	// begin inline asm
	dp4a.u32.u32 %r3909, %r3910, %r4307, %r3905;
	// end inline asm
	ld.const.u32 	%r3914, [matrix+3668];
	// begin inline asm
	dp4a.u32.u32 %r3913, %r3914, %r4311, %r3909;
	// end inline asm
	ld.const.u32 	%r3918, [matrix+3672];
	// begin inline asm
	dp4a.u32.u32 %r3917, %r3918, %r4315, %r3913;
	// end inline asm
	ld.const.u32 	%r3922, [matrix+3676];
	// begin inline asm
	dp4a.u32.u32 %r3921, %r3922, %r4319, %r3917;
	// end inline asm
	ld.const.u32 	%r3926, [matrix+3680];
	// begin inline asm
	dp4a.u32.u32 %r3925, %r3926, %r4323, %r3921;
	// end inline asm
	ld.const.u32 	%r3930, [matrix+3684];
	// begin inline asm
	dp4a.u32.u32 %r3929, %r3930, %r4327, %r3925;
	// end inline asm
	ld.const.u32 	%r3934, [matrix+3688];
	// begin inline asm
	dp4a.u32.u32 %r3933, %r3934, %r4331, %r3929;
	// end inline asm
	ld.const.u32 	%r3938, [matrix+3692];
	// begin inline asm
	dp4a.u32.u32 %r3937, %r3938, %r4335, %r3933;
	// end inline asm
	ld.const.u32 	%r3942, [matrix+3696];
	// begin inline asm
	dp4a.u32.u32 %r3941, %r3942, %r4339, %r3937;
	// end inline asm
	ld.const.u32 	%r3946, [matrix+3700];
	// begin inline asm
	dp4a.u32.u32 %r3945, %r3946, %r4343, %r3941;
	// end inline asm
	ld.const.u32 	%r3950, [matrix+3704];
	// begin inline asm
	dp4a.u32.u32 %r3949, %r3950, %r4347, %r3945;
	// end inline asm
	ld.const.u32 	%r3954, [matrix+3708];
	// begin inline asm
	dp4a.u32.u32 %r3953, %r3954, %r4351, %r3949;
	// end inline asm
	shr.u32 	%r4553, %r3889, 6;
	and.b32  	%r3958, %r4553, 240;
	shr.u32 	%r3959, %r3953, 10;
	and.b32  	%r3960, %r4503, 255;
	// begin inline asm
	lop3.b32 %r3957, %r3958, %r3959, %r3960, 0x56;
	// end inline asm
	ld.const.u32 	%r3962, [matrix+3712];
	// begin inline asm
	dp4a.u32.u32 %r3961, %r3962, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r3966, [matrix+3716];
	// begin inline asm
	dp4a.u32.u32 %r3965, %r3966, %r4295, %r3961;
	// end inline asm
	ld.const.u32 	%r3970, [matrix+3720];
	// begin inline asm
	dp4a.u32.u32 %r3969, %r3970, %r4299, %r3965;
	// end inline asm
	ld.const.u32 	%r3974, [matrix+3724];
	// begin inline asm
	dp4a.u32.u32 %r3973, %r3974, %r4303, %r3969;
	// end inline asm
	ld.const.u32 	%r3978, [matrix+3728];
	// begin inline asm
	dp4a.u32.u32 %r3977, %r3978, %r4307, %r3973;
	// end inline asm
	ld.const.u32 	%r3982, [matrix+3732];
	// begin inline asm
	dp4a.u32.u32 %r3981, %r3982, %r4311, %r3977;
	// end inline asm
	ld.const.u32 	%r3986, [matrix+3736];
	// begin inline asm
	dp4a.u32.u32 %r3985, %r3986, %r4315, %r3981;
	// end inline asm
	ld.const.u32 	%r3990, [matrix+3740];
	// begin inline asm
	dp4a.u32.u32 %r3989, %r3990, %r4319, %r3985;
	// end inline asm
	ld.const.u32 	%r3994, [matrix+3744];
	// begin inline asm
	dp4a.u32.u32 %r3993, %r3994, %r4323, %r3989;
	// end inline asm
	ld.const.u32 	%r3998, [matrix+3748];
	// begin inline asm
	dp4a.u32.u32 %r3997, %r3998, %r4327, %r3993;
	// end inline asm
	ld.const.u32 	%r4002, [matrix+3752];
	// begin inline asm
	dp4a.u32.u32 %r4001, %r4002, %r4331, %r3997;
	// end inline asm
	ld.const.u32 	%r4006, [matrix+3756];
	// begin inline asm
	dp4a.u32.u32 %r4005, %r4006, %r4335, %r4001;
	// end inline asm
	ld.const.u32 	%r4010, [matrix+3760];
	// begin inline asm
	dp4a.u32.u32 %r4009, %r4010, %r4339, %r4005;
	// end inline asm
	ld.const.u32 	%r4014, [matrix+3764];
	// begin inline asm
	dp4a.u32.u32 %r4013, %r4014, %r4343, %r4009;
	// end inline asm
	ld.const.u32 	%r4018, [matrix+3768];
	// begin inline asm
	dp4a.u32.u32 %r4017, %r4018, %r4347, %r4013;
	// end inline asm
	ld.const.u32 	%r4022, [matrix+3772];
	// begin inline asm
	dp4a.u32.u32 %r4021, %r4022, %r4351, %r4017;
	// end inline asm
	ld.const.u32 	%r4026, [matrix+3776];
	// begin inline asm
	dp4a.u32.u32 %r4025, %r4026, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r4030, [matrix+3780];
	// begin inline asm
	dp4a.u32.u32 %r4029, %r4030, %r4295, %r4025;
	// end inline asm
	ld.const.u32 	%r4034, [matrix+3784];
	// begin inline asm
	dp4a.u32.u32 %r4033, %r4034, %r4299, %r4029;
	// end inline asm
	ld.const.u32 	%r4038, [matrix+3788];
	// begin inline asm
	dp4a.u32.u32 %r4037, %r4038, %r4303, %r4033;
	// end inline asm
	ld.const.u32 	%r4042, [matrix+3792];
	// begin inline asm
	dp4a.u32.u32 %r4041, %r4042, %r4307, %r4037;
	// end inline asm
	ld.const.u32 	%r4046, [matrix+3796];
	// begin inline asm
	dp4a.u32.u32 %r4045, %r4046, %r4311, %r4041;
	// end inline asm
	ld.const.u32 	%r4050, [matrix+3800];
	// begin inline asm
	dp4a.u32.u32 %r4049, %r4050, %r4315, %r4045;
	// end inline asm
	ld.const.u32 	%r4054, [matrix+3804];
	// begin inline asm
	dp4a.u32.u32 %r4053, %r4054, %r4319, %r4049;
	// end inline asm
	ld.const.u32 	%r4058, [matrix+3808];
	// begin inline asm
	dp4a.u32.u32 %r4057, %r4058, %r4323, %r4053;
	// end inline asm
	ld.const.u32 	%r4062, [matrix+3812];
	// begin inline asm
	dp4a.u32.u32 %r4061, %r4062, %r4327, %r4057;
	// end inline asm
	ld.const.u32 	%r4066, [matrix+3816];
	// begin inline asm
	dp4a.u32.u32 %r4065, %r4066, %r4331, %r4061;
	// end inline asm
	ld.const.u32 	%r4070, [matrix+3820];
	// begin inline asm
	dp4a.u32.u32 %r4069, %r4070, %r4335, %r4065;
	// end inline asm
	ld.const.u32 	%r4074, [matrix+3824];
	// begin inline asm
	dp4a.u32.u32 %r4073, %r4074, %r4339, %r4069;
	// end inline asm
	ld.const.u32 	%r4078, [matrix+3828];
	// begin inline asm
	dp4a.u32.u32 %r4077, %r4078, %r4343, %r4073;
	// end inline asm
	ld.const.u32 	%r4082, [matrix+3832];
	// begin inline asm
	dp4a.u32.u32 %r4081, %r4082, %r4347, %r4077;
	// end inline asm
	ld.const.u32 	%r4086, [matrix+3836];
	// begin inline asm
	dp4a.u32.u32 %r4085, %r4086, %r4351, %r4081;
	// end inline asm
	shr.u32 	%r4554, %r4021, 6;
	and.b32  	%r4090, %r4554, 240;
	shr.u32 	%r4091, %r4085, 10;
	and.b32  	%r4092, %r4506, 255;
	// begin inline asm
	lop3.b32 %r4089, %r4090, %r4091, %r4092, 0x56;
	// end inline asm
	ld.const.u32 	%r4094, [matrix+3840];
	// begin inline asm
	dp4a.u32.u32 %r4093, %r4094, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r4098, [matrix+3844];
	// begin inline asm
	dp4a.u32.u32 %r4097, %r4098, %r4295, %r4093;
	// end inline asm
	ld.const.u32 	%r4102, [matrix+3848];
	// begin inline asm
	dp4a.u32.u32 %r4101, %r4102, %r4299, %r4097;
	// end inline asm
	ld.const.u32 	%r4106, [matrix+3852];
	// begin inline asm
	dp4a.u32.u32 %r4105, %r4106, %r4303, %r4101;
	// end inline asm
	ld.const.u32 	%r4110, [matrix+3856];
	// begin inline asm
	dp4a.u32.u32 %r4109, %r4110, %r4307, %r4105;
	// end inline asm
	ld.const.u32 	%r4114, [matrix+3860];
	// begin inline asm
	dp4a.u32.u32 %r4113, %r4114, %r4311, %r4109;
	// end inline asm
	ld.const.u32 	%r4118, [matrix+3864];
	// begin inline asm
	dp4a.u32.u32 %r4117, %r4118, %r4315, %r4113;
	// end inline asm
	ld.const.u32 	%r4122, [matrix+3868];
	// begin inline asm
	dp4a.u32.u32 %r4121, %r4122, %r4319, %r4117;
	// end inline asm
	ld.const.u32 	%r4126, [matrix+3872];
	// begin inline asm
	dp4a.u32.u32 %r4125, %r4126, %r4323, %r4121;
	// end inline asm
	ld.const.u32 	%r4130, [matrix+3876];
	// begin inline asm
	dp4a.u32.u32 %r4129, %r4130, %r4327, %r4125;
	// end inline asm
	ld.const.u32 	%r4134, [matrix+3880];
	// begin inline asm
	dp4a.u32.u32 %r4133, %r4134, %r4331, %r4129;
	// end inline asm
	ld.const.u32 	%r4138, [matrix+3884];
	// begin inline asm
	dp4a.u32.u32 %r4137, %r4138, %r4335, %r4133;
	// end inline asm
	ld.const.u32 	%r4142, [matrix+3888];
	// begin inline asm
	dp4a.u32.u32 %r4141, %r4142, %r4339, %r4137;
	// end inline asm
	ld.const.u32 	%r4146, [matrix+3892];
	// begin inline asm
	dp4a.u32.u32 %r4145, %r4146, %r4343, %r4141;
	// end inline asm
	ld.const.u32 	%r4150, [matrix+3896];
	// begin inline asm
	dp4a.u32.u32 %r4149, %r4150, %r4347, %r4145;
	// end inline asm
	ld.const.u32 	%r4154, [matrix+3900];
	// begin inline asm
	dp4a.u32.u32 %r4153, %r4154, %r4351, %r4149;
	// end inline asm
	ld.const.u32 	%r4158, [matrix+3904];
	// begin inline asm
	dp4a.u32.u32 %r4157, %r4158, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r4162, [matrix+3908];
	// begin inline asm
	dp4a.u32.u32 %r4161, %r4162, %r4295, %r4157;
	// end inline asm
	ld.const.u32 	%r4166, [matrix+3912];
	// begin inline asm
	dp4a.u32.u32 %r4165, %r4166, %r4299, %r4161;
	// end inline asm
	ld.const.u32 	%r4170, [matrix+3916];
	// begin inline asm
	dp4a.u32.u32 %r4169, %r4170, %r4303, %r4165;
	// end inline asm
	ld.const.u32 	%r4174, [matrix+3920];
	// begin inline asm
	dp4a.u32.u32 %r4173, %r4174, %r4307, %r4169;
	// end inline asm
	ld.const.u32 	%r4178, [matrix+3924];
	// begin inline asm
	dp4a.u32.u32 %r4177, %r4178, %r4311, %r4173;
	// end inline asm
	ld.const.u32 	%r4182, [matrix+3928];
	// begin inline asm
	dp4a.u32.u32 %r4181, %r4182, %r4315, %r4177;
	// end inline asm
	ld.const.u32 	%r4186, [matrix+3932];
	// begin inline asm
	dp4a.u32.u32 %r4185, %r4186, %r4319, %r4181;
	// end inline asm
	ld.const.u32 	%r4190, [matrix+3936];
	// begin inline asm
	dp4a.u32.u32 %r4189, %r4190, %r4323, %r4185;
	// end inline asm
	ld.const.u32 	%r4194, [matrix+3940];
	// begin inline asm
	dp4a.u32.u32 %r4193, %r4194, %r4327, %r4189;
	// end inline asm
	ld.const.u32 	%r4198, [matrix+3944];
	// begin inline asm
	dp4a.u32.u32 %r4197, %r4198, %r4331, %r4193;
	// end inline asm
	ld.const.u32 	%r4202, [matrix+3948];
	// begin inline asm
	dp4a.u32.u32 %r4201, %r4202, %r4335, %r4197;
	// end inline asm
	ld.const.u32 	%r4206, [matrix+3952];
	// begin inline asm
	dp4a.u32.u32 %r4205, %r4206, %r4339, %r4201;
	// end inline asm
	ld.const.u32 	%r4210, [matrix+3956];
	// begin inline asm
	dp4a.u32.u32 %r4209, %r4210, %r4343, %r4205;
	// end inline asm
	ld.const.u32 	%r4214, [matrix+3960];
	// begin inline asm
	dp4a.u32.u32 %r4213, %r4214, %r4347, %r4209;
	// end inline asm
	ld.const.u32 	%r4218, [matrix+3964];
	// begin inline asm
	dp4a.u32.u32 %r4217, %r4218, %r4351, %r4213;
	// end inline asm
	shr.u32 	%r4555, %r4153, 6;
	and.b32  	%r4222, %r4555, 240;
	shr.u32 	%r4223, %r4217, 10;
	and.b32  	%r4224, %r4515, 255;
	// begin inline asm
	lop3.b32 %r4221, %r4222, %r4223, %r4224, 0x56;
	// end inline asm
	ld.const.u32 	%r4226, [matrix+3968];
	// begin inline asm
	dp4a.u32.u32 %r4225, %r4226, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r4230, [matrix+3972];
	// begin inline asm
	dp4a.u32.u32 %r4229, %r4230, %r4295, %r4225;
	// end inline asm
	ld.const.u32 	%r4234, [matrix+3976];
	// begin inline asm
	dp4a.u32.u32 %r4233, %r4234, %r4299, %r4229;
	// end inline asm
	ld.const.u32 	%r4238, [matrix+3980];
	// begin inline asm
	dp4a.u32.u32 %r4237, %r4238, %r4303, %r4233;
	// end inline asm
	ld.const.u32 	%r4242, [matrix+3984];
	// begin inline asm
	dp4a.u32.u32 %r4241, %r4242, %r4307, %r4237;
	// end inline asm
	ld.const.u32 	%r4246, [matrix+3988];
	// begin inline asm
	dp4a.u32.u32 %r4245, %r4246, %r4311, %r4241;
	// end inline asm
	ld.const.u32 	%r4250, [matrix+3992];
	// begin inline asm
	dp4a.u32.u32 %r4249, %r4250, %r4315, %r4245;
	// end inline asm
	ld.const.u32 	%r4254, [matrix+3996];
	// begin inline asm
	dp4a.u32.u32 %r4253, %r4254, %r4319, %r4249;
	// end inline asm
	ld.const.u32 	%r4258, [matrix+4000];
	// begin inline asm
	dp4a.u32.u32 %r4257, %r4258, %r4323, %r4253;
	// end inline asm
	ld.const.u32 	%r4262, [matrix+4004];
	// begin inline asm
	dp4a.u32.u32 %r4261, %r4262, %r4327, %r4257;
	// end inline asm
	ld.const.u32 	%r4266, [matrix+4008];
	// begin inline asm
	dp4a.u32.u32 %r4265, %r4266, %r4331, %r4261;
	// end inline asm
	ld.const.u32 	%r4270, [matrix+4012];
	// begin inline asm
	dp4a.u32.u32 %r4269, %r4270, %r4335, %r4265;
	// end inline asm
	ld.const.u32 	%r4274, [matrix+4016];
	// begin inline asm
	dp4a.u32.u32 %r4273, %r4274, %r4339, %r4269;
	// end inline asm
	ld.const.u32 	%r4278, [matrix+4020];
	// begin inline asm
	dp4a.u32.u32 %r4277, %r4278, %r4343, %r4273;
	// end inline asm
	ld.const.u32 	%r4282, [matrix+4024];
	// begin inline asm
	dp4a.u32.u32 %r4281, %r4282, %r4347, %r4277;
	// end inline asm
	ld.const.u32 	%r4286, [matrix+4028];
	// begin inline asm
	dp4a.u32.u32 %r4285, %r4286, %r4351, %r4281;
	// end inline asm
	ld.const.u32 	%r4290, [matrix+4032];
	// begin inline asm
	dp4a.u32.u32 %r4289, %r4290, %r4291, %r4695;
	// end inline asm
	ld.const.u32 	%r4294, [matrix+4036];
	// begin inline asm
	dp4a.u32.u32 %r4293, %r4294, %r4295, %r4289;
	// end inline asm
	ld.const.u32 	%r4298, [matrix+4040];
	// begin inline asm
	dp4a.u32.u32 %r4297, %r4298, %r4299, %r4293;
	// end inline asm
	ld.const.u32 	%r4302, [matrix+4044];
	// begin inline asm
	dp4a.u32.u32 %r4301, %r4302, %r4303, %r4297;
	// end inline asm
	ld.const.u32 	%r4306, [matrix+4048];
	// begin inline asm
	dp4a.u32.u32 %r4305, %r4306, %r4307, %r4301;
	// end inline asm
	ld.const.u32 	%r4310, [matrix+4052];
	// begin inline asm
	dp4a.u32.u32 %r4309, %r4310, %r4311, %r4305;
	// end inline asm
	ld.const.u32 	%r4314, [matrix+4056];
	// begin inline asm
	dp4a.u32.u32 %r4313, %r4314, %r4315, %r4309;
	// end inline asm
	ld.const.u32 	%r4318, [matrix+4060];
	// begin inline asm
	dp4a.u32.u32 %r4317, %r4318, %r4319, %r4313;
	// end inline asm
	ld.const.u32 	%r4322, [matrix+4064];
	// begin inline asm
	dp4a.u32.u32 %r4321, %r4322, %r4323, %r4317;
	// end inline asm
	ld.const.u32 	%r4326, [matrix+4068];
	// begin inline asm
	dp4a.u32.u32 %r4325, %r4326, %r4327, %r4321;
	// end inline asm
	ld.const.u32 	%r4330, [matrix+4072];
	// begin inline asm
	dp4a.u32.u32 %r4329, %r4330, %r4331, %r4325;
	// end inline asm
	ld.const.u32 	%r4334, [matrix+4076];
	// begin inline asm
	dp4a.u32.u32 %r4333, %r4334, %r4335, %r4329;
	// end inline asm
	ld.const.u32 	%r4338, [matrix+4080];
	// begin inline asm
	dp4a.u32.u32 %r4337, %r4338, %r4339, %r4333;
	// end inline asm
	ld.const.u32 	%r4342, [matrix+4084];
	// begin inline asm
	dp4a.u32.u32 %r4341, %r4342, %r4343, %r4337;
	// end inline asm
	ld.const.u32 	%r4346, [matrix+4088];
	// begin inline asm
	dp4a.u32.u32 %r4345, %r4346, %r4347, %r4341;
	// end inline asm
	ld.const.u32 	%r4350, [matrix+4092];
	// begin inline asm
	dp4a.u32.u32 %r4349, %r4350, %r4351, %r4345;
	// end inline asm
	shr.u32 	%r4556, %r4285, 6;
	and.b32  	%r4354, %r4556, 240;
	shr.u32 	%r4355, %r4349, 10;
	// begin inline asm
	lop3.b32 %r4353, %r4354, %r4355, %r4356, 0x56;
	// end inline asm
	shl.b32 	%r4557, %r657, 24;
	cvt.u64.u32 	%rd375, %r4557;
	shl.b32 	%r4558, %r525, 16;
	and.b32  	%r4559, %r4558, 16711680;
	cvt.u64.u32 	%rd376, %r4559;
	shl.b32 	%r4560, %r393, 8;
	and.b32  	%r4561, %r4560, 65280;
	cvt.u64.u32 	%rd377, %r4561;
	shl.b32 	%r4562, %r1713, 24;
	cvt.u64.u32 	%rd378, %r4562;
	shl.b32 	%r4563, %r1581, 16;
	and.b32  	%r4564, %r4563, 16711680;
	cvt.u64.u32 	%rd379, %r4564;
	shl.b32 	%r4565, %r1449, 8;
	and.b32  	%r4566, %r4565, 65280;
	cvt.u64.u32 	%rd380, %r4566;
	shl.b32 	%r4567, %r2769, 24;
	cvt.u64.u32 	%rd381, %r4567;
	shl.b32 	%r4568, %r2637, 16;
	and.b32  	%r4569, %r4568, 16711680;
	cvt.u64.u32 	%rd382, %r4569;
	shl.b32 	%r4570, %r2505, 8;
	and.b32  	%r4571, %r4570, 65280;
	cvt.u64.u32 	%rd383, %r4571;
	cvt.u64.u32 	%rd384, %r1185;
	shl.b64 	%rd385, %rd384, 56;
	cvt.u64.u32 	%rd386, %r1053;
	shl.b64 	%rd387, %rd386, 48;
	and.b64  	%rd388, %rd387, 71776119061217280;
	or.b64  	%rd389, %rd385, %rd388;
	cvt.u64.u32 	%rd390, %r921;
	shl.b64 	%rd391, %rd390, 40;
	and.b64  	%rd392, %rd391, 280375465082880;
	or.b64  	%rd393, %rd389, %rd392;
	cvt.u64.u32 	%rd394, %r789;
	shl.b64 	%rd395, %rd394, 32;
	and.b64  	%rd396, %rd395, 1095216660480;
	or.b64  	%rd397, %rd393, %rd396;
	or.b64  	%rd398, %rd397, %rd375;
	or.b64  	%rd399, %rd398, %rd376;
	and.b32  	%r4572, %r261, 255;
	cvt.u64.u32 	%rd400, %r4572;
	or.b64  	%rd401, %rd399, %rd377;
	or.b64  	%rd402, %rd401, %rd400;
	xor.b64  	%rd123, %rd402, 4239941492252378377;
	cvt.u64.u32 	%rd403, %r2241;
	shl.b64 	%rd404, %rd403, 56;
	cvt.u64.u32 	%rd405, %r2109;
	shl.b64 	%rd406, %rd405, 48;
	and.b64  	%rd407, %rd406, 71776119061217280;
	or.b64  	%rd408, %rd404, %rd407;
	cvt.u64.u32 	%rd409, %r1977;
	shl.b64 	%rd410, %rd409, 40;
	and.b64  	%rd411, %rd410, 280375465082880;
	or.b64  	%rd412, %rd408, %rd411;
	cvt.u64.u32 	%rd413, %r1845;
	shl.b64 	%rd414, %rd413, 32;
	and.b64  	%rd415, %rd414, 1095216660480;
	or.b64  	%rd416, %rd412, %rd415;
	or.b64  	%rd417, %rd416, %rd378;
	or.b64  	%rd418, %rd417, %rd379;
	and.b32  	%r4573, %r1317, 255;
	cvt.u64.u32 	%rd419, %r4573;
	or.b64  	%rd420, %rd418, %rd380;
	or.b64  	%rd421, %rd420, %rd419;
	xor.b64  	%rd642, %rd421, 8746723911537738262;
	cvt.u64.u32 	%rd422, %r3297;
	shl.b64 	%rd423, %rd422, 56;
	cvt.u64.u32 	%rd424, %r3165;
	shl.b64 	%rd425, %rd424, 48;
	and.b64  	%rd426, %rd425, 71776119061217280;
	or.b64  	%rd427, %rd423, %rd426;
	cvt.u64.u32 	%rd428, %r3033;
	shl.b64 	%rd429, %rd428, 40;
	and.b64  	%rd430, %rd429, 280375465082880;
	or.b64  	%rd431, %rd427, %rd430;
	cvt.u64.u32 	%rd432, %r2901;
	shl.b64 	%rd433, %rd432, 32;
	and.b64  	%rd434, %rd433, 1095216660480;
	or.b64  	%rd435, %rd431, %rd434;
	or.b64  	%rd436, %rd435, %rd381;
	or.b64  	%rd437, %rd436, %rd382;
	and.b32  	%r4574, %r2373, 255;
	cvt.u64.u32 	%rd438, %r4574;
	or.b64  	%rd439, %rd437, %rd383;
	or.b64  	%rd440, %rd439, %rd438;
	xor.b64  	%rd637, %rd440, 8796936657246353646;
	cvt.u64.u32 	%rd441, %r4353;
	shl.b64 	%rd442, %rd441, 56;
	cvt.u64.u32 	%rd443, %r4221;
	shl.b64 	%rd444, %rd443, 48;
	and.b64  	%rd445, %rd444, 71776119061217280;
	or.b64  	%rd446, %rd442, %rd445;
	cvt.u64.u32 	%rd447, %r4089;
	shl.b64 	%rd448, %rd447, 40;
	and.b64  	%rd449, %rd448, 280375465082880;
	or.b64  	%rd450, %rd446, %rd449;
	cvt.u64.u32 	%rd451, %r3957;
	shl.b64 	%rd452, %rd451, 32;
	and.b64  	%rd453, %rd452, 1095216660480;
	or.b64  	%rd454, %rd450, %rd453;
	or.b64  	%rd455, %rd454, %rd374;
	shl.b32 	%r4575, %r3561, 8;
	and.b32  	%r4576, %r4575, 65280;
	cvt.u64.u32 	%rd456, %r4576;
	or.b64  	%rd457, %rd455, %rd373;
	and.b32  	%r4577, %r3429, 255;
	cvt.u64.u32 	%rd458, %r4577;
	or.b64  	%rd459, %rd457, %rd456;
	or.b64  	%rd460, %rd459, %rd458;
	xor.b64  	%rd632, %rd460, 1272090201925444760;
	mov.u64 	%rd646, 8270816933120786537;
	mov.u64 	%rd645, -850687345431043546;
	mov.u64 	%rd644, 8596393687355028144;
	mov.u64 	%rd643, -4073852189716399785;
	mov.u64 	%rd641, -4539347866060507718;
	mov.u64 	%rd640, -3233781605604422593;
	mov.u64 	%rd639, 570094237299545110;
	mov.u64 	%rd638, 5171152063242093102;
	mov.u64 	%rd636, 6782861118970774626;
	mov.u64 	%rd635, 7812475424661425213;
	mov.u64 	%rd634, 9119540418498120711;
	mov.u64 	%rd633, -7873636174015165430;
	mov.u64 	%rd631, -9207053471590684088;
	mov.u64 	%rd630, 3370482334374859748;
	mov.u64 	%rd629, -1544774801229058759;
	mov.u64 	%rd628, 6096431547456407061;
	mov.u64 	%rd627, -1792185402154627366;
	mov.u64 	%rd626, -6864424130110145268;
	mov.u64 	%rd625, 5690099369266491460;
	mov.u64 	%rd624, -5074726839974049192;
	mov.u64 	%rd623, 1592359455985097269;
	mov.u64 	%rd622, RC;

LBB0_9:
	xor.b64  	%rd461, %rd646, %rd123;
	xor.b64  	%rd462, %rd461, %rd645;
	xor.b64  	%rd463, %rd462, %rd644;
	xor.b64  	%rd464, %rd463, %rd643;
	xor.b64  	%rd465, %rd641, %rd642;
	xor.b64  	%rd466, %rd465, %rd640;
	xor.b64  	%rd467, %rd466, %rd639;
	xor.b64  	%rd468, %rd467, %rd638;
	xor.b64  	%rd469, %rd636, %rd637;
	xor.b64  	%rd470, %rd469, %rd635;
	xor.b64  	%rd471, %rd470, %rd634;
	xor.b64  	%rd472, %rd471, %rd633;
	xor.b64  	%rd473, %rd631, %rd632;
	xor.b64  	%rd474, %rd473, %rd630;
	xor.b64  	%rd475, %rd474, %rd629;
	xor.b64  	%rd476, %rd475, %rd628;
	xor.b64  	%rd477, %rd626, %rd627;
	xor.b64  	%rd478, %rd477, %rd625;
	xor.b64  	%rd479, %rd478, %rd624;
	xor.b64  	%rd480, %rd479, %rd623;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4578}, %rd468;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4579,%dummy}, %rd468;
	}
	shf.l.wrap.b32 	%r4580, %r4579, %r4578, 1;
	shf.l.wrap.b32 	%r4581, %r4578, %r4579, 1;
	mov.b64 	%rd481, {%r4581, %r4580};
	xor.b64  	%rd482, %rd480, %rd481;
	xor.b64  	%rd483, %rd482, %rd123;
	xor.b64  	%rd484, %rd646, %rd482;
	xor.b64  	%rd485, %rd645, %rd482;
	xor.b64  	%rd486, %rd644, %rd482;
	xor.b64  	%rd487, %rd643, %rd482;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4582}, %rd472;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4583,%dummy}, %rd472;
	}
	shf.l.wrap.b32 	%r4584, %r4583, %r4582, 1;
	shf.l.wrap.b32 	%r4585, %r4582, %r4583, 1;
	mov.b64 	%rd488, {%r4585, %r4584};
	xor.b64  	%rd489, %rd488, %rd464;
	xor.b64  	%rd490, %rd642, %rd489;
	xor.b64  	%rd491, %rd641, %rd489;
	xor.b64  	%rd492, %rd640, %rd489;
	xor.b64  	%rd493, %rd639, %rd489;
	xor.b64  	%rd494, %rd638, %rd489;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4586}, %rd476;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4587,%dummy}, %rd476;
	}
	shf.l.wrap.b32 	%r4588, %r4587, %r4586, 1;
	shf.l.wrap.b32 	%r4589, %r4586, %r4587, 1;
	mov.b64 	%rd495, {%r4589, %r4588};
	xor.b64  	%rd496, %rd495, %rd468;
	xor.b64  	%rd497, %rd637, %rd496;
	xor.b64  	%rd498, %rd636, %rd496;
	xor.b64  	%rd499, %rd635, %rd496;
	xor.b64  	%rd500, %rd634, %rd496;
	xor.b64  	%rd501, %rd633, %rd496;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4590}, %rd480;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4591,%dummy}, %rd480;
	}
	shf.l.wrap.b32 	%r4592, %r4591, %r4590, 1;
	shf.l.wrap.b32 	%r4593, %r4590, %r4591, 1;
	mov.b64 	%rd502, {%r4593, %r4592};
	xor.b64  	%rd503, %rd502, %rd472;
	xor.b64  	%rd504, %rd632, %rd503;
	xor.b64  	%rd505, %rd631, %rd503;
	xor.b64  	%rd506, %rd630, %rd503;
	xor.b64  	%rd507, %rd629, %rd503;
	xor.b64  	%rd508, %rd628, %rd503;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4594}, %rd464;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4595,%dummy}, %rd464;
	}
	shf.l.wrap.b32 	%r4596, %r4595, %r4594, 1;
	shf.l.wrap.b32 	%r4597, %r4594, %r4595, 1;
	mov.b64 	%rd509, {%r4597, %r4596};
	xor.b64  	%rd510, %rd476, %rd509;
	xor.b64  	%rd511, %rd627, %rd510;
	xor.b64  	%rd512, %rd626, %rd510;
	xor.b64  	%rd513, %rd625, %rd510;
	xor.b64  	%rd514, %rd624, %rd510;
	xor.b64  	%rd515, %rd623, %rd510;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4598}, %rd490;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4599,%dummy}, %rd490;
	}
	shf.l.wrap.b32 	%r4600, %r4599, %r4598, 1;
	shf.l.wrap.b32 	%r4601, %r4598, %r4599, 1;
	mov.b64 	%rd516, {%r4601, %r4600};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4602}, %rd485;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4603,%dummy}, %rd485;
	}
	shf.l.wrap.b32 	%r4604, %r4603, %r4602, 3;
	shf.l.wrap.b32 	%r4605, %r4602, %r4603, 3;
	mov.b64 	%rd517, {%r4605, %r4604};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4606}, %rd498;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4607,%dummy}, %rd498;
	}
	shf.l.wrap.b32 	%r4608, %r4607, %r4606, 6;
	shf.l.wrap.b32 	%r4609, %r4606, %r4607, 6;
	mov.b64 	%rd518, {%r4609, %r4608};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4610}, %rd492;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4611,%dummy}, %rd492;
	}
	shf.l.wrap.b32 	%r4612, %r4611, %r4610, 10;
	shf.l.wrap.b32 	%r4613, %r4610, %r4611, 10;
	mov.b64 	%rd519, {%r4613, %r4612};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4614}, %rd500;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4615,%dummy}, %rd500;
	}
	shf.l.wrap.b32 	%r4616, %r4615, %r4614, 15;
	shf.l.wrap.b32 	%r4617, %r4614, %r4615, 15;
	mov.b64 	%rd520, {%r4617, %r4616};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4618}, %rd507;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4619,%dummy}, %rd507;
	}
	shf.l.wrap.b32 	%r4620, %r4619, %r4618, 21;
	shf.l.wrap.b32 	%r4621, %r4618, %r4619, 21;
	mov.b64 	%rd521, {%r4621, %r4620};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4622}, %rd504;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4623,%dummy}, %rd504;
	}
	shf.l.wrap.b32 	%r4624, %r4623, %r4622, 28;
	shf.l.wrap.b32 	%r4625, %r4622, %r4623, 28;
	mov.b64 	%rd522, {%r4625, %r4624};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4626,%dummy}, %rd484;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4627}, %rd484;
	}
	shf.r.wrap.b32 	%r4628, %r4627, %r4626, 28;
	shf.r.wrap.b32 	%r4629, %r4626, %r4627, 28;
	mov.b64 	%rd523, {%r4629, %r4628};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4630,%dummy}, %rd493;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4631}, %rd493;
	}
	shf.r.wrap.b32 	%r4632, %r4631, %r4630, 19;
	shf.r.wrap.b32 	%r4633, %r4630, %r4631, 19;
	mov.b64 	%rd524, {%r4633, %r4632};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4634,%dummy}, %rd505;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4635}, %rd505;
	}
	shf.r.wrap.b32 	%r4636, %r4635, %r4634, 9;
	shf.r.wrap.b32 	%r4637, %r4634, %r4635, 9;
	mov.b64 	%rd525, {%r4637, %r4636};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4638}, %rd494;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4639,%dummy}, %rd494;
	}
	shf.l.wrap.b32 	%r4640, %r4639, %r4638, 2;
	shf.l.wrap.b32 	%r4641, %r4638, %r4639, 2;
	mov.b64 	%rd526, {%r4641, %r4640};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4642}, %rd515;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4643,%dummy}, %rd515;
	}
	shf.l.wrap.b32 	%r4644, %r4643, %r4642, 14;
	shf.l.wrap.b32 	%r4645, %r4642, %r4643, 14;
	mov.b64 	%rd527, {%r4645, %r4644};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4646}, %rd511;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4647,%dummy}, %rd511;
	}
	shf.l.wrap.b32 	%r4648, %r4647, %r4646, 27;
	shf.l.wrap.b32 	%r4649, %r4646, %r4647, 27;
	mov.b64 	%rd528, {%r4649, %r4648};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4650,%dummy}, %rd486;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4651}, %rd486;
	}
	shf.r.wrap.b32 	%r4652, %r4651, %r4650, 23;
	shf.r.wrap.b32 	%r4653, %r4650, %r4651, 23;
	mov.b64 	%rd529, {%r4653, %r4652};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4654,%dummy}, %rd508;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4655}, %rd508;
	}
	shf.r.wrap.b32 	%r4656, %r4655, %r4654, 8;
	shf.r.wrap.b32 	%r4657, %r4654, %r4655, 8;
	mov.b64 	%rd530, {%r4657, %r4656};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4658}, %rd514;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4659,%dummy}, %rd514;
	}
	shf.l.wrap.b32 	%r4660, %r4659, %r4658, 8;
	shf.l.wrap.b32 	%r4661, %r4658, %r4659, 8;
	mov.b64 	%rd531, {%r4661, %r4660};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4662}, %rd506;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4663,%dummy}, %rd506;
	}
	shf.l.wrap.b32 	%r4664, %r4663, %r4662, 25;
	shf.l.wrap.b32 	%r4665, %r4662, %r4663, 25;
	mov.b64 	%rd532, {%r4665, %r4664};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4666,%dummy}, %rd499;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4667}, %rd499;
	}
	shf.r.wrap.b32 	%r4668, %r4667, %r4666, 21;
	shf.r.wrap.b32 	%r4669, %r4666, %r4667, 21;
	mov.b64 	%rd533, {%r4669, %r4668};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4670,%dummy}, %rd497;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4671}, %rd497;
	}
	shf.r.wrap.b32 	%r4672, %r4671, %r4670, 2;
	shf.r.wrap.b32 	%r4673, %r4670, %r4671, 2;
	mov.b64 	%rd534, {%r4673, %r4672};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4674}, %rd487;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4675,%dummy}, %rd487;
	}
	shf.l.wrap.b32 	%r4676, %r4675, %r4674, 18;
	shf.l.wrap.b32 	%r4677, %r4674, %r4675, 18;
	mov.b64 	%rd535, {%r4677, %r4676};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4678,%dummy}, %rd513;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4679}, %rd513;
	}
	shf.r.wrap.b32 	%r4680, %r4679, %r4678, 25;
	shf.r.wrap.b32 	%r4681, %r4678, %r4679, 25;
	mov.b64 	%rd536, {%r4681, %r4680};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4682,%dummy}, %rd501;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4683}, %rd501;
	}
	shf.r.wrap.b32 	%r4684, %r4683, %r4682, 3;
	shf.r.wrap.b32 	%r4685, %r4682, %r4683, 3;
	mov.b64 	%rd537, {%r4685, %r4684};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4686}, %rd512;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4687,%dummy}, %rd512;
	}
	shf.l.wrap.b32 	%r4688, %r4687, %r4686, 20;
	shf.l.wrap.b32 	%r4689, %r4686, %r4687, 20;
	mov.b64 	%rd538, {%r4689, %r4688};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4690,%dummy}, %rd491;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4691}, %rd491;
	}
	shf.r.wrap.b32 	%r4692, %r4691, %r4690, 20;
	shf.r.wrap.b32 	%r4693, %r4690, %r4691, 20;
	mov.b64 	%rd539, {%r4693, %r4692};
	not.b64 	%rd540, %rd539;
	and.b64  	%rd541, %rd533, %rd540;
	xor.b64  	%rd542, %rd541, %rd483;
	not.b64 	%rd543, %rd533;
	and.b64  	%rd544, %rd521, %rd543;
	xor.b64  	%rd642, %rd544, %rd539;
	not.b64 	%rd545, %rd521;
	and.b64  	%rd546, %rd527, %rd545;
	xor.b64  	%rd637, %rd546, %rd533;
	not.b64 	%rd547, %rd527;
	and.b64  	%rd548, %rd483, %rd547;
	xor.b64  	%rd632, %rd548, %rd521;
	not.b64 	%rd549, %rd483;
	and.b64  	%rd550, %rd539, %rd549;
	xor.b64  	%rd627, %rd527, %rd550;
	not.b64 	%rd551, %rd538;
	and.b64  	%rd552, %rd517, %rd551;
	xor.b64  	%rd646, %rd552, %rd522;
	not.b64 	%rd553, %rd517;
	and.b64  	%rd554, %rd524, %rd553;
	xor.b64  	%rd641, %rd554, %rd538;
	not.b64 	%rd555, %rd524;
	and.b64  	%rd556, %rd537, %rd555;
	xor.b64  	%rd636, %rd556, %rd517;
	not.b64 	%rd557, %rd537;
	and.b64  	%rd558, %rd522, %rd557;
	xor.b64  	%rd631, %rd558, %rd524;
	not.b64 	%rd559, %rd522;
	and.b64  	%rd560, %rd538, %rd559;
	xor.b64  	%rd626, %rd537, %rd560;
	not.b64 	%rd561, %rd518;
	and.b64  	%rd562, %rd532, %rd561;
	xor.b64  	%rd645, %rd562, %rd516;
	not.b64 	%rd563, %rd532;
	and.b64  	%rd564, %rd531, %rd563;
	xor.b64  	%rd640, %rd564, %rd518;
	not.b64 	%rd565, %rd531;
	and.b64  	%rd566, %rd535, %rd565;
	xor.b64  	%rd635, %rd566, %rd532;
	not.b64 	%rd567, %rd535;
	and.b64  	%rd568, %rd516, %rd567;
	xor.b64  	%rd630, %rd568, %rd531;
	not.b64 	%rd569, %rd516;
	and.b64  	%rd570, %rd518, %rd569;
	xor.b64  	%rd625, %rd535, %rd570;
	not.b64 	%rd571, %rd523;
	and.b64  	%rd572, %rd519, %rd571;
	xor.b64  	%rd644, %rd572, %rd528;
	not.b64 	%rd573, %rd519;
	and.b64  	%rd574, %rd520, %rd573;
	xor.b64  	%rd639, %rd574, %rd523;
	not.b64 	%rd575, %rd520;
	and.b64  	%rd576, %rd530, %rd575;
	xor.b64  	%rd634, %rd576, %rd519;
	not.b64 	%rd577, %rd530;
	and.b64  	%rd578, %rd528, %rd577;
	xor.b64  	%rd629, %rd578, %rd520;
	not.b64 	%rd579, %rd528;
	and.b64  	%rd580, %rd523, %rd579;
	xor.b64  	%rd624, %rd530, %rd580;
	not.b64 	%rd581, %rd525;
	and.b64  	%rd582, %rd536, %rd581;
	xor.b64  	%rd643, %rd582, %rd534;
	not.b64 	%rd583, %rd536;
	and.b64  	%rd584, %rd529, %rd583;
	xor.b64  	%rd638, %rd584, %rd525;
	not.b64 	%rd585, %rd529;
	and.b64  	%rd586, %rd526, %rd585;
	xor.b64  	%rd633, %rd586, %rd536;
	not.b64 	%rd587, %rd526;
	and.b64  	%rd588, %rd534, %rd587;
	xor.b64  	%rd628, %rd588, %rd529;
	not.b64 	%rd589, %rd534;
	and.b64  	%rd590, %rd525, %rd589;
	xor.b64  	%rd623, %rd526, %rd590;
	ld.global.nc.u64 	%rd591, [%rd622];
	xor.b64  	%rd123, %rd542, %rd591;
	add.s64 	%rd622, %rd622, 8;
	add.s32 	%r4695, %r4695, 1;
	setp.ne.s32 	%p10, %r4695, 24;
	@%p10 bra 	LBB0_9;

	ld.const.u64 	%rd125, [target+24];
	setp.eq.s64 	%p11, %rd632, %rd125;
	@%p11 bra 	LBB0_12;
	bra.uni 	LBB0_11;

LBB0_12:
	ld.const.u64 	%rd126, [target+16];
	setp.eq.s64 	%p12, %rd637, %rd126;
	@%p12 bra 	LBB0_14;
	bra.uni 	LBB0_13;

LBB0_14:
	ld.const.u64 	%rd127, [target+8];
	setp.eq.s64 	%p13, %rd642, %rd127;
	@%p13 bra 	LBB0_16;
	bra.uni 	LBB0_15;

LBB0_16:
	ld.const.u64 	%rd592, [target];
	setp.lt.u64 	%p15, %rd123, %rd592;
	bra.uni 	LBB0_17;

LBB0_11:
	setp.lt.u64 	%p15, %rd632, %rd125;
	bra.uni 	LBB0_17;

LBB0_13:
	setp.lt.u64 	%p15, %rd637, %rd126;
	bra.uni 	LBB0_17;

LBB0_15:
	setp.lt.u64 	%p15, %rd642, %rd127;

LBB0_17:
	not.pred 	%p14, %p15;
	@%p14 bra 	LBB0_19;

	mov.u64 	%rd593, 0;
	atom.global.cas.b64 	%rd594, [%rd1], %rd593, %rd6;

LBB0_19:
	ret;

}

